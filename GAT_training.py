#!/usr/bin/env python3
"""
GATè‡ªç›‘ç£å­¦ä¹ è®­ç»ƒç³»ç»Ÿ
åŸºäºæœ€æ–°GNNè‡ªç›‘ç£å­¦ä¹ ç ”ç©¶ï¼Œä¸“ä¸ºå¤šè½¦åè°ƒè®¾è®¡

æ ¸å¿ƒæ€æƒ³ï¼š
1. å¯¹æ¯”å­¦ä¹  - å­¦ä¹ å¥½ååè°ƒæ–¹æ¡ˆçš„åŒºåˆ«
2. é‡å»ºå­¦ä¹  - é¢„æµ‹åè°ƒç­–ç•¥å’Œç»“æœ
3. å¤šè§†å›¾å­¦ä¹  - ä»ä¸åŒè§’åº¦ç†è§£è½¦è¾†äº¤äº’
4. ç»éªŒå›æ”¾ - ä»å†å²æˆåŠŸæ¡ˆä¾‹ä¸­å­¦ä¹ 

å‚è€ƒæ–‡çŒ®ï¼š
- TrajRCL: Self-supervised contrastive representation learning for trajectories
- HeCo: Self-supervised Heterogeneous Graph Neural Network with Co-contrastive Learning  
- ST-A-PGCL: Spatiotemporal adaptive periodical graph contrastive learning
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import random
import json
import time
from collections import deque, defaultdict
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
import math

@dataclass
class GATPlanningExperience:
    """GATè§„åˆ’ç»éªŒæ•°æ®"""
    # è¾“å…¥çŠ¶æ€
    graph_data: dict                    # è½¦è¾†äº¤äº’å›¾æ•°æ®
    vehicles_info: List[Dict]           # è½¦è¾†ä¿¡æ¯
    
    # GATå†³ç­–
    gat_decisions: dict                 # GATè¾“å‡ºçš„å†³ç­–
    guidance_list: List                 # è§£æåçš„åè°ƒæŒ‡å¯¼
    
    # è§„åˆ’ç»“æœ
    planning_results: Dict[int, bool]   # æ¯è¾†è½¦çš„è§„åˆ’æ˜¯å¦æˆåŠŸ
    success_rate: float                 # æ•´ä½“æˆåŠŸç‡
    planning_time: float                # è§„åˆ’è€—æ—¶
    conflict_count: int                 # å†²çªæ•°é‡
    
    # è´¨é‡è¯„ä¼°
    coordination_quality: float         # åè°ƒè´¨é‡è¯„åˆ† [0,1]
    efficiency_score: float             # æ•ˆç‡è¯„åˆ† [0,1]
    safety_score: float                 # å®‰å…¨è¯„åˆ† [0,1]
    
    # æ—¶é—´æˆ³
    timestamp: float
    map_name: str

class TrajectoryQualityEvaluator:
    """è½¨è¿¹è´¨é‡è¯„ä¼°å™¨ - ä¸ºè‡ªç›‘ç£å­¦ä¹ æä¾›ä¿¡å·"""
    
    def __init__(self, environment):
        self.environment = environment
        
    def evaluate_coordination_quality(self, planning_results: Dict, 
                                    vehicles_info: List[Dict], 
                                    guidance_list: List) -> Dict[str, float]:
        """ç»¼åˆè¯„ä¼°åè°ƒè´¨é‡"""
        
        successful_vehicles = [vid for vid, result in planning_results.items() 
                              if result.get('trajectory')]
        total_vehicles = len(planning_results)
        
        # 1. æˆåŠŸç‡è¯„åˆ†
        success_rate = len(successful_vehicles) / max(1, total_vehicles)
        
        # 2. æ•ˆç‡è¯„åˆ†
        efficiency_score = self._evaluate_efficiency(planning_results, vehicles_info)
        
        # 3. å®‰å…¨è¯„åˆ†  
        safety_score = self._evaluate_safety(planning_results)
        
        # 4. åè°ƒä¸€è‡´æ€§è¯„åˆ†
        coordination_score = self._evaluate_coordination_consistency(guidance_list)
        
        # 5. ç»¼åˆè´¨é‡è¯„åˆ†
        overall_quality = (0.4 * success_rate + 
                          0.25 * efficiency_score + 
                          0.25 * safety_score + 
                          0.1 * coordination_score)
        
        return {
            'overall_quality': overall_quality,
            'success_rate': success_rate,
            'efficiency_score': efficiency_score,
            'safety_score': safety_score,
            'coordination_score': coordination_score
        }
    
    def _evaluate_efficiency(self, planning_results: Dict, vehicles_info: List[Dict]) -> float:
        """è¯„ä¼°è§„åˆ’æ•ˆç‡"""
        if not planning_results:
            return 0.0
        
        total_efficiency = 0.0
        valid_count = 0
        
        for vehicle_info in vehicles_info:
            vid = vehicle_info['id']
            if vid in planning_results and planning_results[vid].get('trajectory'):
                trajectory = planning_results[vid]['trajectory']
                planning_time = planning_results[vid].get('planning_time', float('inf'))
                
                # è®¡ç®—è½¨è¿¹é•¿åº¦
                traj_length = len(trajectory)
                final_time = trajectory[-1].t if trajectory else float('inf')
                
                # è®¡ç®—ç›´çº¿è·ç¦»
                start = vehicle_info['start']
                goal = vehicle_info['goal']
                euclidean_dist = math.sqrt((goal.x - start.x)**2 + (goal.y - start.y)**2)
                
                # æ•ˆç‡ = ç›´çº¿è·ç¦» / (è½¨è¿¹æ—¶é—´ * è§„åˆ’æ—¶é—´æƒé‡)
                if final_time > 0 and planning_time < 60:  # åˆç†èŒƒå›´å†…
                    efficiency = euclidean_dist / (final_time + planning_time * 0.1)
                    total_efficiency += min(1.0, efficiency / 5.0)  # å½’ä¸€åŒ–
                    valid_count += 1
        
        return total_efficiency / max(1, valid_count)
    
    def _evaluate_safety(self, planning_results: Dict) -> float:
        """è¯„ä¼°å®‰å…¨æ€§ - æ£€æŸ¥è½¨è¿¹é—´çš„æœ€å°è·ç¦»"""
        trajectories = []
        for result in planning_results.values():
            if result.get('trajectory'):
                trajectories.append(result['trajectory'])
        
        if len(trajectories) < 2:
            return 1.0  # å•è½¦æˆ–æ— è½¦æƒ…å†µè®¤ä¸ºæ˜¯å®‰å…¨çš„
        
        min_distance = float('inf')
        
        # æ£€æŸ¥æ‰€æœ‰è½¨è¿¹å¯¹åœ¨æ‰€æœ‰æ—¶é—´ç‚¹çš„æœ€å°è·ç¦»
        for i in range(len(trajectories)):
            for j in range(i + 1, len(trajectories)):
                traj1, traj2 = trajectories[i], trajectories[j]
                
                for state1 in traj1:
                    for state2 in traj2:
                        if abs(state1.t - state2.t) < 0.5:  # æ—¶é—´æ¥è¿‘
                            distance = math.sqrt((state1.x - state2.x)**2 + 
                                               (state1.y - state2.y)**2)
                            min_distance = min(min_distance, distance)
        
        # å®‰å…¨è¯„åˆ†ï¼šè·ç¦»è¶Šå¤§è¶Šå®‰å…¨
        safety_threshold = 4.0  # å®‰å…¨è·ç¦»é˜ˆå€¼
        if min_distance == float('inf'):
            return 1.0
        
        return min(1.0, min_distance / safety_threshold)
    
    def _evaluate_coordination_consistency(self, guidance_list: List) -> float:
        """è¯„ä¼°åè°ƒç­–ç•¥çš„ä¸€è‡´æ€§"""
        if not guidance_list:
            return 0.0
        
        # ç»Ÿè®¡ç­–ç•¥åˆ†å¸ƒ
        strategies = [g.strategy for g in guidance_list]
        strategy_counts = {}
        for strategy in strategies:
            strategy_counts[strategy] = strategy_counts.get(strategy, 0) + 1
        
        # è®¡ç®—ç­–ç•¥å¤šæ ·æ€§ (Shannonç†µ)
        total = len(strategies)
        entropy = 0.0
        for count in strategy_counts.values():
            if count > 0:
                p = count / total
                entropy -= p * math.log2(p)
        
        # å½’ä¸€åŒ–ç†µå€¼
        max_entropy = math.log2(min(5, total))  # æœ€å¤š5ç§ç­–ç•¥
        normalized_entropy = entropy / max_entropy if max_entropy > 0 else 0
        
        # ä¼˜å…ˆçº§åˆ†å¸ƒåˆç†æ€§
        priorities = [g.adjusted_priority for g in guidance_list]
        priority_std = np.std(priorities) if len(priorities) > 1 else 0
        priority_score = min(1.0, priority_std / 2.0)  # ä¼˜å…ˆçº§åº”è¯¥æœ‰ä¸€å®šå·®å¼‚
        
        return (normalized_entropy + priority_score) / 2.0

class VehicleGraphAugmentor:
    """è½¦è¾†å›¾å¢å¼ºå™¨ - ç”Ÿæˆå¯¹æ¯”å­¦ä¹ çš„ä¸åŒè§†å›¾"""
    
    def __init__(self, interaction_radius: float = 50.0):
        self.interaction_radius = interaction_radius
        
    def create_augmented_views(self, vehicles_info: List[Dict]) -> Tuple[List[Dict], List[Dict]]:
        """åˆ›å»ºä¸¤ä¸ªä¸åŒçš„å¢å¼ºè§†å›¾ç”¨äºå¯¹æ¯”å­¦ä¹ """
        
        # è§†å›¾1: ä½ç½®å™ªå£°å¢å¼º (æ¨¡æ‹Ÿæ„ŸçŸ¥è¯¯å·®)
        view1 = self._position_noise_augmentation(vehicles_info)
        
        # è§†å›¾2: é€Ÿåº¦æ—¶é—´å¢å¼º (æ¨¡æ‹ŸåŠ¨æ€å˜åŒ–)  
        view2 = self._velocity_time_augmentation(vehicles_info)
        
        return view1, view2
    
    def _position_noise_augmentation(self, vehicles_info: List[Dict]) -> List[Dict]:
        """ä½ç½®å™ªå£°å¢å¼º - æ¨¡æ‹ŸGPSå®šä½è¯¯å·®"""
        augmented = []
        
        for vehicle in vehicles_info:
            aug_vehicle = vehicle.copy()
            
            # ä¸ºå½“å‰ä½ç½®æ·»åŠ å°å¹…å™ªå£° (0.5-1.0ç±³)
            noise_x = random.uniform(-1.0, 1.0)
            noise_y = random.uniform(-1.0, 1.0)
            
            # åˆ›å»ºæ–°çš„çŠ¶æ€å‰¯æœ¬
            current_state = aug_vehicle['current_state']
            aug_current = type(current_state)(
                x=current_state.x + noise_x,
                y=current_state.y + noise_y,
                theta=current_state.theta,
                v=current_state.v,
                t=current_state.t
            )
            aug_vehicle['current_state'] = aug_current
            
            augmented.append(aug_vehicle)
        
        return augmented
    
    def _velocity_time_augmentation(self, vehicles_info: List[Dict]) -> List[Dict]:
        """é€Ÿåº¦å’Œæ—¶é—´å¢å¼º - æ¨¡æ‹ŸåŠ¨æ€å˜åŒ–"""
        augmented = []
        
        for vehicle in vehicles_info:
            aug_vehicle = vehicle.copy()
            
            # é€Ÿåº¦æ‰°åŠ¨ (Â±10%)
            velocity_factor = random.uniform(0.9, 1.1)
            
            # æ—¶é—´åç§» (Â±0.2ç§’)
            time_offset = random.uniform(-0.2, 0.2)
            
            current_state = aug_vehicle['current_state']
            aug_current = type(current_state)(
                x=current_state.x,
                y=current_state.y,
                theta=current_state.theta,
                v=current_state.v * velocity_factor,
                t=current_state.t + time_offset
            )
            aug_vehicle['current_state'] = aug_current
            
            augmented.append(aug_vehicle)
        
        return augmented

class GATContrastiveLearner:
    """GATå¯¹æ¯”å­¦ä¹ å™¨ - æ ¸å¿ƒè‡ªç›‘ç£å­¦ä¹ ç»„ä»¶"""
    
    def __init__(self, gat_network, graph_builder, temperature: float = 0.1):
        self.gat_network = gat_network
        self.graph_builder = graph_builder
        self.temperature = temperature
        self.augmentor = VehicleGraphAugmentor()
        
        # ä¼˜åŒ–å™¨
        self.optimizer = torch.optim.Adam(
            self.gat_network.parameters(), 
            lr=1e-4, weight_decay=1e-5
        )
        
        print("ğŸ§  GATå¯¹æ¯”å­¦ä¹ å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   æ¸©åº¦å‚æ•°: {temperature}")
        print(f"   å­¦ä¹ ç‡: 1e-4")
    
    def contrastive_learning_step(self, vehicles_info: List[Dict], 
                                 quality_scores: Dict[str, float]) -> Dict[str, float]:
        """æ‰§è¡Œä¸€æ­¥å¯¹æ¯”å­¦ä¹ """
        
        # 1. ç”Ÿæˆå¢å¼ºè§†å›¾
        view1, view2 = self.augmentor.create_augmented_views(vehicles_info)
        
        # 2. æ„å»ºå›¾æ•°æ®
        graph1 = self.graph_builder.build_graph(view1)
        graph2 = self.graph_builder.build_graph(view2)
        
        # 3. GATç¼–ç 
        self.gat_network.train()
        
        # å‰å‘ä¼ æ’­
        decisions1 = self.gat_network(graph1)
        decisions2 = self.gat_network(graph2)
        
        # 4. æå–è¡¨å¾å‘é‡
        repr1 = self._extract_representation(decisions1, graph1)
        repr2 = self._extract_representation(decisions2, graph2)
        
        # 5. è®¡ç®—å¯¹æ¯”æŸå¤±
        contrastive_loss = self._compute_contrastive_loss(repr1, repr2)
        
        # 6. è´¨é‡å¼•å¯¼æŸå¤± (åŸºäºå†å²ç»éªŒ)
        quality_loss = self._compute_quality_guided_loss(
            decisions1, quality_scores)
        
        # 7. æ€»æŸå¤±
        total_loss = contrastive_loss + 0.5 * quality_loss
        
        # 8. åå‘ä¼ æ’­
        self.optimizer.zero_grad()
        total_loss.backward()
        torch.nn.utils.clip_grad_norm_(self.gat_network.parameters(), 1.0)
        self.optimizer.step()
        
        return {
            'total_loss': total_loss.item(),
            'contrastive_loss': contrastive_loss.item(),
            'quality_loss': quality_loss.item()
        }
    
    def _extract_representation(self, decisions, graph_data) -> torch.Tensor:
        """ä»GATå†³ç­–ä¸­æå–è¡¨å¾å‘é‡"""
        
        # å°†å¤šä»»åŠ¡è¾“å‡ºåˆå¹¶ä¸ºç»Ÿä¸€è¡¨å¾
        priority_repr = decisions.priority_adjustments.flatten()
        cooperation_repr = decisions.cooperation_scores.flatten()  
        urgency_repr = decisions.urgency_levels.flatten()
        safety_repr = decisions.safety_factors.flatten()
        strategy_repr = decisions.strategies.flatten()
        global_repr = decisions.global_signal
        
        # æ‹¼æ¥æ‰€æœ‰è¡¨å¾
        combined_repr = torch.cat([
            priority_repr, cooperation_repr, urgency_repr, 
            safety_repr, strategy_repr, global_repr
        ], dim=0)
        
        return combined_repr
    
    def _compute_contrastive_loss(self, repr1: torch.Tensor, 
                                 repr2: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—å¯¹æ¯”æŸå¤± - åŸºäºInfoNCE"""
        
        # L2æ ‡å‡†åŒ–
        repr1_norm = F.normalize(repr1, dim=0)
        repr2_norm = F.normalize(repr2, dim=0)
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarity = torch.dot(repr1_norm, repr2_norm) / self.temperature
        
        # ç”±äºæˆ‘ä»¬åªæœ‰æ­£æ ·æœ¬å¯¹ï¼Œä½¿ç”¨ç®€åŒ–çš„å¯¹æ¯”æŸå¤±
        # ç›®æ ‡ï¼šæœ€å¤§åŒ–ä¸¤ä¸ªè§†å›¾é—´çš„ç›¸ä¼¼åº¦
        contrastive_loss = -similarity + torch.log(torch.exp(similarity) + 1)
        
        return contrastive_loss
    
    def _compute_quality_guided_loss(self, decisions, 
                                   quality_scores: Dict[str, float]) -> torch.Tensor:
        """åŸºäºè´¨é‡è¯„åˆ†çš„å¼•å¯¼æŸå¤±"""
        
        if not quality_scores:
            return torch.tensor(0.0)
        
        overall_quality = quality_scores.get('overall_quality', 0.5)
        
        # å¦‚æœè´¨é‡é«˜ï¼Œé¼“åŠ±å½“å‰å†³ç­–ï¼›å¦‚æœè´¨é‡ä½ï¼Œæƒ©ç½šå½“å‰å†³ç­–
        quality_target = torch.tensor(overall_quality)
        
        # è®¡ç®—å†³ç­–çš„"æ¿€è¿›ç¨‹åº¦" - ä½œä¸ºè´¨é‡çš„ä»£ç†æŒ‡æ ‡
        priority_variance = torch.var(decisions.priority_adjustments)
        cooperation_mean = torch.mean(decisions.cooperation_scores)
        
        decision_intensity = priority_variance + (1.0 - cooperation_mean)
        
        # è´¨é‡å¼•å¯¼æŸå¤±ï¼šé«˜è´¨é‡æ—¶é¼“åŠ±é€‚ä¸­çš„å†³ç­–å¼ºåº¦
        if overall_quality > 0.7:
            # é«˜è´¨é‡ï¼šé¼“åŠ±é€‚ä¸­å†³ç­–
            target_intensity = 0.3
        elif overall_quality > 0.4:
            # ä¸­ç­‰è´¨é‡ï¼šä¿æŒå½“å‰æ°´å¹³
            target_intensity = decision_intensity.detach()
        else:
            # ä½è´¨é‡ï¼šé¼“åŠ±æ›´ä¿å®ˆçš„å†³ç­–
            target_intensity = 0.1
        
        quality_loss = F.mse_loss(decision_intensity, 
                                torch.tensor(target_intensity))
        
        return quality_loss

class ExperienceBuffer:
    """ç»éªŒç¼“å†²åŒº - å­˜å‚¨å’Œç®¡ç†GATè§„åˆ’ç»éªŒ"""
    
    def __init__(self, max_size: int = 1000):
        self.max_size = max_size
        self.experiences = deque(maxlen=max_size)
        self.quality_stats = {
            'mean_quality': 0.0,
            'std_quality': 0.0,
            'best_quality': 0.0,
            'worst_quality': 1.0
        }
        
        print(f"ğŸ“š ç»éªŒç¼“å†²åŒºåˆå§‹åŒ–: æœ€å¤§å®¹é‡ {max_size}")
    
    def add_experience(self, experience: GATPlanningExperience):
        """æ·»åŠ æ–°çš„è§„åˆ’ç»éªŒ"""
        self.experiences.append(experience)
        self._update_quality_stats()
        
        print(f"   ğŸ“ æ–°å¢ç»éªŒ: è´¨é‡ {experience.coordination_quality:.3f}, "
              f"æˆåŠŸç‡ {experience.success_rate:.1%}, "
              f"ç¼“å†²åŒºå¤§å° {len(self.experiences)}")
    
    def get_high_quality_experiences(self, top_k: int = 50) -> List[GATPlanningExperience]:
        """è·å–é«˜è´¨é‡ç»éªŒ"""
        if not self.experiences:
            return []
        
        sorted_experiences = sorted(self.experiences, 
                                  key=lambda x: x.coordination_quality, 
                                  reverse=True)
        return sorted_experiences[:top_k]
    
    def get_diverse_experiences(self, num_samples: int = 20) -> List[GATPlanningExperience]:
        """è·å–å¤šæ ·åŒ–ç»éªŒæ ·æœ¬"""
        if not self.experiences:
            return []
        
        # æŒ‰è´¨é‡åˆ†å±‚é‡‡æ ·
        high_quality = [exp for exp in self.experiences if exp.coordination_quality > 0.7]
        medium_quality = [exp for exp in self.experiences if 0.4 <= exp.coordination_quality <= 0.7]
        low_quality = [exp for exp in self.experiences if exp.coordination_quality < 0.4]
        
        samples = []
        
        # åˆ†å±‚é‡‡æ ·
        if high_quality:
            samples.extend(random.sample(high_quality, min(num_samples//3, len(high_quality))))
        if medium_quality:
            samples.extend(random.sample(medium_quality, min(num_samples//3, len(medium_quality))))
        if low_quality:
            samples.extend(random.sample(low_quality, min(num_samples//3, len(low_quality))))
        
        # è¡¥å……éšæœºæ ·æœ¬
        remaining = num_samples - len(samples)
        if remaining > 0:
            all_samples = list(self.experiences)
            additional = random.sample(all_samples, min(remaining, len(all_samples)))
            samples.extend(additional)
        
        return samples[:num_samples]
    
    def _update_quality_stats(self):
        """æ›´æ–°è´¨é‡ç»Ÿè®¡ä¿¡æ¯"""
        if not self.experiences:
            return
        
        qualities = [exp.coordination_quality for exp in self.experiences]
        self.quality_stats = {
            'mean_quality': np.mean(qualities),
            'std_quality': np.std(qualities),
            'best_quality': np.max(qualities),
            'worst_quality': np.min(qualities),
            'count': len(qualities)
        }

class GATSelfSupervisedTrainer:
    """ğŸ¯ GATè‡ªç›‘ç£å­¦ä¹ è®­ç»ƒå™¨ - ä¸»è¦æ¥å£"""
    
    def __init__(self, gat_network, graph_builder, environment):
        self.gat_network = gat_network
        self.graph_builder = graph_builder
        self.environment = environment
        
        # æ ¸å¿ƒç»„ä»¶
        self.quality_evaluator = TrajectoryQualityEvaluator(environment)
        self.contrastive_learner = GATContrastiveLearner(gat_network, graph_builder)
        self.experience_buffer = ExperienceBuffer(max_size=1000)
        
        # è®­ç»ƒç»Ÿè®¡
        self.training_stats = {
            'total_episodes': 0,
            'training_steps': 0,
            'avg_loss': 0.0,
            'learning_rate': 1e-4
        }
        
        print("ğŸš€ GATè‡ªç›‘ç£è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
        print("   ğŸ¯ æ ¸å¿ƒåŠŸèƒ½:")
        print("     - å¯¹æ¯”å­¦ä¹  (å¤šè§†å›¾å¢å¼º)")
        print("     - è´¨é‡å¼•å¯¼å­¦ä¹  (æˆåŠŸæ¡ˆä¾‹å­¦ä¹ )")
        print("     - ç»éªŒå›æ”¾ (å†å²ç»éªŒåˆ©ç”¨)")
        print("     - è‡ªé€‚åº”ä¼˜åŒ– (åŠ¨æ€è°ƒæ•´)")
    
    def record_planning_experience(self, vehicles_info: List[Dict], 
                                 gat_decisions, guidance_list: List,
                                 planning_results: Dict, 
                                 planning_time: float,
                                 map_name: str):
        """è®°å½•ä¸€æ¬¡å®Œæ•´çš„è§„åˆ’ç»éªŒ"""
        
        # è¯„ä¼°åè°ƒè´¨é‡
        quality_metrics = self.quality_evaluator.evaluate_coordination_quality(
            planning_results, vehicles_info, guidance_list)
        
        # åˆ›å»ºç»éªŒè®°å½•
        experience = GATPlanningExperience(
            graph_data=self.graph_builder.build_graph(vehicles_info).__dict__,
            vehicles_info=vehicles_info,
            gat_decisions=gat_decisions.__dict__ if hasattr(gat_decisions, '__dict__') else gat_decisions,
            guidance_list=guidance_list,
            planning_results={vid: bool(result.get('trajectory')) for vid, result in planning_results.items()},
            success_rate=quality_metrics['success_rate'],
            planning_time=planning_time,
            conflict_count=0,  # TODO: å®ç°å†²çªè®¡æ•°
            coordination_quality=quality_metrics['overall_quality'],
            efficiency_score=quality_metrics['efficiency_score'],
            safety_score=quality_metrics['safety_score'],
            timestamp=time.time(),
            map_name=map_name
        )
        
        # å­˜å‚¨ç»éªŒ
        self.experience_buffer.add_experience(experience)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è®­ç»ƒ
        if len(self.experience_buffer.experiences) >= 10:  # ç´¯ç§¯è¶³å¤Ÿç»éªŒåå¼€å§‹è®­ç»ƒ
            self._perform_training_step()
    
    def _perform_training_step(self):
        """æ‰§è¡Œä¸€æ­¥è®­ç»ƒ"""
        
        # è·å–å¤šæ ·åŒ–è®­ç»ƒæ ·æœ¬
        training_samples = self.experience_buffer.get_diverse_experiences(num_samples=5)
        
        if not training_samples:
            return
        
        total_loss = 0.0
        
        for sample in training_samples:
            # ä½¿ç”¨ç»éªŒä¸­çš„è½¦è¾†ä¿¡æ¯è¿›è¡Œå¯¹æ¯”å­¦ä¹ 
            quality_scores = {
                'overall_quality': sample.coordination_quality,
                'efficiency_score': sample.efficiency_score,
                'safety_score': sample.safety_score
            }
            
            loss_info = self.contrastive_learner.contrastive_learning_step(
                sample.vehicles_info, quality_scores)
            
            total_loss += loss_info['total_loss']
        
        # æ›´æ–°è®­ç»ƒç»Ÿè®¡
        self.training_stats['training_steps'] += 1
        self.training_stats['avg_loss'] = (self.training_stats['avg_loss'] * 0.9 + 
                                          (total_loss / len(training_samples)) * 0.1)
        
        if self.training_stats['training_steps'] % 10 == 0:
            self._print_training_progress()
    
    def _print_training_progress(self):
        """æ‰“å°è®­ç»ƒè¿›åº¦"""
        stats = self.training_stats
        buffer_stats = self.experience_buffer.quality_stats
        
        print(f"\nğŸ§  GATè‡ªç›‘ç£å­¦ä¹ è¿›åº¦:")
        print(f"   è®­ç»ƒæ­¥æ•°: {stats['training_steps']}")
        print(f"   å¹³å‡æŸå¤±: {stats['avg_loss']:.4f}")
        print(f"   ç»éªŒæ•°é‡: {buffer_stats.get('count', 0)}")
        print(f"   å¹³å‡è´¨é‡: {buffer_stats.get('mean_quality', 0):.3f}")
        print(f"   æœ€ä½³è´¨é‡: {buffer_stats.get('best_quality', 0):.3f}")
    
    def save_model(self, filepath: str):
        """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹"""
        checkpoint = {
            'gat_network_state': self.gat_network.state_dict(),
            'optimizer_state': self.contrastive_learner.optimizer.state_dict(),
            'training_stats': self.training_stats,
            'buffer_stats': self.experience_buffer.quality_stats
        }
        
        torch.save(checkpoint, filepath)
        print(f"ğŸ’¾ GATæ¨¡å‹å·²ä¿å­˜: {filepath}")
    
    def load_model(self, filepath: str):
        """åŠ è½½é¢„è®­ç»ƒæ¨¡å‹"""
        try:
            checkpoint = torch.load(filepath)
            self.gat_network.load_state_dict(checkpoint['gat_network_state'])
            self.contrastive_learner.optimizer.load_state_dict(checkpoint['optimizer_state'])
            self.training_stats = checkpoint.get('training_stats', self.training_stats)
            
            print(f"âœ… GATæ¨¡å‹å·²åŠ è½½: {filepath}")
            print(f"   è®­ç»ƒæ­¥æ•°: {self.training_stats.get('training_steps', 0)}")
            print(f"   å¹³å‡æŸå¤±: {self.training_stats.get('avg_loss', 0):.4f}")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    
    def get_learning_summary(self) -> Dict:
        """è·å–å­¦ä¹ æ€»ç»“"""
        return {
            'training_stats': self.training_stats,
            'buffer_stats': self.experience_buffer.quality_stats,
            'model_info': {
                'total_parameters': sum(p.numel() for p in self.gat_network.parameters()),
                'trainable_parameters': sum(p.numel() for p in self.gat_network.parameters() if p.requires_grad)
            }
        }

def create_gat_self_supervised_system(gat_network, graph_builder, environment):
    """åˆ›å»ºå®Œæ•´çš„GATè‡ªç›‘ç£å­¦ä¹ ç³»ç»Ÿ"""
    
    trainer = GATSelfSupervisedTrainer(gat_network, graph_builder, environment)
    
    print("ğŸ‰ GATè‡ªç›‘ç£å­¦ä¹ ç³»ç»Ÿåˆ›å»ºå®Œæˆï¼")
    print("\nğŸ¯ ä½¿ç”¨æ–¹æ³•:")
    print("1. åœ¨æ¯æ¬¡è§„åˆ’åè°ƒç”¨ trainer.record_planning_experience()")
    print("2. ç³»ç»Ÿä¼šè‡ªåŠ¨è¿›è¡Œå¯¹æ¯”å­¦ä¹ å’Œè´¨é‡å¼•å¯¼å­¦ä¹ ")
    print("3. å®šæœŸè°ƒç”¨ trainer.save_model() ä¿å­˜å­¦ä¹ è¿›åº¦")
    print("4. ä½¿ç”¨ trainer.load_model() åŠ è½½é¢„è®­ç»ƒæ¨¡å‹")
    
    print("\nğŸ“š å­¦ä¹ ç­–ç•¥:")
    print("   ğŸ”„ å¯¹æ¯”å­¦ä¹ : ä»ä¸åŒè§†å›¾å­¦ä¹ é²æ£’è¡¨å¾")
    print("   ğŸ¯ è´¨é‡å¼•å¯¼: ä»æˆåŠŸæ¡ˆä¾‹å­¦ä¹ ä¼˜ç§€ç­–ç•¥")
    print("   ğŸ“ˆ ç»éªŒå›æ”¾: åˆ©ç”¨å†å²ç»éªŒæŒç»­æ”¹è¿›")
    print("   ğŸš€ è‡ªé€‚åº”: æ ¹æ®è§„åˆ’è´¨é‡åŠ¨æ€è°ƒæ•´")
    
    return trainer

# ========================================
# é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿä¸­çš„ç¤ºä¾‹
# ========================================

def integrate_self_supervised_learning_example():
    """é›†æˆè‡ªç›‘ç£å­¦ä¹ åˆ°ç°æœ‰GATç³»ç»Ÿçš„ç¤ºä¾‹"""
    
    print("\nğŸ”§ é›†æˆç¤ºä¾‹:")
    print("""
    # åœ¨ EnhancedFirstRoundPlanner ä¸­é›†æˆè‡ªç›‘ç£å­¦ä¹ 
    
    class EnhancedFirstRoundPlanner:
        def __init__(self, ...):
            # ... ç°æœ‰åˆå§‹åŒ–ä»£ç  ...
            
            # ğŸ†• æ·»åŠ è‡ªç›‘ç£å­¦ä¹ ç»„ä»¶
            if self.enable_gat:
                self.gat_trainer = create_gat_self_supervised_system(
                    self.gat_network, 
                    self.graph_builder, 
                    self.environment
                )
                
                # å°è¯•åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
                model_path = f"gat_model_{self.map_data.get('map_info', {}).get('name', 'default')}.pt"
                if os.path.exists(model_path):
                    self.gat_trainer.load_model(model_path)
        
        def plan_all_vehicles(self):
            # ... ç°æœ‰è§„åˆ’ä»£ç  ...
            
            # ğŸ†• è®°å½•è§„åˆ’ç»éªŒç”¨äºå­¦ä¹ 
            if self.enable_gat and hasattr(self, 'gat_trainer'):
                vehicles_info = self._convert_vehicles_to_gat_format()
                
                # è·å–GATå†³ç­–å’ŒæŒ‡å¯¼
                graph_data = self.graph_builder.build_graph(vehicles_info)
                gat_decisions = self.gat_network(graph_data)
                guidance_list = self.decision_parser.parse_decisions(gat_decisions, vehicles_info)
                
                # æ”¶é›†è§„åˆ’ç»“æœ
                planning_results = {}
                for vehicle in self.vehicles:
                    planning_results[vehicle.vehicle_id] = {
                        'trajectory': vehicle.trajectory,
                        'planning_time': vehicle.planning_time
                    }
                
                # ğŸ¯ è®°å½•ç»éªŒï¼Œè§¦å‘è‡ªç›‘ç£å­¦ä¹ 
                self.gat_trainer.record_planning_experience(
                    vehicles_info=vehicles_info,
                    gat_decisions=gat_decisions,
                    guidance_list=guidance_list,
                    planning_results=planning_results,
                    planning_time=total_planning_time,
                    map_name=self.environment.map_name
                )
                
                # å®šæœŸä¿å­˜æ¨¡å‹
                if len(self.gat_trainer.experience_buffer.experiences) % 50 == 0:
                    self.gat_trainer.save_model(model_path)
                    print(f"ğŸ“ GATæ¨¡å‹å­¦ä¹ è¿›åº¦å·²ä¿å­˜")
    """)

if __name__ == "__main__":
    print("ğŸ§  GATè‡ªç›‘ç£å­¦ä¹ ç³»ç»Ÿ")
    print("=" * 60)
    print("åŸºäºæœ€æ–°GNNè‡ªç›‘ç£å­¦ä¹ ç ”ç©¶ï¼Œä¸“ä¸ºå¤šè½¦åè°ƒè®¾è®¡")
    print("\næ ¸å¿ƒç‰¹æ€§:")
    print("âœ… å¯¹æ¯”å­¦ä¹  - ä»å¤šè§†å›¾ä¸­å­¦ä¹ é²æ£’åè°ƒç­–ç•¥")
    print("âœ… è´¨é‡å¼•å¯¼ - ä»æˆåŠŸæ¡ˆä¾‹ä¸­å­¦ä¹ ä¼˜ç§€å†³ç­–")
    print("âœ… ç»éªŒå›æ”¾ - åˆ©ç”¨å†å²æ•°æ®æŒç»­æ”¹è¿›")
    print("âœ… è‡ªé€‚åº”å­¦ä¹  - æ ¹æ®è§„åˆ’è´¨é‡åŠ¨æ€è°ƒæ•´")
    print("âœ… é›¶äººå·¥æ ‡æ³¨ - å®Œå…¨è‡ªç›‘ç£å­¦ä¹ ")
    
    integrate_self_supervised_learning_example()