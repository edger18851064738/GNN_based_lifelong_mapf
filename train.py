#!/usr/bin/env python3
"""
ğŸ›¡ï¸ è·¯å£GNNé¢„è®­ç»ƒç³»ç»Ÿ - æ”¯æŒintersection_edgesæ ¼å¼
ä¸“é—¨ä¸ºlifelong_planning.pyçš„è·¯å£åœºæ™¯è®¾è®¡

ä¸»è¦ç‰¹æ€§:
âœ… æ”¯æŒintersection_edgesåœ°å›¾æ ¼å¼
âœ… ç”Ÿæˆè·¯å£å†²çªæ¿€çƒˆåœºæ™¯
âœ… æ¯æ¡è¾¹ä¸€ä¸ªä»»åŠ¡çš„è®­ç»ƒæ•°æ®
âœ… å®‰å…¨æ„ŸçŸ¥çš„è·¯å£æ ‡ç­¾ç”Ÿæˆ
âœ… å…¼å®¹lifelong_planning.pyçš„ç‰¹å¾ç»´åº¦
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch_geometric.nn as pyg_nn
from torch_geometric.data import Data, DataLoader, Batch
from torch.utils.data import Dataset
import numpy as np
import math
import json
import os
from typing import List, Dict, Tuple
from dataclasses import dataclass
import time
from tqdm import tqdm
import random

# å¯¼å…¥åŸºç¡€ç»„ä»¶
try:
    from trying import UnstructuredEnvironment, VehicleState, VehicleParameters
    HAS_TRYING = True
    print("âœ… æˆåŠŸå¯¼å…¥trying.pyç¯å¢ƒç»„ä»¶")
except ImportError:
    HAS_TRYING = False
    print("âš ï¸ æ— æ³•å¯¼å…¥trying.pyï¼Œå°†ä½¿ç”¨ç®€åŒ–å®ç°")
    
    @dataclass
    class VehicleState:
        x: float
        y: float
        theta: float
        v: float
        t: float
    
    class VehicleParameters:
        def __init__(self):
            self.max_speed = 8.0
            self.max_accel = 2.0
            self.length = 4.0
            self.width = 2.0
    
    class UnstructuredEnvironment:
        def __init__(self, size=100):
            self.size = size
            self.obstacle_map = np.zeros((size, size), dtype=bool)
        
        def is_valid_position(self, x, y):
            ix, iy = int(round(x)), int(round(y))
            if 0 <= ix < self.size and 0 <= iy < self.size:
                return not self.obstacle_map[iy, ix]
            return False

# å¯¼å…¥lifelongç»„ä»¶
try:
    from lifelong_planning import IntersectionEdge, Task, Vehicle
    HAS_LIFELONG = True
    print("âœ… æˆåŠŸå¯¼å…¥lifelong_planning.pyç»„ä»¶")
except ImportError:
    HAS_LIFELONG = False
    print("âš ï¸ å°†ä½¿ç”¨å†…ç½®è·¯å£ç»„ä»¶")
    
    @dataclass
    class IntersectionEdge:
        edge_id: str
        center_x: int
        center_y: int
        length: int = 5
        direction: str = ""
        
        def get_random_integer_position(self) -> Tuple[int, int]:
            return (self.center_x, self.center_y)
    
    @dataclass
    class Task:
        task_id: int
        start_edge: IntersectionEdge
        end_edge: IntersectionEdge
        start_pos: Tuple[int, int]
        end_pos: Tuple[int, int]
        priority: int = 1
    
    @dataclass
    class Vehicle:
        vehicle_id: int
        task: Task
        trajectory: List[VehicleState] = None
        color: str = "blue"

@dataclass
class IntersectionTrainingConfig:
    """ğŸ›¡ï¸ è·¯å£è®­ç»ƒé…ç½®"""
    batch_size: int = 4
    learning_rate: float = 0.0008
    num_epochs: int = 40
    hidden_dim: int = 64
    num_layers: int = 3
    dropout: float = 0.15
    weight_decay: float = 1e-4
    
    # ğŸ†• è·¯å£åœºæ™¯é…ç½®
    num_scenarios: int = 2000
    num_map_variants: int = 8
    max_vehicles_per_scenario: int = 8
    min_vehicles_per_scenario: int = 3
    
    # ğŸ›¡ï¸ å®‰å…¨ç›¸å…³é…ç½®
    min_safe_distance: float = 8.0
    safety_priority_weight: float = 1.8  # è·¯å£å®‰å…¨æƒé‡æ›´é«˜
    high_conflict_ratio: float = 0.4     # 40%é«˜å†²çªåœºæ™¯
    
    # éªŒè¯é…ç½®
    val_split: float = 0.2
    early_stopping_patience: int = 10

class IntersectionMapGenerator:
    """è·¯å£åœ°å›¾ç”Ÿæˆå™¨"""
    
    def __init__(self, config: IntersectionTrainingConfig):
        self.config = config
        self.real_maps = []
        self.synthetic_maps = []
        
        print("ğŸ—ºï¸ åˆå§‹åŒ–è·¯å£åœ°å›¾ç”Ÿæˆå™¨...")
        self._scan_intersection_maps()
        self._generate_synthetic_intersection_maps()
    
    def _scan_intersection_maps(self):
        """æ‰«æçœŸå®è·¯å£åœ°å›¾"""
        print("ğŸ” æ‰«æè·¯å£åœ°å›¾æ–‡ä»¶...")
        
        json_files = [f for f in os.listdir('.') if f.endswith('.json')]
        intersection_files = [f for f in json_files if any(keyword in f.lower() 
                            for keyword in ['lifelong', 'intersection', 'cross', 'junction'])]
        
        for json_file in intersection_files:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    map_data = json.load(f)
                
                # éªŒè¯æ˜¯å¦ä¸ºè·¯å£åœ°å›¾
                if 'intersection_edges' in map_data and map_data['intersection_edges']:
                    env = UnstructuredEnvironment(size=100)
                    if hasattr(env, 'load_from_json'):
                        success = env.load_from_json(json_file)
                        if success:
                            self.real_maps.append({
                                'name': json_file,
                                'environment': env,
                                'data': map_data
                            })
                            print(f"  âœ… åŠ è½½è·¯å£åœ°å›¾: {json_file}")
                    
            except Exception as e:
                continue
        
        print(f"ğŸ“Š å‘ç° {len(self.real_maps)} ä¸ªè·¯å£åœ°å›¾æ–‡ä»¶")
    
    def _generate_synthetic_intersection_maps(self):
        """ç”Ÿæˆåˆæˆè·¯å£åœ°å›¾"""
        print(f"ğŸ—ï¸ ç”Ÿæˆ {self.config.num_map_variants} ç§åˆæˆè·¯å£åœ°å›¾...")
        
        for i in range(self.config.num_map_variants):
            map_data = self._create_synthetic_intersection(i)
            env = UnstructuredEnvironment(size=100)
            
            # è®¾ç½®éšœç¢ç‰©
            if 'grid' in map_data:
                grid = np.array(map_data['grid'])
                for row in range(min(grid.shape[0], env.size)):
                    for col in range(min(grid.shape[1], env.size)):
                        if grid[row, col] == 1:
                            env.obstacle_map[row, col] = True
            
            self.synthetic_maps.append({
                'name': f"synthetic_intersection_{i}",
                'environment': env,
                'data': map_data
            })
        
        print(f"âœ… ç”Ÿæˆäº† {len(self.synthetic_maps)} ä¸ªåˆæˆè·¯å£åœ°å›¾")
    
    def _create_synthetic_intersection(self, variant_id: int) -> Dict:
        """åˆ›å»ºåˆæˆè·¯å£åœ°å›¾"""
        # åŸºäºvariant_idåˆ›å»ºä¸åŒç±»å‹çš„è·¯å£
        intersection_types = ['four_way', 'three_way', 'complex', 'roundabout']
        intersection_type = intersection_types[variant_id % len(intersection_types)]
        
        # åŸºç¡€åœ°å›¾ä¿¡æ¯
        map_data = {
            "map_info": {
                "name": f"synthetic_intersection_{variant_id}",
                "width": 100,
                "height": 100,
                "type": intersection_type
            },
            "intersection_edges": [],
            "grid": np.zeros((100, 100), dtype=int).tolist()
        }
        
        if intersection_type == 'four_way':
            # å››å‘è·¯å£
            edges = [
                {"edge_id": "N", "center_x": 50, "center_y": 10, "direction": "north", "length": 8},
                {"edge_id": "S", "center_x": 50, "center_y": 90, "direction": "south", "length": 8},
                {"edge_id": "E", "center_x": 90, "center_y": 50, "direction": "east", "length": 8},
                {"edge_id": "W", "center_x": 10, "center_y": 50, "direction": "west", "length": 8}
            ]
            # æ·»åŠ ä¸­å¤®éšœç¢ç‰©
            for x in range(45, 56):
                for y in range(45, 56):
                    map_data["grid"][y][x] = 1
                    
        elif intersection_type == 'three_way':
            # Tå‹è·¯å£
            edges = [
                {"edge_id": "N", "center_x": 50, "center_y": 15, "direction": "north", "length": 10},
                {"edge_id": "E", "center_x": 85, "center_y": 50, "direction": "east", "length": 10},
                {"edge_id": "W", "center_x": 15, "center_y": 50, "direction": "west", "length": 10}
            ]
            # æ·»åŠ éšœç¢ç‰©
            for x in range(40, 61):
                for y in range(60, 80):
                    map_data["grid"][y][x] = 1
                    
        elif intersection_type == 'complex':
            # å¤æ‚è·¯å£
            edges = [
                {"edge_id": "N1", "center_x": 40, "center_y": 10, "direction": "north", "length": 6},
                {"edge_id": "N2", "center_x": 60, "center_y": 10, "direction": "north", "length": 6},
                {"edge_id": "S", "center_x": 50, "center_y": 90, "direction": "south", "length": 8},
                {"edge_id": "E", "center_x": 90, "center_y": 50, "direction": "east", "length": 8},
                {"edge_id": "W", "center_x": 10, "center_y": 50, "direction": "west", "length": 8}
            ]
            # å¤æ‚éšœç¢ç‰©å¸ƒå±€
            for x in range(30, 35):
                for y in range(30, 70):
                    map_data["grid"][y][x] = 1
            for x in range(65, 70):
                for y in range(30, 70):
                    map_data["grid"][y][x] = 1
                    
        else:  # roundabout
            # ç¯å²›
            edges = [
                {"edge_id": "N", "center_x": 50, "center_y": 20, "direction": "north", "length": 6},
                {"edge_id": "S", "center_x": 50, "center_y": 80, "direction": "south", "length": 6},
                {"edge_id": "E", "center_x": 80, "center_y": 50, "direction": "east", "length": 6},
                {"edge_id": "W", "center_x": 20, "center_y": 50, "direction": "west", "length": 6}
            ]
            # ä¸­å¤®åœ†å½¢éšœç¢ç‰©
            center_x, center_y = 50, 50
            radius = 12
            for x in range(100):
                for y in range(100):
                    if (x - center_x)**2 + (y - center_y)**2 <= radius**2:
                        map_data["grid"][y][x] = 1
        
        map_data["intersection_edges"] = edges
        return map_data
    
    def get_random_intersection_map(self) -> Tuple[UnstructuredEnvironment, Dict, str]:
        """è·å–éšæœºè·¯å£åœ°å›¾"""
        all_maps = self.real_maps + self.synthetic_maps
        
        if not all_maps:
            # åˆ›å»ºæœ€ç®€å•çš„é»˜è®¤è·¯å£
            default_map = self._create_synthetic_intersection(0)
            env = UnstructuredEnvironment(size=100)
            return env, default_map, "default_intersection"
        
        selected = random.choice(all_maps)
        return selected['environment'], selected['data'], selected['name']

class IntersectionVehicleScenarioGenerator:
    """è·¯å£è½¦è¾†åœºæ™¯ç”Ÿæˆå™¨"""
    
    def __init__(self, config: IntersectionTrainingConfig):
        self.config = config
        self.map_generator = IntersectionMapGenerator(config)
        
    def generate_training_data(self) -> List[Tuple]:
        """ç”Ÿæˆè·¯å£è®­ç»ƒæ•°æ®"""
        print(f"ğŸ›¡ï¸ ç”Ÿæˆ {self.config.num_scenarios} ä¸ªè·¯å£è®­ç»ƒåœºæ™¯...")
        
        data_list = []
        failed_scenarios = 0
        
        # åˆ†é…é«˜å†²çªå’Œæ™®é€šåœºæ™¯
        num_high_conflict = int(self.config.num_scenarios * self.config.high_conflict_ratio)
        num_normal = self.config.num_scenarios - num_high_conflict
        
        print(f"ğŸ“Š åœºæ™¯åˆ†é…: {num_high_conflict} é«˜å†²çª + {num_normal} æ™®é€šåœºæ™¯")
        
        for i in tqdm(range(self.config.num_scenarios)):
            try:
                # è·å–éšæœºè·¯å£åœ°å›¾
                environment, map_data, map_name = self.map_generator.get_random_intersection_map()
                
                # ç”Ÿæˆè½¦è¾†åœºæ™¯
                is_high_conflict = i < num_high_conflict
                vehicles = self._generate_intersection_vehicles(map_data, is_high_conflict)
                
                if not vehicles:
                    failed_scenarios += 1
                    continue
                
                # æ„å»ºå›¾æ•°æ®
                graph_data = self._build_intersection_graph(vehicles, environment)
                
                if graph_data.x.size(0) == 0:
                    failed_scenarios += 1
                    continue
                
                # ç”Ÿæˆè·¯å£å®‰å…¨æ ‡ç­¾
                labels = self._generate_intersection_safety_labels(vehicles, map_data)
                
                # éªŒè¯æ•°æ®ä¸€è‡´æ€§
                if self._validate_data_consistency(graph_data, labels, len(vehicles)):
                    data_list.append((graph_data, labels))
                else:
                    failed_scenarios += 1
                
            except Exception as e:
                failed_scenarios += 1
                if i < 10:
                    print(f"âš ï¸ ç”Ÿæˆåœºæ™¯ {i} æ—¶å‡ºé”™: {str(e)}")
                continue
        
        print(f"âœ… æˆåŠŸç”Ÿæˆ {len(data_list)} ä¸ªè·¯å£è®­ç»ƒåœºæ™¯")
        print(f"ğŸ“Š ç»Ÿè®¡: æˆåŠŸ {len(data_list)}, å¤±è´¥ {failed_scenarios}")
        
        return data_list
    
    def _generate_intersection_vehicles(self, map_data: Dict, is_high_conflict: bool) -> List[Vehicle]:
        """ç”Ÿæˆè·¯å£è½¦è¾†åœºæ™¯"""
        edges_data = map_data.get("intersection_edges", [])
        if not edges_data:
            return []
        
        # åˆ›å»ºè·¯å£è¾¹å¯¹è±¡
        edges = []
        for edge_data in edges_data:
            edge = IntersectionEdge(
                edge_id=edge_data["edge_id"],
                center_x=edge_data["center_x"],
                center_y=edge_data["center_y"],
                length=edge_data.get("length", 5),
                direction=edge_data.get("direction", "")
            )
            edges.append(edge)
        
        if len(edges) < 2:
            return []
        
        vehicles = []
        
        if is_high_conflict:
            # é«˜å†²çªåœºæ™¯ï¼šæ¯æ¡è¾¹éƒ½æœ‰è½¦è¾†ï¼Œå¢åŠ å¯¹è§’çº¿å†²çª
            for i, start_edge in enumerate(edges):
                # é€‰æ‹©å†²çªç›®æ ‡è¾¹
                if len(edges) >= 4:
                    # ä¼˜å…ˆé€‰æ‹©å¯¹è§’çº¿è¾¹
                    target_edges = [e for e in edges if e.edge_id != start_edge.edge_id]
                    if len(target_edges) >= 2:
                        end_edge = target_edges[i % len(target_edges)]
                    else:
                        end_edge = random.choice(target_edges)
                else:
                    # è¾¹æ•°è¾ƒå°‘æ—¶éšæœºé€‰æ‹©
                    others = [e for e in edges if e.edge_id != start_edge.edge_id]
                    end_edge = random.choice(others)
                
                task = Task(
                    task_id=i + 1,
                    start_edge=start_edge,
                    end_edge=end_edge,
                    start_pos=start_edge.get_random_integer_position(),
                    end_pos=end_edge.get_random_integer_position(),
                    priority=random.randint(2, 5)  # é«˜ä¼˜å…ˆçº§èŒƒå›´
                )
                
                vehicle = Vehicle(
                    vehicle_id=i + 1,
                    task=task,
                    color='red'
                )
                vehicles.append(vehicle)
                
            # é¢å¤–æ·»åŠ ä¸€äº›æ±‡èšè½¦è¾†
            if len(edges) >= 3:
                target_edge = random.choice(edges)
                source_edges = [e for e in edges if e.edge_id != target_edge.edge_id][:2]
                
                for j, source_edge in enumerate(source_edges):
                    task = Task(
                        task_id=len(vehicles) + j + 1,
                        start_edge=source_edge,
                        end_edge=target_edge,
                        start_pos=source_edge.get_random_integer_position(),
                        end_pos=target_edge.get_random_integer_position(),
                        priority=random.randint(1, 4)
                    )
                    
                    vehicle = Vehicle(
                        vehicle_id=len(vehicles) + j + 1,
                        task=task,
                        color='orange'
                    )
                    vehicles.append(vehicle)
        
        else:
            # æ™®é€šåœºæ™¯ï¼šé€‚åº¦æ•°é‡çš„è½¦è¾†ï¼Œé¿å…è¿‡åº¦å†²çª
            num_vehicles = random.randint(self.config.min_vehicles_per_scenario, 
                                        min(len(edges), self.config.max_vehicles_per_scenario))
            
            selected_edges = random.sample(edges, min(num_vehicles, len(edges)))
            
            for i, start_edge in enumerate(selected_edges):
                # é€‰æ‹©éç›¸é‚»è¾¹
                others = [e for e in edges if e.edge_id != start_edge.edge_id]
                if len(others) >= 3:
                    # æ’é™¤æœ€è¿‘çš„è¾¹
                    others.sort(key=lambda e: 
                        math.sqrt((e.center_x - start_edge.center_x)**2 + 
                                 (e.center_y - start_edge.center_y)**2))
                    end_edge = random.choice(others[1:])  # æ’é™¤æœ€è¿‘çš„
                else:
                    end_edge = random.choice(others)
                
                task = Task(
                    task_id=i + 1,
                    start_edge=start_edge,
                    end_edge=end_edge,
                    start_pos=start_edge.get_random_integer_position(),
                    end_pos=end_edge.get_random_integer_position(),
                    priority=random.randint(1, 4)
                )
                
                vehicle = Vehicle(
                    vehicle_id=i + 1,
                    task=task,
                    color='blue'
                )
                vehicles.append(vehicle)
        
        return vehicles
    
    def _build_intersection_graph(self, vehicles: List[Vehicle], environment) -> Data:
        """æ„å»ºè·¯å£äº¤äº’å›¾ - å…¼å®¹lifelong_planning.pyçš„ç‰¹å¾"""
        
        # ğŸ¯ ç”Ÿæˆ8ç»´èŠ‚ç‚¹ç‰¹å¾ (ä¸lifelong_planning.pyå…¼å®¹)
        node_features = self._extract_8d_node_features(vehicles)
        
        # æ„å»ºè¾¹ç‰¹å¾
        edge_indices, edge_features = self._build_intersection_edges(vehicles)
        
        # å…¨å±€ç‰¹å¾
        global_features = self._extract_global_features(vehicles)
        
        return Data(
            x=torch.tensor(node_features, dtype=torch.float32),
            edge_index=torch.tensor(edge_indices, dtype=torch.long).T if edge_indices else torch.zeros((2, 0), dtype=torch.long),
            edge_attr=torch.tensor(edge_features, dtype=torch.float32) if edge_features else torch.zeros((0, 6), dtype=torch.float32),
            global_features=torch.tensor(global_features, dtype=torch.float32)
        )
    
    def _extract_8d_node_features(self, vehicles: List[Vehicle]) -> List[List[float]]:
        """æå–8ç»´èŠ‚ç‚¹ç‰¹å¾ - ä¸lifelong_planning.pyå®Œå…¨å…¼å®¹"""
        features = []
        
        for vehicle in vehicles:
            task = vehicle.task
            start_x, start_y = task.start_pos
            end_x, end_y = task.end_pos
            
            # è®¡ç®—åŸºç¡€ç‰¹å¾
            dx = end_x - start_x
            dy = end_y - start_y
            distance_to_goal = math.sqrt(dx*dx + dy*dy)
            goal_bearing = math.atan2(dy, dx)
            
            # ğŸ¯ 8ç»´ç‰¹å¾å‘é‡ (ä¸lifelong_planning.pyå®Œå…¨ä¸€è‡´)
            node_feature = [
                (start_x - 50.0) / 50.0,          # [0] ç›¸å¯¹ç¯å¢ƒä¸­å¿ƒx
                math.cos(goal_bearing),           # [1] èˆªå‘ä½™å¼¦
                math.sin(goal_bearing),           # [2] èˆªå‘æ­£å¼¦
                3.0 / 8.0,                        # [3] å½’ä¸€åŒ–é€Ÿåº¦ (å›ºå®š3.0)
                0.0,                              # [4] å½’ä¸€åŒ–åŠ é€Ÿåº¦
                distance_to_goal / 100.0,         # [5] å½’ä¸€åŒ–ç›®æ ‡è·ç¦»
                math.cos(goal_bearing),           # [6] ç›®æ ‡æ–¹å‘ä½™å¼¦
                task.priority / 10.0              # [7] å½’ä¸€åŒ–ä¼˜å…ˆçº§
            ]
            
            features.append(node_feature)
        
        return features
    
    def _build_intersection_edges(self, vehicles: List[Vehicle]) -> Tuple[List, List]:
        """æ„å»ºè·¯å£è¾¹ç‰¹å¾"""
        edge_indices = []
        edge_features = []
        
        for i in range(len(vehicles)):
            for j in range(i + 1, len(vehicles)):
                v1, v2 = vehicles[i], vehicles[j]
                
                # è®¡ç®—äº¤äº’ç‰¹å¾
                dist = math.sqrt((v1.task.start_pos[0] - v2.task.start_pos[0])**2 + 
                               (v1.task.start_pos[1] - v2.task.start_pos[1])**2)
                
                if dist < 50.0:  # äº¤äº’èŒƒå›´
                    # è·¯å¾„äº¤å‰æ£€æµ‹
                    crossing = self._check_path_crossing(v1.task, v2.task)
                    
                    # 6ç»´è¾¹ç‰¹å¾
                    edge_feat = [
                        dist / 50.0,                    # å½’ä¸€åŒ–è·ç¦»
                        6.0 / 16.0,                     # å¹³å‡é€Ÿåº¦
                        0.0,                            # è§’åº¦å·®
                        1.0 if crossing else 0.0,      # è·¯å¾„äº¤å‰
                        (v1.task.priority + v2.task.priority) / 10.0,  # ä¼˜å…ˆçº§
                        0.5                             # å†²çªé£é™©
                    ]
                    
                    edge_indices.extend([[i, j], [j, i]])
                    edge_features.extend([edge_feat, edge_feat])
        
        return edge_indices, edge_features
    
    def _check_path_crossing(self, task1: Task, task2: Task) -> bool:
        """æ£€æŸ¥ä¸¤ä¸ªä»»åŠ¡çš„è·¯å¾„æ˜¯å¦äº¤å‰"""
        def ccw(A, B, C):
            return (C[1]-A[1]) * (B[0]-A[0]) > (B[1]-A[1]) * (C[0]-A[0])
        
        def intersect(A, B, C, D):
            return ccw(A,C,D) != ccw(B,C,D) and ccw(A,B,C) != ccw(A,B,D)
        
        return intersect(task1.start_pos, task1.end_pos, task2.start_pos, task2.end_pos)
    
    def _extract_global_features(self, vehicles: List[Vehicle]) -> List[float]:
        """æå–å…¨å±€ç‰¹å¾"""
        if not vehicles:
            return [0.0] * 8
        
        n_vehicles = len(vehicles)
        priorities = [v.task.priority for v in vehicles]
        
        # è®¡ç®—å†²çªå¯¹æ•°
        conflicts = 0
        total_pairs = 0
        for i in range(n_vehicles):
            for j in range(i + 1, n_vehicles):
                total_pairs += 1
                if self._check_path_crossing(vehicles[i].task, vehicles[j].task):
                    conflicts += 1
        
        conflict_ratio = conflicts / max(total_pairs, 1)
        
        return [
            n_vehicles / 10.0,           # è½¦è¾†æ•°
            3.0 / 8.0,                   # å¹³å‡é€Ÿåº¦
            0.1,                         # é€Ÿåº¦æ–¹å·®
            50.0 / 100.0,                # å¹³å‡è·ç¦»
            10.0 / 100.0,                # è·ç¦»æ–¹å·®
            sum(priorities) / (n_vehicles * 10),  # å¹³å‡ä¼˜å…ˆçº§
            conflict_ratio,              # å†²çªæ¯”ä¾‹
            0.5                          # é¢„ç•™ç‰¹å¾
        ]
    
    def _generate_intersection_safety_labels(self, vehicles: List[Vehicle], map_data: Dict) -> Dict:
        """ç”Ÿæˆè·¯å£å®‰å…¨æ ‡ç­¾"""
        labels = {
            'priority': [],
            'cooperation': [],
            'urgency': [],
            'safety': [],
            'speed_adjustment': [],
            'route_preference': []
        }
        
        # åˆ†æå…¨å±€å†²çªæƒ…å†µ
        n_vehicles = len(vehicles)
        total_conflicts = 0
        for i in range(n_vehicles):
            for j in range(i + 1, n_vehicles):
                if self._check_path_crossing(vehicles[i].task, vehicles[j].task):
                    total_conflicts += 1
        
        global_conflict_level = total_conflicts / max(n_vehicles * (n_vehicles - 1) / 2, 1)
        
        for vehicle in vehicles:
            # è®¡ç®—è¯¥è½¦è¾†çš„å†²çªæ•°
            vehicle_conflicts = 0
            for other in vehicles:
                if other.vehicle_id != vehicle.vehicle_id:
                    if self._check_path_crossing(vehicle.task, other.task):
                        vehicle_conflicts += 1
            
            conflict_factor = vehicle_conflicts / max(n_vehicles - 1, 1)
            
            # ğŸ›¡ï¸ è·¯å£å®‰å…¨æ ‡ç­¾ç”Ÿæˆ
            
            # ä¼˜å…ˆçº§è°ƒæ•´
            base_priority = (vehicle.task.priority - 3) / 3.0
            if conflict_factor > 0.5:
                priority_adj = base_priority * 0.7  # é«˜å†²çªæ—¶é™ä½ä¼˜å…ˆçº§
            else:
                priority_adj = base_priority
            labels['priority'].append([np.tanh(priority_adj)])
            
            # åˆä½œå€¾å‘
            if global_conflict_level > 0.3:
                cooperation = 0.8  # é«˜å†²çªç¯å¢ƒä¸‹æé«˜åˆä½œ
            else:
                cooperation = 0.5 + conflict_factor * 0.3
            labels['cooperation'].append([cooperation])
            
            # ç´§æ€¥ç¨‹åº¦
            if conflict_factor > 0.6:
                urgency = 0.3  # é«˜å†²çªæ—¶é™ä½ç´§æ€¥ç¨‹åº¦ï¼Œä¼˜å…ˆå®‰å…¨
            else:
                urgency = 0.4 + conflict_factor * 0.2
            labels['urgency'].append([urgency])
            
            # ğŸ›¡ï¸ å®‰å…¨ç³»æ•° (è·¯å£æœ€é‡è¦)
            if conflict_factor > 0.5:
                safety = 0.9  # é«˜å†²çªæ—¶æœ€é«˜å®‰å…¨è¦æ±‚
            elif conflict_factor > 0.3:
                safety = 0.8
            else:
                safety = 0.6 + conflict_factor * 0.2
            labels['safety'].append([safety])
            
            # é€Ÿåº¦è°ƒæ•´
            if conflict_factor > 0.4:
                speed_adj = -0.3  # é«˜å†²çªæ—¶å‡é€Ÿ
            elif global_conflict_level > 0.4:
                speed_adj = -0.2  # å…¨å±€å†²çªæ—¶é€‚åº¦å‡é€Ÿ
            else:
                speed_adj = 0.0
            labels['speed_adjustment'].append([speed_adj])
            
            # è·¯å¾„åå¥½
            if conflict_factor > 0.3:
                # é«˜å†²çªæ—¶åå‘é¿è®©
                route_pref = [0.4, 0.2, 0.4]  # å·¦/ç›´/å³
            else:
                route_pref = [0.3, 0.4, 0.3]  # å‡è¡¡åå¥½
            labels['route_preference'].append(route_pref)
        
        # è½¬æ¢ä¸ºå¼ é‡
        for key in labels:
            labels[key] = torch.tensor(labels[key], dtype=torch.float32)
        
        return labels
    
    def _validate_data_consistency(self, graph_data: Data, labels: Dict, expected_nodes: int) -> bool:
        """éªŒè¯æ•°æ®ä¸€è‡´æ€§"""
        try:
            actual_nodes = graph_data.x.size(0)
            if actual_nodes != expected_nodes:
                return False
            
            for key, label_tensor in labels.items():
                if label_tensor.size(0) != expected_nodes:
                    return False
            
            return True
            
        except Exception:
            return False

# å¤ç”¨Pretraining_gnn.pyçš„æ¨¡å‹å’Œè®­ç»ƒå™¨ç±»
class IntersectionVehicleCoordinationGNN(nn.Module):
    """è·¯å£è½¦è¾†åè°ƒGNN - å…¼å®¹8ç»´è¾“å…¥"""
    
    def __init__(self, config: IntersectionTrainingConfig):
        super().__init__()
        
        self.config = config
        self.node_dim = 8      # ğŸ¯ å…¼å®¹lifelong_planning.pyçš„8ç»´ç‰¹å¾
        self.edge_dim = 6
        self.global_dim = 8
        self.hidden_dim = config.hidden_dim
        
        # ç¼–ç å™¨
        self.node_encoder = nn.Sequential(
            nn.Linear(self.node_dim, self.hidden_dim),
            nn.ReLU(),
            nn.Dropout(config.dropout)
        )
        
        # GNNå±‚
        self.gnn_layers = nn.ModuleList([
            pyg_nn.GCNConv(self.hidden_dim, self.hidden_dim)
            for _ in range(config.num_layers)
        ])
        
        # å†³ç­–è¾“å‡ºå¤´
        self.decision_heads = nn.ModuleDict({
            'priority': nn.Sequential(
                nn.Linear(self.hidden_dim, 32),
                nn.ReLU(),
                nn.Dropout(0.1),
                nn.Linear(32, 1),
                nn.Tanh()
            ),
            'cooperation': nn.Sequential(
                nn.Linear(self.hidden_dim, 32),
                nn.ReLU(),
                nn.Dropout(0.1),
                nn.Linear(32, 1),
                nn.Sigmoid()
            ),
            'urgency': nn.Sequential(
                nn.Linear(self.hidden_dim, 32),
                nn.ReLU(),
                nn.Dropout(0.1),
                nn.Linear(32, 1),
                nn.Sigmoid()
            ),
            'safety': nn.Sequential(
                nn.Linear(self.hidden_dim, 64),
                nn.ReLU(),
                nn.Dropout(0.05),
                nn.Linear(64, 32),
                nn.ReLU(),
                nn.Linear(32, 1),
                nn.Sigmoid()
            ),
            'speed_adjustment': nn.Sequential(
                nn.Linear(self.hidden_dim, 32),
                nn.ReLU(),
                nn.Dropout(0.1),
                nn.Linear(32, 1),
                nn.Tanh()
            ),
            'route_preference': nn.Sequential(
                nn.Linear(self.hidden_dim, 32),
                nn.ReLU(),
                nn.Dropout(0.1),
                nn.Linear(32, 3),
                nn.Softmax(dim=-1)
            )
        })
    
    def forward(self, batch: Batch) -> Dict[str, torch.Tensor]:
        """å‰å‘ä¼ æ’­"""
        x, edge_index = batch.x, batch.edge_index
        
        if x.size(0) == 0:
            return self._empty_output()
        
        # èŠ‚ç‚¹ç¼–ç 
        x = self.node_encoder(x)
        
        # GNNå±‚
        for gnn_layer in self.gnn_layers:
            x = F.relu(gnn_layer(x, edge_index))
            x = F.dropout(x, p=self.config.dropout, training=self.training)
        
        # ç”Ÿæˆå†³ç­–
        decisions = {}
        for decision_type, head in self.decision_heads.items():
            decisions[decision_type] = head(x)
        
        return decisions
    
    def _empty_output(self) -> Dict[str, torch.Tensor]:
        """ç©ºè¾“å‡º"""
        return {
            'priority': torch.zeros((0, 1)),
            'cooperation': torch.zeros((0, 1)),
            'urgency': torch.zeros((0, 1)),
            'safety': torch.zeros((0, 1)),
            'speed_adjustment': torch.zeros((0, 1)),
            'route_preference': torch.zeros((0, 3))
        }

class IntersectionGraphDataset(Dataset):
    """è·¯å£å›¾æ•°æ®é›†"""
    
    def __init__(self, scenarios_data: List[Tuple]):
        self.data = []
        
        print(f"ğŸ”„ å¤„ç† {len(scenarios_data)} ä¸ªè·¯å£åœºæ™¯æ•°æ®...")
        
        for i, (graph_data, labels) in enumerate(scenarios_data):
            try:
                data_obj = Data(
                    x=graph_data.x,
                    edge_index=graph_data.edge_index,
                    edge_attr=graph_data.edge_attr,
                    global_features=graph_data.global_features,
                    y_priority=labels['priority'],
                    y_cooperation=labels['cooperation'],
                    y_urgency=labels['urgency'],
                    y_safety=labels['safety'],
                    y_speed_adjustment=labels['speed_adjustment'],
                    y_route_preference=labels['route_preference']
                )
                
                num_nodes = data_obj.x.size(0)
                if (data_obj.y_priority.size(0) == num_nodes and
                    data_obj.y_cooperation.size(0) == num_nodes):
                    self.data.append(data_obj)
                else:
                    if i < 5:
                        print(f"âš ï¸ è·³è¿‡åœºæ™¯ {i}: æ ‡ç­¾ä¸èŠ‚ç‚¹æ•°ä¸åŒ¹é…")
                    
            except Exception as e:
                if i < 5:
                    print(f"âš ï¸ å¤„ç†åœºæ™¯ {i} æ—¶å‡ºé”™: {str(e)}")
                continue
        
        print(f"âœ… æˆåŠŸå¤„ç† {len(self.data)} ä¸ªæœ‰æ•ˆè·¯å£åœºæ™¯")
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        return self.data[idx]

class IntersectionGNNTrainer:
    """è·¯å£GNNè®­ç»ƒå™¨"""
    
    def __init__(self, config: IntersectionTrainingConfig):
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        self.model = IntersectionVehicleCoordinationGNN(config).to(self.device)
        
        self.optimizer = torch.optim.Adam(
            self.model.parameters(),
            lr=config.learning_rate,
            weight_decay=config.weight_decay
        )
        
        self.scheduler = torch.optim.lr_scheduler.StepLR(
            self.optimizer, step_size=12, gamma=0.7
        )
        
        # æŸå¤±å‡½æ•°
        self.mse_loss = nn.MSELoss()
        self.bce_loss = nn.BCELoss()
        self.ce_loss = nn.CrossEntropyLoss()
        
        # è®­ç»ƒè®°å½•
        self.train_losses = []
        self.val_losses = []
        self.best_val_loss = float('inf')
        self.patience_counter = 0
    
    def compute_batch_loss(self, predictions: Dict, batch: Batch) -> torch.Tensor:
        """è®¡ç®—æ‰¹æ¬¡æŸå¤±"""
        total_loss = 0.0
        
        # ğŸ›¡ï¸ è·¯å£å®‰å…¨ä¼˜å…ˆçš„æŸå¤±æƒé‡
        loss_weights = {
            'priority': 1.0,
            'cooperation': 1.2,
            'urgency': 1.0,
            'safety': self.config.safety_priority_weight,  # è·¯å£å®‰å…¨æƒé‡æœ€é«˜
            'speed_adjustment': 0.8,
            'route_preference': 1.0
        }
        
        for task in ['priority', 'cooperation', 'urgency', 'safety', 'speed_adjustment']:
            if task in predictions and hasattr(batch, f'y_{task}'):
                y_true = getattr(batch, f'y_{task}')
                if y_true.size(0) > 0:
                    if task in ['cooperation', 'urgency', 'safety']:
                        loss = self.bce_loss(predictions[task], y_true)
                        # ğŸ›¡ï¸ å®‰å…¨é¢å¤–æƒ©ç½š
                        if task == 'safety':
                            safety_penalty = torch.mean(torch.relu(y_true - predictions[task])) * 0.3
                            loss += safety_penalty
                    else:
                        loss = self.mse_loss(predictions[task], y_true)
                    total_loss += loss_weights[task] * loss
        
        if 'route_preference' in predictions and hasattr(batch, 'y_route_preference'):
            y_route = batch.y_route_preference
            if y_route.size(0) > 0:
                loss = self.ce_loss(predictions['route_preference'], y_route)
                total_loss += loss_weights['route_preference'] * loss
        
        return total_loss
    
    def train_epoch(self, dataloader) -> float:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0.0
        num_batches = 0
        
        for batch in tqdm(dataloader, desc="ğŸ›¡ï¸ è·¯å£è®­ç»ƒ"):
            try:
                self.optimizer.zero_grad()
                batch = batch.to(self.device)
                predictions = self.model(batch)
                loss = self.compute_batch_loss(predictions, batch)
                loss.backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)
                self.optimizer.step()
                
                total_loss += loss.item()
                num_batches += 1
                
            except Exception as e:
                print(f"âš ï¸ è®­ç»ƒæ‰¹æ¬¡å‡ºé”™: {str(e)}")
                continue
        
        return total_loss / max(num_batches, 1)
    
    def validate(self, dataloader) -> float:
        """éªŒè¯"""
        self.model.eval()
        total_loss = 0.0
        num_batches = 0
        
        with torch.no_grad():
            for batch in tqdm(dataloader, desc="ğŸ›¡ï¸ è·¯å£éªŒè¯"):
                try:
                    batch = batch.to(self.device)
                    predictions = self.model(batch)
                    loss = self.compute_batch_loss(predictions, batch)
                    total_loss += loss.item()
                    num_batches += 1
                except Exception as e:
                    continue
        
        return total_loss / max(num_batches, 1)
    
    def train(self, train_dataset: IntersectionGraphDataset, val_dataset: IntersectionGraphDataset):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        print(f"ğŸ›¡ï¸ å¼€å§‹è®­ç»ƒè·¯å£GNNæ¨¡å‹...")
        print(f"  è®­ç»ƒæ•°æ®: {len(train_dataset)} ä¸ªè·¯å£åœºæ™¯")
        print(f"  éªŒè¯æ•°æ®: {len(val_dataset)} ä¸ªè·¯å£åœºæ™¯")
        print(f"  ğŸ›¡ï¸ å®‰å…¨æŸå¤±æƒé‡: {self.config.safety_priority_weight}")
        
        train_loader = DataLoader(
            train_dataset, 
            batch_size=self.config.batch_size, 
            shuffle=True,
            follow_batch=['x']
        )
        
        val_loader = DataLoader(
            val_dataset, 
            batch_size=self.config.batch_size, 
            shuffle=False,
            follow_batch=['x']
        )
        
        for epoch in range(self.config.num_epochs):
            print(f"\nğŸ“Š Epoch {epoch+1}/{self.config.num_epochs} (ğŸ›¡ï¸ è·¯å£å®‰å…¨è®­ç»ƒ)")
            
            train_loss = self.train_epoch(train_loader)
            self.train_losses.append(train_loss)
            
            val_loss = self.validate(val_loader)
            self.val_losses.append(val_loss)
            
            self.scheduler.step()
            
            print(f"  è®­ç»ƒæŸå¤±: {train_loss:.4f}")
            print(f"  éªŒè¯æŸå¤±: {val_loss:.4f}")
            print(f"  å­¦ä¹ ç‡: {self.optimizer.param_groups[0]['lr']:.6f}")
            
            if val_loss < self.best_val_loss:
                self.best_val_loss = val_loss
                self.patience_counter = 0
                self.save_model('best_intersection_gnn_model.pth')
                print(f"  âœ… éªŒè¯æŸå¤±æ”¹å–„ï¼Œä¿å­˜æœ€ä½³è·¯å£æ¨¡å‹")
            else:
                self.patience_counter += 1
                print(f"  â³ éªŒè¯æŸå¤±æœªæ”¹å–„ ({self.patience_counter}/{self.config.early_stopping_patience})")
            
            if self.patience_counter >= self.config.early_stopping_patience:
                print(f"  ğŸ›‘ æ—©åœ")
                break
        
        print(f"\nğŸ‰ è·¯å£GNNè®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯æŸå¤±: {self.best_val_loss:.4f}")
    
    def save_model(self, filepath: str):
        """ä¿å­˜æ¨¡å‹"""
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'config': self.config,
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
            'best_val_loss': self.best_val_loss
        }, filepath)

def main():
    """ğŸ›¡ï¸ è·¯å£GNNé¢„è®­ç»ƒä¸»æµç¨‹"""
    print("ğŸ›¡ï¸ è·¯å£GNNé¢„è®­ç»ƒç³»ç»Ÿ")
    print("=" * 80)
    print("ğŸ¯ ä¸“ä¸ºlifelong_planning.pyè·¯å£åœºæ™¯è®¾è®¡:")
    print("   âœ… ğŸ›¡ï¸ æ”¯æŒintersection_edgesåœ°å›¾æ ¼å¼")
    print("   âœ… ğŸ›¡ï¸ æ¯æ¡è¾¹ä¸€ä¸ªä»»åŠ¡çš„è®­ç»ƒæ•°æ®ç”Ÿæˆ")
    print("   âœ… ğŸ›¡ï¸ 8ç»´ç‰¹å¾å…¼å®¹æ€§")
    print("   âœ… ğŸ›¡ï¸ è·¯å£å†²çªå®‰å…¨æ ‡ç­¾ç”Ÿæˆ")
    print("   âœ… ğŸ›¡ï¸ é«˜å†²çªåœºæ™¯ä¸“é—¨è®­ç»ƒ")
    print("=" * 80)
    
    # è·¯å£è®­ç»ƒé…ç½®
    config = IntersectionTrainingConfig(
        batch_size=4,
        learning_rate=0.0008,
        num_epochs=40,
        hidden_dim=64,
        num_layers=3,
        dropout=0.15,
        
        # è·¯å£ç‰¹åŒ–é…ç½®
        num_scenarios=2000,
        num_map_variants=8,
        max_vehicles_per_scenario=8,
        min_vehicles_per_scenario=3,
        
        # å®‰å…¨é…ç½®
        min_safe_distance=8.0,
        safety_priority_weight=1.8,
        high_conflict_ratio=0.4
    )
    
    print(f"\nğŸ“‹ ğŸ›¡ï¸ è·¯å£è®­ç»ƒé…ç½®:")
    print(f"  æ•°æ®é›†å¤§å°: {config.num_scenarios}")
    print(f"  é«˜å†²çªåœºæ™¯æ¯”ä¾‹: {config.high_conflict_ratio*100:.0f}%")
    print(f"  å®‰å…¨æŸå¤±æƒé‡: {config.safety_priority_weight}x")
    print(f"  åœ°å›¾å˜ä½“æ•°: {config.num_map_variants}")
    print(f"  ç‰¹å¾ç»´åº¦: 8ç»´èŠ‚ç‚¹ + 6ç»´è¾¹ + 8ç»´å…¨å±€")
    
    try:
        # 1. ç”Ÿæˆè·¯å£è®­ç»ƒæ•°æ®
        print(f"\nğŸ“Š æ­¥éª¤1: ç”Ÿæˆè·¯å£è®­ç»ƒæ•°æ®")
        generator = IntersectionVehicleScenarioGenerator(config)
        all_data = generator.generate_training_data()
        
        if len(all_data) < 20:
            print("âŒ ç”Ÿæˆçš„æœ‰æ•ˆè·¯å£æ•°æ®å¤ªå°‘ï¼Œæ— æ³•è®­ç»ƒ")
            return
        
        # 2. åˆ’åˆ†æ•°æ®é›†
        val_size = max(5, int(len(all_data) * config.val_split))
        train_size = len(all_data) - val_size
        
        train_data = all_data[:train_size]
        val_data = all_data[train_size:]
        
        print(f"  è®­ç»ƒé›†: {len(train_data)} ä¸ªè·¯å£åœºæ™¯")
        print(f"  éªŒè¯é›†: {len(val_data)} ä¸ªè·¯å£åœºæ™¯")
        
        # 3. åˆ›å»ºæ•°æ®é›†
        print(f"\nğŸ”„ æ­¥éª¤2: åˆ›å»ºè·¯å£æ•°æ®é›†")
        train_dataset = IntersectionGraphDataset(train_data)
        val_dataset = IntersectionGraphDataset(val_data)
        
        if len(train_dataset) == 0 or len(val_dataset) == 0:
            print("âŒ è·¯å£æ•°æ®é›†åˆ›å»ºå¤±è´¥")
            return
        
        # 4. è®­ç»ƒè·¯å£GNNæ¨¡å‹
        print(f"\nğŸ›¡ï¸ æ­¥éª¤3: è®­ç»ƒè·¯å£GNNæ¨¡å‹")
        trainer = IntersectionGNNTrainer(config)
        trainer.train(train_dataset, val_dataset)
        
        # 5. ä¿å­˜æ¨¡å‹
        trainer.save_model('final_intersection_gnn_model.pth')
        
        print(f"\nâœ… ğŸ›¡ï¸ è·¯å£GNNé¢„è®­ç»ƒå®Œæˆï¼")
        print(f"  æœ€ä½³æ¨¡å‹: best_intersection_gnn_model.pth")
        print(f"  æœ€ç»ˆæ¨¡å‹: final_intersection_gnn_model.pth")
        print(f"\nğŸ¯ ğŸ›¡ï¸ è·¯å£æ¨¡å‹ç‰¹æ€§:")
        print(f"  âœ… å…¼å®¹lifelong_planning.pyçš„8ç»´ç‰¹å¾")
        print(f"  âœ… æ”¯æŒintersection_edgesåœ°å›¾æ ¼å¼")
        print(f"  âœ… 40%é«˜å†²çªåœºæ™¯è®­ç»ƒå®‰å…¨é¿è®©")
        print(f"  âœ… è·¯å£å®‰å…¨ä¼˜å…ˆå†³ç­– (æƒé‡1.8x)")
        print(f"  âœ… æ¯æ¡è¾¹ä¸€ä¸ªä»»åŠ¡çš„ä¸“é—¨è®­ç»ƒ")
        
        print(f"\nğŸ›¡ï¸ ä½¿ç”¨æ–¹æ³•:")
        print(f"  ç°åœ¨å¯ä»¥è¿è¡Œ lifelong_planning.py")
        print(f"  ç³»ç»Ÿå°†è‡ªåŠ¨åŠ è½½é¢„è®­ç»ƒçš„è·¯å£GNNæ¨¡å‹")
        print(f"  äº«å—è·¯å£å®‰å…¨æ™ºèƒ½è§„åˆ’ï¼")
        
    except Exception as e:
        print(f"âŒ è·¯å£é¢„è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()