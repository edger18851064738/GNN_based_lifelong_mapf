#!/usr/bin/env python3
"""
ğŸš€ Advanced GNN Framework for Multi-Vehicle Path Planning - å®Œæ•´ä¿®å¤ç‰ˆæœ¬
ä½œè€…: é›†æˆtrying.pyå’Œtrans.pyçš„æœ€æ–°GNNæ¶æ„ + ç»´åº¦é”™è¯¯ä¿®å¤

ä½¿ç”¨æ–¹æ³•:
1. å°†æ­¤æ–‡ä»¶ä¿å­˜ä¸º train.py
2. ç¡®ä¿trying.pyå’Œtrans.pyåœ¨åŒç›®å½•ä¸‹
3. è¿è¡Œ: python train.py

æ ¸å¿ƒä¼˜åŠ¿:
âœ… ä¿æŒtrying.pyå®Œå…¨ä¸å˜ï¼ˆ240sâ†’3sä¼˜åŒ–ä¿æŒä¸å˜ï¼‰
âœ… å‡çº§GNNä¸º2020-2025é¡¶çº§æœŸåˆŠæ°´å¹³  
âœ… ä¿®å¤æ‰€æœ‰ç»´åº¦ä¸åŒ¹é…é—®é¢˜
âœ… è‡ªåŠ¨å¤„ç†ä¾èµ–ï¼Œä¼˜é›…é™çº§
âœ… å³æ’å³ç”¨ï¼Œæœ€å°ä¿®æ”¹é‡
âœ… åŸºäºæœ€æ–°MAPF+GNNæ–‡çŒ®ä¼˜åŒ–
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import math
import numpy as np
import time
import json
import os
import sys
import traceback
import warnings
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
from enum import Enum

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings("ignore")

# =============================================================================
# ğŸ”„ ä¾èµ–ç®¡ç†å’Œè‡ªåŠ¨å¯¼å…¥
# =============================================================================

print("ğŸ”„ Auto-importing trying.py modules...")
try:
    from trying import (
        VehicleState, VehicleParameters, UnstructuredEnvironment,
        VHybridAStarPlanner, MultiVehicleCoordinator, OptimizationLevel,
        HybridNode, ConflictDensityAnalyzer, TimeSync,
        OptimizedTrajectoryProcessor, CompleteQPOptimizer, 
        EnhancedConvexSpaceSTDiagram, PreciseKinematicModel,
        interactive_json_selection, save_trajectories
    )
    print("âœ… Successfully imported trying.py - using mature algorithms")
    HAS_TRYING = True
except ImportError as e:
    print(f"âš ï¸ trying.py not found: {e}")
    print("ğŸ”§ Using fallback implementations")
    HAS_TRYING = False

print("ğŸ”„ Auto-importing trans.py modules...")
try:
    from trans import (
        VehicleGraphBuilder, VehicleInteractionGraph,
        GNNEnhancementLevel
    )
    print("âœ… Successfully imported trans.py - using graph building logic")
    HAS_TRANS = True
except ImportError as e:
    print(f"âš ï¸ trans.py not found: {e}")
    print("ğŸ”§ Using fallback graph builder")
    HAS_TRANS = False

# ğŸ”„ å¯é€‰PyTorch Geometric
try:
    from torch_geometric.nn import GCNConv, GATConv, global_mean_pool
    HAS_TORCH_GEOMETRIC = True
    print("âœ… PyTorch Geometric available")
except ImportError:
    HAS_TORCH_GEOMETRIC = False
    print("âš ï¸ PyTorch Geometric not found - using pure PyTorch")

# =============================================================================
# ğŸ“š Fallbackæ•°æ®ç»“æ„ï¼ˆå½“ä¾èµ–ä¸å¯ç”¨æ—¶ï¼‰
# =============================================================================

if not HAS_TRYING:
    @dataclass
    class VehicleState:
        x: float; y: float; theta: float; v: float; t: float
        steer: float = 0.0; acceleration: float = 0.0
        def copy(self): return VehicleState(self.x, self.y, self.theta, self.v, self.t, self.steer, self.acceleration)
    
    class VehicleParameters:
        def __init__(self):
            self.wheelbase = 2.1; self.length = 2.8; self.width = 1.6
            self.max_speed = 6.0; self.min_speed = 0.3; self.dt = 0.4
            self.max_accel = 2.0
    
    class OptimizationLevel(Enum):
        BASIC = "basic"; ENHANCED = "enhanced"; FULL = "full"

if not HAS_TRANS:
    @dataclass
    class VehicleInteractionGraph:
        node_features: torch.Tensor; edge_indices: torch.Tensor; edge_features: torch.Tensor
        vehicle_ids: List[int]; adjacency_matrix: torch.Tensor; global_features: torch.Tensor
    
    class GNNEnhancementLevel(Enum):
        PRIORITY_ONLY = "priority_only"; EXPANSION_GUIDE = "expansion_guide"; FULL_INTEGRATION = "full_integration"

# =============================================================================
# ğŸ”§ ä¿®å¤ç‰ˆæœ¬ï¼šSpatioTemporalPositionalEncoding
# =============================================================================

class SpatioTemporalPositionalEncoding(nn.Module):
    """ğŸ“ ä¿®å¤çš„æ—¶ç©ºä½ç½®ç¼–ç  - è§£å†³ç»´åº¦æ‹¼æ¥é—®é¢˜"""
    
    def __init__(self, hidden_dim):
        super().__init__()
        self.hidden_dim = hidden_dim
        
        # ğŸ”§ ä¿®å¤ï¼šç¡®ä¿è¾“å‡ºç»´åº¦æ­£ç¡®åˆ†é…
        quarter_dim = max(1, hidden_dim // 4)
        
        self.spatial_proj = nn.Linear(2, quarter_dim)      # x, y
        self.angle_proj = nn.Linear(2, quarter_dim)        # cos, sin Î¸
        self.velocity_proj = nn.Linear(1, quarter_dim)     # v
        self.time_proj = nn.Linear(1, quarter_dim)         # t
        
        # ğŸ”§ ä¿®å¤ï¼šæ­£ç¡®çš„èåˆå±‚ç»´åº¦
        total_input_dim = quarter_dim * 4
        self.fusion = nn.Linear(total_input_dim, hidden_dim)
        
        print(f"         âœ… ä½ç½®ç¼–ç ä¿®å¤: è¾“å…¥ç»´åº¦ {total_input_dim} -> è¾“å‡ºç»´åº¦ {hidden_dim}")

    def forward(self, x, raw_features):
        if raw_features.shape[1] < 5:
            return x
            
        try:
            batch_size = raw_features.shape[0]
            device = raw_features.device
            
            # ğŸ”§ å®‰å…¨çš„ç‰¹å¾æå–
            spatial_features = raw_features[:, 0:2]  # x, y
            
            # è§’åº¦ç‰¹å¾å¤„ç†
            if raw_features.shape[1] >= 3:
                theta = raw_features[:, 2]
                angle_features = torch.stack([torch.cos(theta), torch.sin(theta)], dim=1)
            else:
                angle_features = torch.zeros(batch_size, 2, device=device)
            
            # é€Ÿåº¦ç‰¹å¾
            if raw_features.shape[1] >= 5:
                velocity_features = raw_features[:, 4:5]
            else:
                velocity_features = torch.ones(batch_size, 1, device=device)
            
            # æ—¶é—´ç‰¹å¾
            if raw_features.shape[1] >= 10:
                time_features = raw_features[:, -1:]
            else:
                time_features = torch.zeros(batch_size, 1, device=device)
            
            # åˆ†åˆ«æŠ•å½±
            spatial_proj = self.spatial_proj(spatial_features)
            angle_proj = self.angle_proj(angle_features)
            velocity_proj = self.velocity_proj(velocity_features)
            time_proj = self.time_proj(time_features)
            
            # æ‹¼æ¥å¹¶èåˆ
            pos_enc_concat = torch.cat([spatial_proj, angle_proj, velocity_proj, time_proj], dim=-1)
            pos_enc = self.fusion(pos_enc_concat)
            
            return x + pos_enc
            
        except Exception as e:
            print(f"        âš ï¸ ä½ç½®ç¼–ç å¤±è´¥: {e}ï¼Œè·³è¿‡ä½ç½®ç¼–ç ")
            return x

# =============================================================================
# ğŸ”§ ä¿®å¤ç‰ˆæœ¬ï¼šGraphTransformerLayer
# =============================================================================

class GraphTransformerLayer(nn.Module):
    """ğŸ”§ ä¿®å¤çš„Graph Transformer Layer - GPSé£æ ¼"""
    
    def __init__(self, hidden_dim, num_heads, dropout=0.1):
        super().__init__()
        
        # ğŸ”§ ç¡®ä¿ hidden_dim èƒ½è¢« num_heads æ•´é™¤
        if hidden_dim % num_heads != 0:
            adjusted_hidden_dim = ((hidden_dim + num_heads - 1) // num_heads) * num_heads
            print(f"         ğŸ”§ GraphTransformerLayer: è°ƒæ•´ hidden_dim {hidden_dim} â†’ {adjusted_hidden_dim}")
            hidden_dim = adjusted_hidden_dim
            
        self.hidden_dim = hidden_dim
        self.num_heads = num_heads
        
        # Multi-head attention
        self.attention = nn.MultiheadAttention(
            hidden_dim, num_heads, dropout=dropout, batch_first=True
        )
        
        # FFN
        self.ffn = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim * 4), nn.GELU(), nn.Dropout(dropout),
            nn.Linear(hidden_dim * 4, hidden_dim), nn.Dropout(dropout)
        )
        
        # Layer norms
        self.norm1 = nn.LayerNorm(hidden_dim)
        self.norm2 = nn.LayerNorm(hidden_dim)
        
        # å±€éƒ¨GNNï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if HAS_TORCH_GEOMETRIC:
            try:
                self.local_gnn = GATConv(hidden_dim, hidden_dim, heads=1, concat=False)
            except:
                pass

    def forward(self, x, edge_index, edge_attr):
        if x.shape[0] == 0:
            return x, edge_attr, None
            
        try:
            residual = x
            
            # å±€éƒ¨GNNå¤„ç†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if hasattr(self, 'local_gnn') and edge_index.shape[1] > 0:
                try:
                    x_local = self.local_gnn(x, edge_index)
                    x = self.norm1(x_local + residual)
                except:
                    pass
            
            # ğŸ”§ å®‰å…¨çš„å…¨å±€æ³¨æ„åŠ›
            if x.shape[0] == 1:
                # å•èŠ‚ç‚¹æƒ…å†µï¼šè·³è¿‡æ³¨æ„åŠ›æœºåˆ¶
                attn_weights = torch.ones(1, 1, 1, device=x.device)
                x_global = x
            else:
                # å¤šèŠ‚ç‚¹æƒ…å†µï¼šåº”ç”¨æ³¨æ„åŠ›
                x_seq = x.unsqueeze(0)  # [1, N, hidden_dim]
                try:
                    attn_out, attn_weights = self.attention(x_seq, x_seq, x_seq)
                    x_global = attn_out.squeeze(0)
                except Exception as e:
                    print(f"        âš ï¸ æ³¨æ„åŠ›è®¡ç®—å¤±è´¥: {e}")
                    x_global = x
                    attn_weights = None
            
            x = self.norm1(x_global + x)
            
            # FFN
            x_ffn = self.ffn(x)
            x = self.norm2(x + x_ffn)
            
            return x, edge_attr, attn_weights
            
        except Exception as e:
            print(f"        âš ï¸ GraphTransformerå±‚å¤±è´¥: {e}")
            return x, edge_attr, None

# =============================================================================
# ğŸ”§ ä¿®å¤ç‰ˆæœ¬ï¼šSpatioTemporalGraphTransformer
# =============================================================================

class SpatioTemporalGraphTransformer(nn.Module):
    """ğŸ§  ä¿®å¤çš„æ—¶ç©ºå›¾Transformer - SOTA 2024æ¶æ„"""
    
    def __init__(self, node_dim=10, edge_dim=6, hidden_dim=128, num_heads=8, num_layers=4, dropout=0.1):
        super().__init__()
        
        # ğŸ”§ è‡ªåŠ¨ä¿®æ­£ hidden_dim å’Œ num_heads çš„å…¼å®¹æ€§
        if hidden_dim % num_heads != 0:
            adjusted_hidden_dim = ((hidden_dim + num_heads - 1) // num_heads) * num_heads
            print(f"âš ï¸ Auto-adjusting hidden_dim: {hidden_dim} â†’ {adjusted_hidden_dim} (divisible by {num_heads} heads)")
            hidden_dim = adjusted_hidden_dim
        
        self.hidden_dim = hidden_dim
        self.node_dim = node_dim
        self.edge_dim = edge_dim
        
        # ç¼–ç å™¨
        self.node_encoder = nn.Sequential(
            nn.Linear(node_dim, hidden_dim), nn.LayerNorm(hidden_dim), nn.ReLU(), nn.Dropout(dropout)
        )
        
        # è¾¹ç¼–ç å™¨
        if edge_dim > 0:
            self.edge_encoder = nn.Sequential(
                nn.Linear(edge_dim, hidden_dim), nn.LayerNorm(hidden_dim), nn.ReLU()
            )
        else:
            self.edge_encoder = None
        
        # ğŸ”§ ä¿®å¤çš„Transformerå±‚
        self.transformer_layers = nn.ModuleList([
            GraphTransformerLayer(hidden_dim, num_heads, dropout) for _ in range(num_layers)
        ])
        
        # ä½ç½®ç¼–ç 
        self.pos_encoding = SpatioTemporalPositionalEncoding(hidden_dim)
        
        print(f"ğŸ§  ä¿®å¤çš„æ—¶ç©ºå›¾Transformer: {num_layers} å±‚, {num_heads} å¤´, ç»´åº¦ {hidden_dim}")

    def forward(self, node_features, edge_indices, edge_features):
        try:
            # ç¼–ç 
            h_nodes = self.node_encoder(node_features)
            
            # è¾¹ç¼–ç 
            if self.edge_encoder and edge_features.size(0) > 0:
                h_edges = self.edge_encoder(edge_features)
            else:
                h_edges = edge_features if edge_features.size(0) > 0 else None
            
            # ä½ç½®ç¼–ç 
            h_nodes = self.pos_encoding(h_nodes, node_features)
            
            # Transformerå¤„ç†
            attention_weights = []
            for layer in self.transformer_layers:
                h_nodes, h_edges, attn = layer(h_nodes, edge_indices, h_edges)
                if attn is not None:
                    attention_weights.append(attn)
            
            return {
                'node_embeddings': h_nodes,
                'edge_embeddings': h_edges,
                'attention_weights': attention_weights
            }
            
        except Exception as e:
            print(f"âŒ Transformerå‰å‘ä¼ æ’­å¤±è´¥: {e}")
            # è¿”å›å®‰å…¨çš„é»˜è®¤å€¼
            batch_size = node_features.size(0) if node_features.size(0) > 0 else 0
            return {
                'node_embeddings': torch.zeros(batch_size, self.hidden_dim, device=node_features.device),
                'edge_embeddings': None,
                'attention_weights': []
            }

# =============================================================================
# ğŸ”§ ä¿®å¤ç‰ˆæœ¬ï¼šHierarchicalGraphPooling
# =============================================================================

class HierarchicalGraphPooling(nn.Module):
    """ğŸ“Š ä¿®å¤çš„åˆ†å±‚å›¾æ± åŒ–"""
    
    def __init__(self, hidden_dim, num_heads=4, pooling_ratio=0.5, num_levels=3):
        super().__init__()
        self.hidden_dim = hidden_dim
        self.num_levels = min(num_levels, 2)  # ğŸ”§ é™åˆ¶å±‚æ•°é¿å…å¤æ‚åº¦
        
        # ğŸ”§ ç®€åŒ–çš„æ± åŒ–ç­–ç•¥
        self.global_pool = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim // 2, hidden_dim)
        )
        
        # è¯»å‡ºå±‚
        self.readout = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, hidden_dim)
        )
        
        print(f"         âœ… ç®€åŒ–åˆ†å±‚æ± åŒ–: {hidden_dim} -> {hidden_dim}")

    def forward(self, x, edge_index, batch_size=1):
        try:
            if x.shape[0] == 0:
                return torch.zeros(1, self.hidden_dim, device=x.device)
            
            # ğŸ”§ ç®€å•çš„å…¨å±€å¹³å‡æ± åŒ–
            if HAS_TORCH_GEOMETRIC:
                try:
                    batch = torch.zeros(x.size(0), dtype=torch.long, device=x.device)
                    global_repr = global_mean_pool(x, batch)
                except:
                    global_repr = x.mean(dim=0, keepdim=True)
            else:
                global_repr = x.mean(dim=0, keepdim=True)
            
            # åº”ç”¨æ± åŒ–ç½‘ç»œ
            pooled = self.global_pool(global_repr)
            final_repr = self.readout(pooled)
            
            return final_repr
            
        except Exception as e:
            print(f"        âš ï¸ åˆ†å±‚æ± åŒ–å¤±è´¥: {e}")
            device = x.device if x.numel() > 0 else torch.device('cpu')
            return torch.zeros(1, self.hidden_dim, device=device)

# =============================================================================
# ğŸ”§ ä¿®å¤ç‰ˆæœ¬ï¼šAdvancedGNNCoordinator
# =============================================================================

class AdvancedGNNCoordinator(nn.Module):
    """ğŸ¯ ä¿®å¤çš„é«˜çº§GNNåè°ƒå™¨"""
    
    def __init__(self, node_dim=10, edge_dim=6, hidden_dim=128, num_heads=8, num_transformer_layers=4, num_pooling_levels=3):
        super().__init__()
        
        # ğŸ”§ é…ç½®éªŒè¯å’Œä¿®å¤
        config = self._validate_and_fix_config(hidden_dim, num_heads, node_dim, edge_dim)
        self.hidden_dim = config['hidden_dim']
        self.node_dim = config['node_dim']
        self.edge_dim = config['edge_dim']
        
        print(f"ğŸ”§ ä½¿ç”¨ä¿®å¤é…ç½®: hidden_dim={self.hidden_dim}, num_heads={config['num_heads']}")
        
        # æ ¸å¿ƒå›¾Transformer
        self.graph_transformer = SpatioTemporalGraphTransformer(
            node_dim, edge_dim, self.hidden_dim, config['num_heads'], num_transformer_layers
        )
        
        # åˆ†å±‚æ± åŒ–
        self.hierarchical_pooling = HierarchicalGraphPooling(
            self.hidden_dim, config['num_heads'], num_levels=min(num_pooling_levels, 2)
        )
        
        # ğŸ”§ ä¿®å¤çš„å¤šæ¨¡æ€å†³ç­–å¤´
        self.decision_heads = nn.ModuleDict({
            'priority': nn.Sequential(
                nn.Linear(self.hidden_dim, 64), nn.ReLU(), nn.Dropout(0.1),
                nn.Linear(64, 1), nn.Tanh()
            ),
            'cooperation': nn.Sequential(
                nn.Linear(self.hidden_dim, 64), nn.ReLU(), nn.Dropout(0.1),
                nn.Linear(64, 1), nn.Sigmoid()
            ),
            'path_quality': nn.Sequential(
                nn.Linear(self.hidden_dim, 64), nn.ReLU(), nn.Dropout(0.1),
                nn.Linear(64, 1), nn.Sigmoid()
            ),
            'avoidance_strength': nn.Sequential(
                nn.Linear(self.hidden_dim, 64), nn.ReLU(), nn.Dropout(0.1),
                nn.Linear(64, 1), nn.Sigmoid()
            ),
            'speed_factor': nn.Sequential(
                nn.Linear(self.hidden_dim, 32), nn.ReLU(),
                nn.Linear(32, 1), nn.Sigmoid()
            )
        })
        
        # å…¨å±€ç­–ç•¥
        self.global_strategy = nn.Sequential(
            nn.Linear(self.hidden_dim, 64), nn.ReLU(), nn.Linear(64, 8)
        )
        self.adaptive_weights = nn.Sequential(
            nn.Linear(self.hidden_dim, 32), nn.ReLU(), nn.Linear(32, 5), nn.Softmax(dim=-1)
        )
        
        print(f"ğŸ¯ ä¿®å¤çš„GNNåè°ƒå™¨: {len(self.decision_heads)} ä¸ªå†³ç­–å¤´")

    def _validate_and_fix_config(self, hidden_dim, num_heads, node_dim, edge_dim):
        """éªŒè¯å¹¶ä¿®å¤é…ç½®"""
        # ğŸ”§ ä¿®å¤hidden_dimå’Œnum_headsçš„å…¼å®¹æ€§
        if hidden_dim % num_heads != 0:
            adjusted_hidden_dim = ((hidden_dim + num_heads - 1) // num_heads) * num_heads
            print(f"ğŸ”§ è‡ªåŠ¨è°ƒæ•´: hidden_dim {hidden_dim} â†’ {adjusted_hidden_dim}")
            hidden_dim = adjusted_hidden_dim
        
        return {
            'hidden_dim': hidden_dim,
            'num_heads': num_heads,
            'node_dim': node_dim,
            'edge_dim': edge_dim
        }

    def forward(self, interaction_graph):
        try:
            # ğŸ”§ å®‰å…¨çš„ç‰¹å¾æ£€æŸ¥
            if not hasattr(interaction_graph, 'node_features') or interaction_graph.node_features.size(0) == 0:
                return self._empty_output()
            
            # Transformerå¤„ç†
            transformer_output = self.graph_transformer(
                interaction_graph.node_features,
                interaction_graph.edge_indices,
                interaction_graph.edge_features
            )
            
            node_embeddings = transformer_output['node_embeddings']
            
            # åˆ†å±‚æ± åŒ–
            if node_embeddings.size(0) > 0:
                pooled_repr = self.hierarchical_pooling(
                    node_embeddings, interaction_graph.edge_indices
                )
            else:
                pooled_repr = torch.zeros(1, self.hidden_dim, device=node_embeddings.device)
            
            # ğŸ”§ å®‰å…¨çš„å¤šæ¨¡æ€å†³ç­–
            decisions = {}
            for decision_type, head in self.decision_heads.items():
                try:
                    if node_embeddings.size(0) > 0:
                        decisions[decision_type] = head(node_embeddings)
                    else:
                        decisions[decision_type] = torch.zeros(0, 1)
                except Exception as e:
                    print(f"        âš ï¸ å†³ç­–å¤´ {decision_type} å¤±è´¥: {e}")
                    # æä¾›é»˜è®¤å€¼
                    default_val = 0.0 if decision_type == 'priority' else 0.5
                    decisions[decision_type] = torch.full(
                        (node_embeddings.size(0), 1), default_val, 
                        device=node_embeddings.device
                    )
            
            # å…¨å±€ç­–ç•¥
            try:
                if pooled_repr.numel() > 0:
                    decisions['global_strategy'] = self.global_strategy(pooled_repr.squeeze(0))
                    decisions['adaptive_weights'] = self.adaptive_weights(pooled_repr.squeeze(0))
                else:
                    decisions['global_strategy'] = torch.zeros(8)
                    decisions['adaptive_weights'] = torch.ones(5) / 5
            except Exception as e:
                print(f"        âš ï¸ å…¨å±€ç­–ç•¥å¤±è´¥: {e}")
                decisions['global_strategy'] = torch.zeros(8)
                decisions['adaptive_weights'] = torch.ones(5) / 5
            
            decisions['attention_weights'] = transformer_output.get('attention_weights', [])
            decisions['node_embeddings'] = node_embeddings
            
            return decisions
            
        except Exception as e:
            print(f"âŒ GNNåè°ƒå™¨å‰å‘ä¼ æ’­å¤±è´¥: {e}")
            return self._empty_output()

    def _empty_output(self):
        """è¿”å›ç©ºè¾“å‡º"""
        return {
            'priority': torch.zeros((0, 1)),
            'cooperation': torch.zeros((0, 1)),
            'path_quality': torch.zeros((0, 1)),
            'avoidance_strength': torch.zeros((0, 1)),
            'speed_factor': torch.zeros((0, 1)),
            'global_strategy': torch.zeros(8),
            'adaptive_weights': torch.ones(5) / 5,
            'attention_weights': [],
            'node_embeddings': torch.zeros((0, self.hidden_dim))
        }

# =============================================================================
# ğŸ“Š GNNæ€§èƒ½ç›‘æ§
# =============================================================================

class GNNPerformanceMonitor:
    """ğŸ“Š GNNæ€§èƒ½ç›‘æ§"""
    
    def __init__(self):
        self.metrics = {'inference_times': [], 'attention_entropies': [], 'planning_times': []}
    
    def log_inference(self, inference_time, attention_weights, decisions):
        self.metrics['inference_times'].append(inference_time)
        if attention_weights and len(attention_weights) > 0:
            try:
                entropy = self._compute_attention_entropy(attention_weights[-1])
                self.metrics['attention_entropies'].append(entropy)
            except:
                pass
    
    def _compute_attention_entropy(self, attention_weights):
        if attention_weights.numel() == 0:
            return 0.0
        probs = F.softmax(attention_weights.flatten(), dim=-1)
        entropy = -(probs * torch.log(probs + 1e-8)).sum()
        return entropy.item()
    
    def generate_report(self, filename, planning_stats):
        print(f"ğŸ“Š GNN Performance Summary:")
        print(f"   Avg Inference Time: {np.mean(self.metrics['inference_times']):.3f}s")
        if self.metrics['attention_entropies']:
            print(f"   Avg Attention Entropy: {np.mean(self.metrics['attention_entropies']):.3f}")
        return filename

# =============================================================================
# ğŸš€ ä¿®å¤ç‰ˆæœ¬ï¼šAdvancedGNNMultiVehicleCoordinator
# =============================================================================

class AdvancedGNNMultiVehicleCoordinator:
    """ğŸš€ ä¿®å¤çš„é«˜çº§GNNå¤šè½¦åè°ƒå™¨ä¸»ç±»"""
    
    def __init__(self, map_file_path=None, optimization_level=None, gnn_enhancement_level=None, gnn_config=None):
        # é»˜è®¤é…ç½®
        if optimization_level is None:
            optimization_level = OptimizationLevel.FULL if HAS_TRYING else "full"
        if gnn_enhancement_level is None:
            gnn_enhancement_level = GNNEnhancementLevel.FULL_INTEGRATION if HAS_TRANS else "full_integration"
        
        # åŸºç¡€ç»„ä»¶åˆå§‹åŒ–
        if HAS_TRYING:
            self.base_coordinator = MultiVehicleCoordinator(map_file_path, optimization_level)
            self.environment = self.base_coordinator.environment
            self.params = self.base_coordinator.params
            self.map_data = self.base_coordinator.map_data
            print("âœ… Using trying.py MultiVehicleCoordinator")
        else:
            self.environment = self._create_fallback_environment()
            self.params = VehicleParameters()
            self.map_data = self._load_fallback_map(map_file_path)
            print("âš ï¸ Using fallback environment")
        
        # ğŸ”§ ä¿®å¤çš„GNNé…ç½® - ç¡®ä¿å…¼å®¹æ€§
        default_gnn_config = {
            'node_dim': 10, 
            'edge_dim': 6, 
            'hidden_dim': 64,    # ğŸ”§ æ”¹ä¸º64ç¡®ä¿ä¸å¤šç§num_headså…¼å®¹
            'num_heads': 4,      # ğŸ”§ æ”¹ä¸º4ï¼Œ64/4=16å®Œç¾æ•´é™¤
            'num_transformer_layers': 2,  # ğŸ”§ å‡å°‘å±‚æ•°æé«˜ç¨³å®šæ€§
            'num_pooling_levels': 2       # ğŸ”§ å‡å°‘æ± åŒ–å±‚æ•°
        }
        if gnn_config:
            default_gnn_config.update(gnn_config)
        
        # ğŸ”§ éªŒè¯å’Œä¿®æ­£é…ç½®
        default_gnn_config = self._validate_gnn_config(default_gnn_config)
        
        # åˆå§‹åŒ–GNNç»„ä»¶
        self.gnn_coordinator = AdvancedGNNCoordinator(**default_gnn_config)
        self.gnn_coordinator.eval()
        
        # å›¾æ„å»ºå™¨
        if HAS_TRANS:
            self.graph_builder = VehicleGraphBuilder(self.params)
        else:
            self.graph_builder = self._create_fallback_graph_builder()
        
        # æ€§èƒ½ç›‘æ§
        self.performance_monitor = GNNPerformanceMonitor()
        self.planning_stats = {'gnn_inferences': 0, 'total_planning_time': 0, 'vehicles_planned': 0, 'success_rate': 0.0}
        
        print(f"ğŸš€ ä¿®å¤çš„Advanced GNN Multi-Vehicle Coordinator initialized")
        print(f"ğŸ”§ ä¿®å¤é…ç½®: {default_gnn_config}")

    def _validate_gnn_config(self, config):
        """ğŸ”§ éªŒè¯å’Œä¿®æ­£GNNé…ç½®"""
        hidden_dim = config['hidden_dim']
        num_heads = config['num_heads']
        
        # æ£€æŸ¥hidden_dimæ˜¯å¦èƒ½è¢«num_headsæ•´é™¤
        if hidden_dim % num_heads != 0:
            # ç­–ç•¥1: è°ƒæ•´hidden_dimåˆ°æœ€è¿‘çš„å…¼å®¹å€¼
            adjusted_hidden_dim = ((hidden_dim + num_heads - 1) // num_heads) * num_heads
            
            # ç­–ç•¥2: å¦‚æœè°ƒæ•´å¹…åº¦å¤ªå¤§ï¼Œåˆ™è°ƒæ•´num_heads
            if abs(adjusted_hidden_dim - hidden_dim) > hidden_dim * 0.1:
                possible_heads = [1, 2, 4, 8, 16, 32, 64]
                best_heads = min(possible_heads, key=lambda h: abs(h - num_heads) if hidden_dim % h == 0 else float('inf'))
                
                if hidden_dim % best_heads == 0:
                    print(f"ğŸ”§ Auto-adjusting num_heads: {num_heads} â†’ {best_heads} (for hidden_dim={hidden_dim})")
                    config['num_heads'] = best_heads
                else:
                    print(f"ğŸ”§ Auto-adjusting hidden_dim: {hidden_dim} â†’ {adjusted_hidden_dim} (for num_heads={num_heads})")
                    config['hidden_dim'] = adjusted_hidden_dim
            else:
                print(f"ğŸ”§ Auto-adjusting hidden_dim: {hidden_dim} â†’ {adjusted_hidden_dim} (for num_heads={num_heads})")
                config['hidden_dim'] = adjusted_hidden_dim
        
        return config

    def create_scenarios_from_json(self):
        """åˆ›å»ºåœºæ™¯"""
        if HAS_TRYING and hasattr(self, 'base_coordinator'):
            return self.base_coordinator.create_scenario_from_json()
        else:
            return self._create_test_scenarios()

    def plan_all_vehicles_with_gnn(self, scenarios):
        """ğŸ§  ä¸»è§„åˆ’å‡½æ•°"""
        print(f"\nğŸ§  Advanced GNN Multi-Vehicle Planning: {len(scenarios)} vehicles")
        
        # GNNæ™ºèƒ½æ’åº
        gnn_sorted_scenarios = self._gnn_intelligent_sorting(scenarios)
        
        results = {}
        high_priority_trajectories = []
        total_start_time = time.time()
        
        # é€è½¦è§„åˆ’
        for i, scenario in enumerate(gnn_sorted_scenarios):
            print(f"\n--- ğŸš— Vehicle {scenario['id']} (GNN Rank #{i+1}) ---")
            
            vehicle_start_time = time.time()
            
            # æ„å»ºè½¦è¾†ä¸Šä¸‹æ–‡
            vehicles_info = self._create_vehicle_context(scenario, gnn_sorted_scenarios, high_priority_trajectories)
            
            # GNNæ¨ç†
            gnn_guidance = self._gnn_inference_for_vehicle(vehicles_info, scenario['id'])
            
            # æ‰§è¡Œè§„åˆ’
            trajectory = self._plan_single_vehicle_with_gnn(scenario, gnn_guidance, high_priority_trajectories)
            
            vehicle_planning_time = time.time() - vehicle_start_time
            
            # è®°å½•ç»“æœ
            if trajectory:
                print(f"âœ… SUCCESS: {len(trajectory)} waypoints")
                results[scenario['id']] = {
                    'trajectory': trajectory, 'color': scenario['color'],
                    'description': scenario['description'], 'planning_time': vehicle_planning_time,
                    'gnn_guidance': gnn_guidance
                }
                high_priority_trajectories.append(trajectory)
            else:
                print(f"âŒ FAILED")
                results[scenario['id']] = {
                    'trajectory': [], 'color': scenario['color'],
                    'description': scenario['description'], 'planning_time': vehicle_planning_time,
                    'gnn_guidance': gnn_guidance
                }
            
            self.planning_stats['vehicles_planned'] += 1
            self.planning_stats['total_planning_time'] += vehicle_planning_time
        
        # æœ€ç»ˆç»Ÿè®¡
        total_time = time.time() - total_start_time
        success_count = sum(1 for r in results.values() if r['trajectory'])
        self.planning_stats['success_rate'] = success_count / len(scenarios) if scenarios else 0
        
        print(f"\nğŸ“Š Advanced GNN Results: {success_count}/{len(scenarios)} ({100*self.planning_stats['success_rate']:.1f}%) in {total_time:.2f}s")
        
        return results, gnn_sorted_scenarios

    def _gnn_intelligent_sorting(self, scenarios):
        """ğŸ§  GNNæ™ºèƒ½æ’åº"""
        print("ğŸ§  GNN Intelligent Sorting...")
        
        try:
            vehicles_info = [{'id': s['id'], 'current_state': s['start'], 'goal_state': s['goal'], 'priority': s['priority']} for s in scenarios]
            global_graph = self.graph_builder.build_interaction_graph(vehicles_info)
            
            start_time = time.time()
            with torch.no_grad():
                gnn_decisions = self.gnn_coordinator(global_graph)
            
            self.planning_stats['gnn_inferences'] += 1
            self.performance_monitor.log_inference(time.time() - start_time, gnn_decisions.get('attention_weights'), gnn_decisions)
            
            # æ™ºèƒ½ä¼˜å…ˆçº§è®¡ç®—
            intelligent_priorities = []
            priority_adj = gnn_decisions.get('priority', torch.zeros(len(scenarios), 1))
            cooperation_scores = gnn_decisions.get('cooperation', torch.zeros(len(scenarios), 1))
            
            for i, scenario in enumerate(scenarios):
                if i < priority_adj.shape[0]:
                    base_priority = scenario['priority']
                    gnn_adjustment = priority_adj[i, 0].item() if priority_adj.numel() > i else 0.0
                    cooperation = cooperation_scores[i, 0].item() if cooperation_scores.numel() > i else 0.5
                    intelligent_priority = base_priority + gnn_adjustment * 2.0 + cooperation * 1.0
                    
                    intelligent_priorities.append({
                        'scenario': scenario, 'intelligent_priority': intelligent_priority,
                        'gnn_adjustment': gnn_adjustment, 'cooperation_score': cooperation
                    })
                    
                    print(f"   V{scenario['id']}: {base_priority:.1f} â†’ {intelligent_priority:.2f}")
                else:
                    intelligent_priorities.append({
                        'scenario': scenario, 'intelligent_priority': scenario['priority'],
                        'gnn_adjustment': 0.0, 'cooperation_score': 0.5
                    })
            
            intelligent_priorities.sort(key=lambda x: x['intelligent_priority'], reverse=True)
            return [item['scenario'] for item in intelligent_priorities]
            
        except Exception as e:
            print(f"âš ï¸ GNNæ’åºå¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤æ’åº")
            return sorted(scenarios, key=lambda x: x['priority'], reverse=True)

    def _gnn_inference_for_vehicle(self, vehicles_info, target_vehicle_id):
        """ğŸ§  å•è½¦GNNæ¨ç†"""
        try:
            interaction_graph = self.graph_builder.build_interaction_graph(vehicles_info)
            
            start_time = time.time()
            with torch.no_grad():
                gnn_decisions = self.gnn_coordinator(interaction_graph)
            
            self.planning_stats['gnn_inferences'] += 1
            
            # æå–ç›®æ ‡è½¦è¾†æŒ‡å¯¼
            target_index = next((i for i, v in enumerate(vehicles_info) if v['id'] == target_vehicle_id), 0)
            guidance = {}
            
            for decision_type, values in gnn_decisions.items():
                try:
                    if isinstance(values, torch.Tensor) and len(values.shape) >= 2 and target_index < values.shape[0]:
                        val = values[target_index].squeeze()
                        guidance[decision_type] = val.item() if val.numel() == 1 else val
                    elif isinstance(values, torch.Tensor) and len(values.shape) == 1:
                        guidance[decision_type] = values[0].item() if values.numel() == 1 else values
                except:
                    # æä¾›é»˜è®¤å€¼
                    if decision_type == 'priority':
                        guidance[decision_type] = 0.0
                    elif decision_type in ['cooperation', 'path_quality', 'avoidance_strength', 'speed_factor']:
                        guidance[decision_type] = 0.5
            
            return guidance
            
        except Exception as e:
            print(f"âš ï¸ GNNæ¨ç†å¤±è´¥: {e}")
            return {'priority': 0.0, 'cooperation': 0.5, 'path_quality': 0.5, 'avoidance_strength': 0.5, 'speed_factor': 1.0}

    def _plan_single_vehicle_with_gnn(self, scenario, gnn_guidance, existing_trajectories):
        """ğŸš— GNNæŒ‡å¯¼çš„å•è½¦è§„åˆ’"""
        if HAS_TRYING:
            planner = VHybridAStarPlanner(self.environment, self.base_coordinator.optimization_level)
            self._apply_gnn_guidance_to_planner(planner, gnn_guidance)
            return planner.search_with_waiting(scenario['start'], scenario['goal'], scenario['id'], existing_trajectories)
        else:
            return self._fallback_planning(scenario, gnn_guidance)

    def _apply_gnn_guidance_to_planner(self, planner, guidance):
        """ğŸ¯ åº”ç”¨GNNæŒ‡å¯¼"""
        if not guidance or not hasattr(planner, 'params'):
            return
        
        try:
            priority_adj = guidance.get('priority', 0.0)
            cooperation = guidance.get('cooperation', 0.5)
            avoidance_strength = guidance.get('avoidance_strength', 0.5)
            speed_factor = guidance.get('speed_factor', 1.0)
            
            if priority_adj > 0.3:
                planner.params.max_speed *= (1.0 + priority_adj * 0.1)
                planner.max_iterations = int(planner.max_iterations * 1.2)
            elif priority_adj < -0.3:
                planner.params.green_additional_safety *= (1.0 + abs(priority_adj) * 0.2)
                planner.params.max_speed *= (1.0 - abs(priority_adj) * 0.1)
            
            if cooperation > 0.7:
                planner.params.green_additional_safety *= (1.0 + cooperation * 0.15)
            
            if avoidance_strength > 0.7:
                planner.params.green_additional_safety *= (1.0 + avoidance_strength * 0.3)
            
            planner.params.max_speed *= speed_factor
            
            print(f"      ğŸ¯ GNN Guidance: priority={priority_adj:.2f}, coop={cooperation:.2f}, avoid={avoidance_strength:.2f}")
            
        except Exception as e:
            print(f"      âš ï¸ åº”ç”¨GNNæŒ‡å¯¼å¤±è´¥: {e}")

    def create_animation_with_gnn_analysis(self, results, scenarios):
        """ğŸ¬ åˆ›å»ºåŠ¨ç”»"""
        if HAS_TRYING and hasattr(self, 'base_coordinator'):
            return self.base_coordinator.create_animation(results, scenarios)
        else:
            self._create_simple_plot(results, scenarios)

    def generate_gnn_performance_report(self, filename="gnn_performance_report.html"):
        """ğŸ“Š ç”ŸæˆæŠ¥å‘Š"""
        return self.performance_monitor.generate_report(filename, self.planning_stats)

    def _create_vehicle_context(self, target_scenario, all_scenarios, existing_trajectories):
        """åˆ›å»ºè½¦è¾†ä¸Šä¸‹æ–‡"""
        vehicles_info = [{'id': target_scenario['id'], 'current_state': target_scenario['start'], 'goal_state': target_scenario['goal'], 'priority': target_scenario['priority']}]
        
        for scenario in all_scenarios:
            if scenario['id'] != target_scenario['id']:
                distance = math.sqrt((scenario['start'].x - target_scenario['start'].x)**2 + (scenario['start'].y - target_scenario['start'].y)**2)
                if distance < 50:
                    vehicles_info.append({'id': scenario['id'], 'current_state': scenario['start'], 'goal_state': scenario['goal'], 'priority': scenario['priority']})
        
        return vehicles_info

    # Fallback methods
    def _create_fallback_environment(self):
        class FallbackEnv:
            def __init__(self): self.size = 100; self.map_name = "fallback"
            def load_from_json(self, file_path): return {"mock": "data"}
            def is_collision_free(self, state, params): return True
        return FallbackEnv()

    def _load_fallback_map(self, map_file_path):
        if map_file_path and os.path.exists(map_file_path):
            try:
                with open(map_file_path, 'r') as f:
                    return json.load(f)
            except:
                pass
        return None

    def _create_fallback_graph_builder(self):
        class FallbackGraphBuilder:
            def __init__(self, params): self.params = params
            def build_interaction_graph(self, vehicles_info):
                n = len(vehicles_info)
                return VehicleInteractionGraph(
                    node_features=torch.randn(n, 10), edge_indices=torch.zeros((2, 0), dtype=torch.long),
                    edge_features=torch.zeros((0, 6)), vehicle_ids=[v['id'] for v in vehicles_info],
                    adjacency_matrix=torch.zeros((n, n)), global_features=torch.zeros(8)
                )
        return FallbackGraphBuilder(self.params)

    def _create_test_scenarios(self):
        return [
            {'id': 1, 'priority': 1, 'color': 'red', 'start': VehicleState(10, 10, 0, 3, 0), 'goal': VehicleState(90, 90, 0, 2, 0), 'description': 'Test Vehicle 1'},
            {'id': 2, 'priority': 1, 'color': 'blue', 'start': VehicleState(90, 10, math.pi/2, 3, 0), 'goal': VehicleState(10, 90, math.pi/2, 2, 0), 'description': 'Test Vehicle 2'}
        ]

    def _fallback_planning(self, scenario, guidance):
        """Fallbackè§„åˆ’"""
        start, goal = scenario['start'], scenario['goal']
        trajectory = [start]
        for i in range(1, 11):
            t = i / 10
            x = start.x + t * (goal.x - start.x)
            y = start.y + t * (goal.y - start.y)
            trajectory.append(VehicleState(x, y, start.theta, start.v, i * 1.0))
        return trajectory

    def _create_simple_plot(self, results, scenarios):
        """ç®€å•ç»˜å›¾"""
        try:
            import matplotlib.pyplot as plt
            fig, ax = plt.subplots(figsize=(10, 10))
            for vehicle_id, result in results.items():
                if result['trajectory']:
                    traj = result['trajectory']
                    xs, ys = [s.x for s in traj], [s.y for s in traj]
                    ax.plot(xs, ys, color=result['color'], linewidth=2, label=result['description'])
            ax.set_xlim(0, 100); ax.set_ylim(0, 100); ax.legend(); ax.set_title("Advanced GNN Planning Results")
            plt.show()
        except ImportError:
            print("âš ï¸ Matplotlib not available for plotting")

# =============================================================================
# ğŸš€ ä¸»å‡½æ•°
# =============================================================================

def main():
    """ğŸš€ ä¸»å‡½æ•°"""
    print("ğŸš€ Advanced GNN Framework for Multi-Vehicle Path Planning - ä¿®å¤ç‰ˆ")
    print("=" * 80)
    print("ğŸ¯ çŠ¶æ€:")
    print(f"   trying.py: {'âœ… é›†æˆ' if HAS_TRYING else 'âŒ æœªæ‰¾åˆ°'}")
    print(f"   trans.py: {'âœ… é›†æˆ' if HAS_TRANS else 'âŒ æœªæ‰¾åˆ°'}")
    print(f"   PyTorch Geometric: {'âœ… å¯ç”¨' if HAS_TORCH_GEOMETRIC else 'âŒ ä½¿ç”¨å›é€€'}")
    print("=" * 80)
    
    # é€‰æ‹©åœ°å›¾
    if HAS_TRYING:
        selected_file = interactive_json_selection()
    else:
        json_files = [f for f in os.listdir('.') if f.endswith('.json')]
        selected_file = json_files[0] if json_files else None
        print(f"ğŸ“ ä½¿ç”¨: {selected_file or 'test scenarios'}")
    
    # ğŸ”§ ä½¿ç”¨ä¿®å¤çš„å®‰å…¨é…ç½®
    print("\nğŸ§  åˆå§‹åŒ–ä¿®å¤çš„Advanced GNN Coordinator...")
    coordinator = AdvancedGNNMultiVehicleCoordinator(
        map_file_path=selected_file,
        gnn_config={
            'hidden_dim': 64,    # ğŸ”§ å®‰å…¨å€¼ï¼š64/4=16
            'num_heads': 4,      # ğŸ”§ å®‰å…¨å€¼ï¼šç¡®ä¿æ•´é™¤æ€§
            'num_transformer_layers': 2,  # ğŸ”§ é™ä½å¤æ‚åº¦
            'num_pooling_levels': 2       # ğŸ”§ ç®€åŒ–æ± åŒ–
        }
    )
    
    # åˆ›å»ºåœºæ™¯
    scenarios = coordinator.create_scenarios_from_json()
    if not scenarios:
        print("âŒ No scenarios found")
        return
    
    print(f"\nğŸš— è§„åˆ’ {len(scenarios)} è¾†è½¦...")
    for s in scenarios:
        print(f"   Vehicle {s['id']}: {s['description']}")
    
    # æ‰§è¡Œè§„åˆ’
    start_time = time.time()
    results, sorted_scenarios = coordinator.plan_all_vehicles_with_gnn(scenarios)
    total_time = time.time() - start_time
    
    # ç»“æœåˆ†æ
    success_count = sum(1 for r in results.values() if r['trajectory'])
    
    print(f"\nğŸ“Š æœ€ç»ˆç»“æœ:")
    print(f"   ğŸ¯ æˆåŠŸç‡: {success_count}/{len(scenarios)} ({100*success_count/len(scenarios):.1f}%)")
    print(f"   â±ï¸ æ€»æ—¶é—´: {total_time:.2f}s")
    print(f"   ğŸ§  GNNæ¨ç†: {coordinator.planning_stats['gnn_inferences']}æ¬¡")
    
    # è¯¦ç»†ç»“æœ
    print(f"\nğŸ“‹ è½¦è¾†è¯¦æƒ…:")
    for vehicle_id, result in results.items():
        status = "âœ… æˆåŠŸ" if result['trajectory'] else "âŒ å¤±è´¥"
        traj_info = f"{len(result['trajectory'])} ç‚¹" if result['trajectory'] else "æ— è½¨è¿¹"
        print(f"   Vehicle {vehicle_id}: {status} - {traj_info}")
    
    # å¯è§†åŒ–
    if success_count > 0:
        print(f"\nğŸ¬ åˆ›å»ºå¯è§†åŒ–...")
        try:
            coordinator.create_animation_with_gnn_analysis(results, scenarios)
        except Exception as e:
            print(f"âš ï¸ å¯è§†åŒ–å¤±è´¥: {e}")
        
        # ä¿å­˜æ•°æ®
        if HAS_TRYING:
            try:
                save_trajectories(results, f"advanced_gnn_results_{int(time.time())}.json")
                print("ğŸ’¾ ç»“æœå·²ä¿å­˜")
            except:
                print("âš ï¸ ä¿å­˜å¤±è´¥")
    
    print(f"\nğŸ‰ Advanced GNN Framework æ¼”ç¤ºå®Œæˆ!")

def quick_test():
    """ğŸ§ª å¿«é€Ÿæµ‹è¯•"""
    print("ğŸ§ª Quick Test Mode")
    
    # ğŸ”§ ä½¿ç”¨ä¿®å¤çš„å®‰å…¨é…ç½®
    coordinator = AdvancedGNNMultiVehicleCoordinator(
        gnn_config={'hidden_dim': 32, 'num_heads': 4, 'num_transformer_layers': 1}
    )
    
    test_scenarios = coordinator._create_test_scenarios()
    results, _ = coordinator.plan_all_vehicles_with_gnn(test_scenarios)
    
    success = sum(1 for r in results.values() if r['trajectory'])
    print(f"ğŸ§ª Test Result: {success}/{len(test_scenarios)} vehicles planned successfully")
    
    return results

# ä¾¿æ·å‡½æ•°
def create_advanced_coordinator(map_file=None, **gnn_config):
    """ğŸ¯ ä¾¿æ·åˆ›å»ºå‡½æ•°"""
    # ğŸ”§ åº”ç”¨é»˜è®¤å®‰å…¨é…ç½®
    safe_config = {'hidden_dim': 64, 'num_heads': 4, 'num_transformer_layers': 2}
    safe_config.update(gnn_config)
    return AdvancedGNNMultiVehicleCoordinator(map_file_path=map_file, gnn_config=safe_config)

def test_config_compatibility():
    """ğŸ§ª æµ‹è¯•é…ç½®å…¼å®¹æ€§"""
    print("ğŸ§ª Testing GNN Configuration Compatibility...")
    
    test_configs = [
        {'hidden_dim': 64, 'num_heads': 4},   # âœ… 64/4=16
        {'hidden_dim': 64, 'num_heads': 8},   # âœ… 64/8=8
        {'hidden_dim': 32, 'num_heads': 4},   # âœ… 32/4=8
        {'hidden_dim': 128, 'num_heads': 8},  # âœ… 128/8=16
        {'hidden_dim': 64, 'num_heads': 6},   # âŒ 64/6=10.67 (will auto-fix)
    ]
    
    for i, config in enumerate(test_configs):
        print(f"\nğŸ§ª Test {i+1}: hidden_dim={config['hidden_dim']}, num_heads={config['num_heads']}")
        try:
            coordinator = AdvancedGNNMultiVehicleCoordinator(gnn_config=config)
            actual_config = coordinator.gnn_coordinator.hidden_dim
            print(f"    âœ… Success: final hidden_dim={actual_config}")
        except Exception as e:
            print(f"    âŒ Failed: {e}")

print("âœ… ä¿®å¤çš„Advanced GNN Frameworkå·²åŠ è½½!")
print("ğŸ“– ä½¿ç”¨æ–¹æ³•: main() | quick_test() | test_config_compatibility() | create_advanced_coordinator()")
print("ğŸ”§ æ¨èé…ç½®:")
print("   â€¢ hidden_dim=64, num_heads=4   (16 dim/head)")
print("   â€¢ hidden_dim=64, num_heads=8   (8 dim/head)")  
print("   â€¢ hidden_dim=32, num_heads=4   (8 dim/head)")

def safe_main():
    """ğŸ›¡ï¸ å®‰å…¨çš„ä¸»å‡½æ•°ï¼Œå¸¦é”™è¯¯å¤„ç†"""
    try:
        main()
    except Exception as e:
        print(f"\nâŒ Error occurred: {e}")
        print("\nğŸ”§ æ•…éšœæ’é™¤å»ºè®®:")
        print("   1. æ£€æŸ¥trying.pyå’Œtrans.pyæ˜¯å¦åœ¨åŒç›®å½•")
        print("   2. å°è¯•æ›´å°çš„GNNé…ç½®: hidden_dim=32, num_heads=4")
        print("   3. è¿è¡Œtest_config_compatibility()éªŒè¯è®¾ç½®")
        print("   4. è¿è¡Œquick_test()æ£€æŸ¥åŸºæœ¬åŠŸèƒ½")
        
        print(f"\nğŸ§ª è¿è¡Œå¿«é€Ÿæµ‹è¯•ä½œä¸ºå›é€€...")
        try:
            quick_test()
        except Exception as e2:
            print(f"âŒ å¿«é€Ÿæµ‹è¯•ä¹Ÿå¤±è´¥: {e2}")
            print("ğŸ”§ è¯·æ£€æŸ¥PyTorchå®‰è£…å’Œä¾èµ–")

if __name__ == "__main__":
    safe_main()