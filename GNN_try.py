#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆtrans.py - é›†æˆé¢„è®­ç»ƒGNNæ¨¡å‹
ä¿®å¤åŸç‰ˆç¼ºé™·ï¼šæ·»åŠ é¢„è®­ç»ƒæ¨¡å‹åŠ è½½ã€å¢å¼ºGNNæ¶æ„ã€æ”¹è¿›è®­ç»ƒæµç¨‹
"""

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch_geometric.nn as pyg_nn
from torch_geometric.data import Data
import math
import time
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
from enum import Enum
import os
import json
# ğŸ”§ æ­£ç¡®çš„å¯¼å…¥æ–¹å¼ï¼ˆä½¿ç”¨åˆ«åï¼‰
from Pretraining_gnn import SafetyEnhancedTrainingConfig as TrainingConfig
# å¯¼å…¥åŸæœ‰ç»„ä»¶
from trying import (
    VehicleState, VehicleParameters, UnstructuredEnvironment, 
    VHybridAStarPlanner, MultiVehicleCoordinator, OptimizationLevel,
    HybridNode, ConflictDensityAnalyzer, TimeSync,
    interactive_json_selection, OptimizedTrajectoryProcessor,
    CompleteQPOptimizer, EnhancedConvexSpaceSTDiagram
)

class GNNEnhancementLevel(Enum):
    """GNNå¢å¼ºçº§åˆ«"""
    PRIORITY_ONLY = "priority_only"           
    EXPANSION_GUIDE = "expansion_guide"       
    FULL_INTEGRATION = "full_integration"
    PRETRAINED_FULL = "pretrained_full"  # ğŸ†• å®Œæ•´é¢„è®­ç»ƒç‰ˆæœ¬

@dataclass
class VehicleInteractionGraph:
    """è½¦è¾†äº¤äº’å›¾ç»“æ„ - å…¼å®¹PyTorch Geometric"""
    node_features: torch.Tensor      # (N, feature_dim) èŠ‚ç‚¹ç‰¹å¾
    edge_indices: torch.Tensor       # (2, E) è¾¹ç´¢å¼•
    edge_features: torch.Tensor      # (E, edge_dim) è¾¹ç‰¹å¾
    vehicle_ids: List[int]           # èŠ‚ç‚¹åˆ°è½¦è¾†IDæ˜ å°„
    adjacency_matrix: torch.Tensor   # (N, N) é‚»æ¥çŸ©é˜µ
    global_features: torch.Tensor    # (global_dim,) å…¨å±€ç‰¹å¾
    
    def to_pyg_data(self) -> Data:
        """ğŸ†• è½¬æ¢ä¸ºPyTorch Geometric Dataå¯¹è±¡"""
        return Data(
            x=self.node_features,
            edge_index=self.edge_indices,
            edge_attr=self.edge_features,
            global_features=self.global_features
        )

class PretrainedGNNLoader:
    """ğŸ†• é¢„è®­ç»ƒGNNæ¨¡å‹åŠ è½½å™¨"""
    
    def __init__(self):
        self.model_cache = {}
        self.available_models = self._scan_available_models()
    
    def _scan_available_models(self) -> List[str]:
        """æ‰«æå¯ç”¨çš„é¢„è®­ç»ƒæ¨¡å‹"""
        models = []
        for filename in os.listdir('.'):
            if filename.endswith('_gnn_model.pth'):
                models.append(filename)
        return models
    
    def load_pretrained_model(self, model_path: str = None) -> Optional[nn.Module]:
        """ğŸ”§ ä¿®å¤çš„åŠ è½½é¢„è®­ç»ƒæ¨¡å‹"""
        if model_path is None:
            # ğŸ†• æ‰©å±•æœç´¢èŒƒå›´ï¼ŒåŒ…æ‹¬å„ç§å¯èƒ½çš„æ¨¡å‹æ–‡ä»¶
            candidate_models = [
                'best_gnn_model.pth', 
                'final_gnn_model.pth',
                'best_fixed_gnn_model.pth',
                'final_fixed_gnn_model.pth', 
                'best_map_aware_gnn_model.pth',
                'final_map_aware_gnn_model.pth'
            ]
            
            for model_name in candidate_models:
                if os.path.exists(model_name):
                    model_path = model_name
                    print(f"ğŸ” æ‰¾åˆ°å€™é€‰æ¨¡å‹: {model_name}")
                    break
        
        if model_path is None or not os.path.exists(model_path):
            print(f"âš ï¸ æœªæ‰¾åˆ°é¢„è®­ç»ƒæ¨¡å‹ï¼Œå°†ä½¿ç”¨éšæœºåˆå§‹åŒ–")
            print(f"   å¯ç”¨æ¨¡å‹: {self.available_models}")
            print(f"   è¯·å…ˆè¿è¡Œé¢„è®­ç»ƒè„šæœ¬ç”Ÿæˆæ¨¡å‹")
            return None
        
        try:
            print(f"ğŸ“¥ å°è¯•åŠ è½½é¢„è®­ç»ƒGNNæ¨¡å‹: {model_path}")
            
            checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
            config = checkpoint.get('config')
            
            if config is None:
                print(f"âŒ æ¨¡å‹æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œç¼ºå°‘é…ç½®ä¿¡æ¯")
                return None
            
            # ğŸ†• å°è¯•å¤šç§å…¼å®¹çš„æ¨¡å‹ç±»
            model = None
            
            # ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šå°è¯•åŠ è½½åœ°å›¾æ„ŸçŸ¥æ¨¡å‹
            try:
                if 'map_aware' in model_path:
                    print(f"   å°è¯•åŠ è½½åœ°å›¾æ„ŸçŸ¥GNNæ¨¡å‹...")
                    # ğŸ†• åˆ›å»ºå…¼å®¹çš„ç®€åŒ–GNN
                    model = self._create_compatible_gnn(config, model_type='map_aware')
                    model.load_state_dict(checkpoint['model_state_dict'], strict=False)
                    print(f"   âœ… åœ°å›¾æ„ŸçŸ¥æ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as e:
                print(f"   âš ï¸ åœ°å›¾æ„ŸçŸ¥æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
                model = None
            
            # ç¬¬äºŒä¼˜å…ˆçº§ï¼šå°è¯•åŠ è½½ä¿®å¤ç‰ˆæ¨¡å‹
            if model is None:
                try:
                    if 'fixed' in model_path:
                        print(f"   å°è¯•åŠ è½½ä¿®å¤ç‰ˆGNNæ¨¡å‹...")
                        model = self._create_compatible_gnn(config, model_type='fixed')
                        model.load_state_dict(checkpoint['model_state_dict'], strict=False)
                        print(f"   âœ… ä¿®å¤ç‰ˆæ¨¡å‹åŠ è½½æˆåŠŸ")
                except Exception as e:
                    print(f"   âš ï¸ ä¿®å¤ç‰ˆæ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
                    model = None
            
            # ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼šå°è¯•åŸºç¡€æ¨¡å‹
            if model is None:
                try:
                    print(f"   å°è¯•åŠ è½½åŸºç¡€GNNæ¨¡å‹...")
                    model = self._create_compatible_gnn(config, model_type='basic')
                    model.load_state_dict(checkpoint['model_state_dict'], strict=False)
                    print(f"   âœ… åŸºç¡€æ¨¡å‹åŠ è½½æˆåŠŸ")
                except Exception as e:
                    print(f"   âš ï¸ åŸºç¡€æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
                    model = None
            
            if model is None:
                print(f"âŒ æ‰€æœ‰æ¨¡å‹åŠ è½½æ–¹å¼éƒ½å¤±è´¥")
                return None
            
            model.eval()  # æ¨ç†æ¨¡å¼
            
            # ç¼“å­˜æ¨¡å‹
            self.model_cache[model_path] = model
            
            # æ‰“å°æ¨¡å‹ä¿¡æ¯
            train_losses = checkpoint.get('train_losses', [])
            val_losses = checkpoint.get('val_losses', [])
            best_val_loss = checkpoint.get('best_val_loss', 'unknown')
            
            print(f"âœ… é¢„è®­ç»ƒæ¨¡å‹åŠ è½½æˆåŠŸ")
            print(f"   æ¨¡å‹æ–‡ä»¶: {model_path}")
            print(f"   è®­ç»ƒå†å²: {len(train_losses)} epochs")
            print(f"   æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss}")
            
            return model
            
        except Exception as e:
            print(f"âŒ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å¤±è´¥: {str(e)}")
            print(f"   å°†å›é€€åˆ°éšæœºåˆå§‹åŒ–")
            return None
    
    def _create_compatible_gnn(self, config, model_type: str = 'basic') -> nn.Module:
        """ğŸ†• åˆ›å»ºå…¼å®¹çš„GNNæ¨¡å‹"""
        
        # ğŸ†• å…¼å®¹çš„ç®€åŒ–GNNç±»
        class CompatibleGNN(nn.Module):
            def __init__(self, config):
                super().__init__()
                
                # æ ¹æ®æ¨¡å‹ç±»å‹è®¾ç½®ç»´åº¦
                if model_type == 'map_aware':
                    self.node_dim = 12
                    self.edge_dim = 6
                elif model_type == 'fixed':
                    self.node_dim = 8  
                    self.edge_dim = 4
                else:  # basic
                    self.node_dim = 10
                    self.edge_dim = 6
                
                self.global_dim = 8
                self.hidden_dim = getattr(config, 'hidden_dim', 64)
                
                # ç®€åŒ–çš„ç¼–ç å™¨
                self.node_encoder = nn.Sequential(
                    nn.Linear(self.node_dim, self.hidden_dim),
                    nn.ReLU(),
                    nn.Dropout(getattr(config, 'dropout', 0.1))
                )
                
                # ç®€åŒ–çš„GNNå±‚
                self.gnn_layers = nn.ModuleList([
                    pyg_nn.GCNConv(self.hidden_dim, self.hidden_dim)
                    for _ in range(getattr(config, 'num_layers', 2))
                ])
                
                # å†³ç­–è¾“å‡ºå¤´
                self.decision_heads = nn.ModuleDict({
                    'priority': nn.Sequential(
                        nn.Linear(self.hidden_dim, 32),
                        nn.ReLU(),
                        nn.Linear(32, 1),
                        nn.Tanh()
                    ),
                    'cooperation': nn.Sequential(
                        nn.Linear(self.hidden_dim, 32),
                        nn.ReLU(),
                        nn.Linear(32, 1),
                        nn.Sigmoid()
                    ),
                    'urgency': nn.Sequential(
                        nn.Linear(self.hidden_dim, 32),
                        nn.ReLU(),
                        nn.Linear(32, 1),
                        nn.Sigmoid()
                    ),
                    'safety': nn.Sequential(
                        nn.Linear(self.hidden_dim, 32),
                        nn.ReLU(),
                        nn.Linear(32, 1),
                        nn.Sigmoid()
                    ),
                    'speed_adjustment': nn.Sequential(
                        nn.Linear(self.hidden_dim, 32),
                        nn.ReLU(),
                        nn.Linear(32, 1),
                        nn.Tanh()
                    ),
                    'route_preference': nn.Sequential(
                        nn.Linear(self.hidden_dim, 32),
                        nn.ReLU(),
                        nn.Linear(32, 3),
                        nn.Softmax(dim=-1)
                    )
                })
            
            def forward(self, graph_or_batch):
                """å…¼å®¹çš„å‰å‘ä¼ æ’­"""
                # å…¼å®¹ä¸åŒçš„è¾“å…¥æ ¼å¼
                if hasattr(graph_or_batch, 'x'):
                    x = graph_or_batch.x
                    edge_index = graph_or_batch.edge_index
                else:
                    x = graph_or_batch.node_features
                    edge_index = graph_or_batch.edge_indices
                
                if x.size(0) == 0:
                    return {
                        'priority': torch.zeros((0, 1)),
                        'cooperation': torch.zeros((0, 1)),
                        'urgency': torch.zeros((0, 1)),
                        'safety': torch.zeros((0, 1)),
                        'speed_adjustment': torch.zeros((0, 1)),
                        'route_preference': torch.zeros((0, 3)),
                        'global_coordination': torch.zeros(4),
                        'node_embeddings': torch.zeros((0, self.hidden_dim))
                    }
                
                # èŠ‚ç‚¹ç¼–ç 
                x = self.node_encoder(x)
                
                # GNNå±‚
                for gnn_layer in self.gnn_layers:
                    x = F.relu(gnn_layer(x, edge_index))
                    x = F.dropout(x, p=0.1, training=self.training)
                
                # ç”Ÿæˆå†³ç­–
                decisions = {}
                for decision_type, head in self.decision_heads.items():
                    decisions[decision_type] = head(x)
                
                # æ·»åŠ å…¼å®¹æ€§è¾“å‡º
                decisions['global_coordination'] = torch.zeros(4)
                decisions['node_embeddings'] = x
                
                return decisions
        
        return CompatibleGNN(config)
    
    def get_model_info(self, model_path: str) -> Dict:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        try:
            checkpoint = torch.load(model_path, map_location='cpu')
            return {
                'config': checkpoint.get('config'),
                'best_val_loss': checkpoint.get('best_val_loss'),
                'train_epochs': len(checkpoint.get('train_losses', [])),
                'model_size': sum(p.numel() for p in checkpoint['model_state_dict'].values())
            }
        except:
            return {}

class EnhancedVehicleGraphBuilder:
    """ğŸ†• å¢å¼ºçš„è½¦è¾†äº¤äº’å›¾æ„å»ºå™¨"""
    
    def __init__(self, params: VehicleParameters):
        self.params = params
        self.interaction_radius = 50.0
        self.node_feature_dim = 18      
        self.edge_feature_dim = 6       
        self.global_feature_dim = 8
        
        # ğŸ†• æ·»åŠ ç‰¹å¾æ ‡å‡†åŒ–
        self.feature_stats = {
            'node_mean': None,
            'node_std': None,
            'edge_mean': None,
            'edge_std': None,
            'global_mean': None,
            'global_std': None
        }
        
    def build_interaction_graph(self, vehicles_info: List[Dict]) -> VehicleInteractionGraph:
        """æ„å»ºå¢å¼ºçš„è½¦è¾†äº¤äº’å›¾"""
        n_vehicles = len(vehicles_info)
        if n_vehicles == 0:
            return self._create_empty_graph()
        
        print(f"        ğŸ”„ æ„å»ºå¢å¼ºäº¤äº’å›¾: {n_vehicles}è¾†è½¦")
        
        # æå–ç‰¹å¾
        node_features = self._extract_enhanced_node_features(vehicles_info)
        edge_indices, edge_features, adjacency_matrix = self._build_enhanced_edges(vehicles_info)
        global_features = self._extract_enhanced_global_features(vehicles_info)
        
        # ğŸ†• ç‰¹å¾æ ‡å‡†åŒ–
        node_features = self._normalize_features(node_features, 'node')
        if edge_features:
            edge_features = self._normalize_features(edge_features, 'edge')
        global_features = self._normalize_features([global_features], 'global')[0]
        
        vehicle_ids = [v['id'] for v in vehicles_info]
        
        print(f"         èŠ‚ç‚¹: {len(node_features)}, è¾¹: {len(edge_indices)}, ç‰¹å¾ç»´åº¦: {len(node_features[0]) if node_features else 0}")
        
        return VehicleInteractionGraph(
            node_features=torch.tensor(node_features, dtype=torch.float32),
            edge_indices=torch.tensor(edge_indices, dtype=torch.long).T if edge_indices else torch.zeros((2, 0), dtype=torch.long),
            edge_features=torch.tensor(edge_features, dtype=torch.float32),
            vehicle_ids=vehicle_ids,
            adjacency_matrix=torch.tensor(adjacency_matrix, dtype=torch.float32),
            global_features=torch.tensor(global_features, dtype=torch.float32)
        )
    
    def _extract_enhanced_node_features(self, vehicles_info: List[Dict]) -> List[List[float]]:
        """ğŸ†• æå–å¢å¼ºèŠ‚ç‚¹ç‰¹å¾ï¼ˆè°ƒæ•´ä¸º8ç»´åŒ¹é…é¢„è®­ç»ƒæ¨¡å‹ï¼‰"""
        node_features = []
        
        for vehicle_info in vehicles_info:
            current_state = vehicle_info['current_state']
            goal_state = vehicle_info['goal_state']
            priority = vehicle_info.get('priority', 1)
            
            # åŸºç¡€å¯¼èˆªç‰¹å¾
            dx = goal_state.x - current_state.x
            dy = goal_state.y - current_state.y
            distance_to_goal = math.sqrt(dx*dx + dy*dy)
            goal_bearing = math.atan2(dy, dx)
            
            # ğŸ”§ è°ƒæ•´ä¸º8ç»´ç‰¹å¾å‘é‡ï¼ˆå»æ‰angular_velocityå’Œrelative_yï¼‰
            features = [
                (current_state.x - 50.0) / 50.0,    # [0] ç›¸å¯¹ç¯å¢ƒä¸­å¿ƒx
                math.cos(current_state.theta),      # [1] èˆªå‘ä½™å¼¦
                math.sin(current_state.theta),      # [2] èˆªå‘æ­£å¼¦
                current_state.v / self.params.max_speed,  # [3] å½’ä¸€åŒ–é€Ÿåº¦
                getattr(current_state, 'acceleration', 0.0) / self.params.max_accel,  # [4] å½’ä¸€åŒ–åŠ é€Ÿåº¦
                distance_to_goal / 100.0,           # [5] å½’ä¸€åŒ–ç›®æ ‡è·ç¦»
                math.cos(goal_bearing),             # [6] ç›®æ ‡æ–¹å‘ä½™å¼¦
                priority / 10.0                     # [7] å½’ä¸€åŒ–ä¼˜å…ˆçº§
            ]
            
            node_features.append(features)
        
        return node_features
    
    def _build_enhanced_edges(self, vehicles_info: List[Dict]) -> Tuple[List, List, List]:
        """ğŸ†• æ„å»ºå¢å¼ºè¾¹ç‰¹å¾"""
        n_vehicles = len(vehicles_info)
        edge_indices = []
        edge_features = []
        adjacency_matrix = np.zeros((n_vehicles, n_vehicles))
        
        interaction_count = 0
        
        for i in range(n_vehicles):
            for j in range(i + 1, n_vehicles):
                interaction_data = self._compute_enhanced_interaction_features(
                    vehicles_info[i], vehicles_info[j])
                
                # ğŸ†• åŠ¨æ€äº¤äº’é˜ˆå€¼
                distance = interaction_data['distance']
                dynamic_threshold = self._compute_dynamic_threshold(vehicles_info[i], vehicles_info[j])
                
                if interaction_data['interaction_strength'] > dynamic_threshold:
                    # æ·»åŠ åŒå‘è¾¹
                    edge_indices.extend([[i, j], [j, i]])
                    edge_features.extend([interaction_data['features'], interaction_data['features']])
                    
                    weight = interaction_data['interaction_strength']
                    adjacency_matrix[i, j] = weight
                    adjacency_matrix[j, i] = weight
                    interaction_count += 1
        
        print(f"         å¢å¼ºè¾¹æ„å»º: {interaction_count}ä¸ªäº¤äº’å¯¹, {len(edge_indices)}æ¡æœ‰å‘è¾¹")
        return edge_indices, edge_features, adjacency_matrix.tolist()
    
    def _compute_enhanced_interaction_features(self, vehicle1: Dict, vehicle2: Dict) -> Dict:
        """ğŸ†• è®¡ç®—å¢å¼ºäº¤äº’ç‰¹å¾"""
        state1 = vehicle1['current_state']
        state2 = vehicle2['current_state']
        goal1 = vehicle1['goal_state']
        goal2 = vehicle2['goal_state']
        
        # åŸºç¡€è·ç¦»
        dx = state2.x - state1.x
        dy = state2.y - state1.y
        distance = math.sqrt(dx*dx + dy*dy)
        
        if distance > self.interaction_radius:
            return {'interaction_strength': 0.0, 'features': [0.0] * self.edge_feature_dim, 'distance': distance}
        
        # ğŸ†• å¢å¼ºäº¤äº’å¼ºåº¦è®¡ç®—
        distance_factor = max(0.05, 1.0 - (distance / self.interaction_radius))
        
        # è¿åŠ¨ç›¸å…³æ€§
        v1x, v1y = state1.v * math.cos(state1.theta), state1.v * math.sin(state1.theta)
        v2x, v2y = state2.v * math.cos(state2.theta), state2.v * math.sin(state2.theta)
        
        relative_speed = math.sqrt((v1x - v2x)**2 + (v1y - v2y)**2)
        approach_speed = max(0, (v1x * dx + v1y * dy) / max(distance, 1e-6))
        
        # è·¯å¾„äº¤å‰åˆ†æ
        path_crossing = self._analyze_path_crossing(state1, goal1, state2, goal2)
        
        # ä¼˜å…ˆçº§å…³ç³»
        priority_diff = (vehicle1.get('priority', 1) - vehicle2.get('priority', 1)) / 10.0
        
        # ğŸ†• æ—¶é—´å†²çªé£é™©
        time_to_conflict = self._estimate_time_to_conflict(state1, state2, v1x, v1y, v2x, v2y)
        conflict_risk = 1.0 / (1.0 + time_to_conflict / 5.0) if time_to_conflict < float('inf') else 0.0
        
        # ğŸ†• ç»¼åˆäº¤äº’å¼ºåº¦
        interaction_strength = (
            distance_factor * 0.4 +
            min(1.0, relative_speed / 8.0) * 0.2 +
            min(1.0, approach_speed / 4.0) * 0.2 +
            path_crossing * 0.15 +
            conflict_risk * 0.05
        )
        
        # 6ç»´å¢å¼ºè¾¹ç‰¹å¾
        features = [
            distance / self.interaction_radius,     # [0] å½’ä¸€åŒ–è·ç¦»
            relative_speed / 8.0,                   # [1] å½’ä¸€åŒ–ç›¸å¯¹é€Ÿåº¦
            approach_speed / 4.0,                   # [2] å½’ä¸€åŒ–æ¥è¿‘é€Ÿåº¦
            path_crossing,                          # [3] è·¯å¾„äº¤å‰æ¦‚ç‡
            priority_diff,                          # [4] ä¼˜å…ˆçº§å·®å¼‚
            conflict_risk                           # [5] å†²çªé£é™©
        ]
        
        return {
            'interaction_strength': min(1.0, interaction_strength),
            'features': features,
            'distance': distance
        }
    
    def _compute_dynamic_threshold(self, vehicle1: Dict, vehicle2: Dict) -> float:
        """ğŸ†• è®¡ç®—åŠ¨æ€äº¤äº’é˜ˆå€¼"""
        # åŸºäºè½¦è¾†é€Ÿåº¦å’Œä¼˜å…ˆçº§çš„åŠ¨æ€é˜ˆå€¼
        avg_speed = (vehicle1['current_state'].v + vehicle2['current_state'].v) / 2
        speed_factor = avg_speed / self.params.max_speed
        
        priority_sum = vehicle1.get('priority', 1) + vehicle2.get('priority', 1)
        priority_factor = priority_sum / 10.0
        
        # é«˜é€Ÿæˆ–é«˜ä¼˜å…ˆçº§æ—¶é™ä½é˜ˆå€¼ï¼ˆæ›´æ•æ„Ÿï¼‰
        base_threshold = 0.1
        dynamic_threshold = base_threshold * (1.0 - 0.3 * speed_factor - 0.2 * priority_factor)
        
        return max(0.02, dynamic_threshold)
    
    def _normalize_features(self, features: List, feature_type: str) -> List:
        """ğŸ†• ç‰¹å¾æ ‡å‡†åŒ–"""
        if not features:
            return features
        
        features_array = np.array(features)
        
        # ä½¿ç”¨é¢„è®¡ç®—çš„ç»Ÿè®¡ä¿¡æ¯æˆ–å½“å‰æ‰¹æ¬¡ç»Ÿè®¡
        mean_key = f'{feature_type}_mean'
        std_key = f'{feature_type}_std'
        
        if self.feature_stats[mean_key] is None:
            # é¦–æ¬¡è®¡ç®—ï¼Œä½¿ç”¨å½“å‰æ‰¹æ¬¡
            mean = np.mean(features_array, axis=0)
            std = np.std(features_array, axis=0) + 1e-8  # é¿å…é™¤é›¶
            
            self.feature_stats[mean_key] = mean
            self.feature_stats[std_key] = std
        else:
            # ä½¿ç”¨é¢„è®¡ç®—çš„ç»Ÿè®¡ä¿¡æ¯
            mean = self.feature_stats[mean_key]
            std = self.feature_stats[std_key]
        
        # æ ‡å‡†åŒ–
        normalized = (features_array - mean) / std
        return normalized.tolist()
    
    # ... å…¶ä»–è¾…åŠ©æ–¹æ³•ä¿æŒä¸å˜
    def _analyze_path_crossing(self, state1: VehicleState, goal1: VehicleState,
                              state2: VehicleState, goal2: VehicleState) -> float:
        """è·¯å¾„äº¤å‰åˆ†æï¼ˆä¿æŒåŸå®ç°ï¼‰"""        
        def line_intersection(p1, p2, p3, p4):
            x1, y1 = p1
            x2, y2 = p2
            x3, y3 = p3
            x4, y4 = p4
            
            denom = (x1-x2)*(y3-y4) - (y1-y2)*(x3-x4)
            if abs(denom) < 1e-10:
                return False, None
            
            t = ((x1-x3)*(y3-y4) - (y1-y3)*(x3-x4)) / denom
            u = -((x1-x2)*(y1-y3) - (y1-y2)*(x1-x3)) / denom
            
            if 0 <= t <= 1 and 0 <= u <= 1:
                intersect_x = x1 + t * (x2 - x1)
                intersect_y = y1 + t * (y2 - y1)
                return True, (intersect_x, intersect_y)
            
            return False, None
        
        intersects, intersection = line_intersection(
            (state1.x, state1.y), (goal1.x, goal1.y),
            (state2.x, state2.y), (goal2.x, goal2.y)
        )
        
        if intersects:
            ix, iy = intersection
            dist1 = math.sqrt((ix - state1.x)**2 + (iy - state1.y)**2)
            dist2 = math.sqrt((ix - state2.x)**2 + (iy - state2.y)**2)
            
            t1 = dist1 / max(0.1, state1.v)
            t2 = dist2 / max(0.1, state2.v)
            
            time_diff = abs(t1 - t2)
            return max(0.0, 1.0 - time_diff / 10.0)
        
        return 0.0
    
    def _estimate_time_to_conflict(self, state1: VehicleState, state2: VehicleState,
                                  v1x: float, v1y: float, v2x: float, v2y: float) -> float:
        """å†²çªæ—¶é—´ä¼°ç®—ï¼ˆä¿æŒåŸå®ç°ï¼‰"""
        dx = state2.x - state1.x
        dy = state2.y - state1.y
        dvx = v1x - v2x
        dvy = v1y - v2y
        
        relative_speed_sq = dvx*dvx + dvy*dvy
        if relative_speed_sq < 1e-6:
            return float('inf')
        
        t_closest = -(dx*dvx + dy*dvy) / relative_speed_sq
        
        if t_closest < 0:
            return float('inf')
        
        closest_distance = math.sqrt(
            (dx + dvx*t_closest)**2 + (dy + dvy*t_closest)**2
        )
        
        if closest_distance > self.params.length * 2:
            return float('inf')
        
        return t_closest
    
    def _extract_enhanced_global_features(self, vehicles_info: List[Dict]) -> List[float]:
        """ğŸ†• æå–å¢å¼ºå…¨å±€ç‰¹å¾"""
        if not vehicles_info:
            return [0.0] * self.global_feature_dim
        
        n_vehicles = len(vehicles_info)
        
        # åŸºç¡€ç»Ÿè®¡
        speeds = [v['current_state'].v for v in vehicles_info]
        distances_to_goal = []
        priorities = []
        
        for v in vehicles_info:
            state = v['current_state']
            goal = v['goal_state']
            dist = math.sqrt((goal.x - state.x)**2 + (goal.y - state.y)**2)
            distances_to_goal.append(dist)
            priorities.append(v.get('priority', 1))
        
        # ç©ºé—´åˆ†å¸ƒåˆ†æ
        positions = [(v['current_state'].x, v['current_state'].y) for v in vehicles_info]
        center_x = sum(p[0] for p in positions) / n_vehicles
        center_y = sum(p[1] for p in positions) / n_vehicles
        spread = sum(math.sqrt((p[0]-center_x)**2 + (p[1]-center_y)**2) for p in positions) / n_vehicles
        
        # ğŸ†• äº¤é€šå¯†åº¦è®¡ç®—
        traffic_density = self._compute_enhanced_traffic_density(vehicles_info)
        
        # 8ç»´å¢å¼ºå…¨å±€ç‰¹å¾
        global_features = [
            n_vehicles / 10.0,                           # [0] å½’ä¸€åŒ–è½¦è¾†æ•°
            sum(speeds) / (n_vehicles * self.params.max_speed),  # [1] å¹³å‡é€Ÿåº¦æ¯”
            np.std(speeds) / self.params.max_speed,      # [2] é€Ÿåº¦æ–¹å·®
            sum(distances_to_goal) / (n_vehicles * 100), # [3] å¹³å‡ç›®æ ‡è·ç¦»
            np.std(distances_to_goal) / 100,             # [4] ç›®æ ‡è·ç¦»æ–¹å·®
            sum(priorities) / (n_vehicles * 10),         # [5] å¹³å‡ä¼˜å…ˆçº§
            spread / 50.0,                               # [6] ç©ºé—´åˆ†å¸ƒ
            traffic_density                              # [7] å¢å¼ºäº¤é€šå¯†åº¦
        ]
        
        return global_features
    
    def _compute_enhanced_traffic_density(self, vehicles_info: List[Dict]) -> float:
        """ğŸ†• è®¡ç®—å¢å¼ºäº¤é€šå¯†åº¦"""
        if len(vehicles_info) < 2:
            return 0.0
        
        total_weighted_interactions = 0.0
        total_possible_weight = 0.0
        
        for i in range(len(vehicles_info)):
            for j in range(i + 1, len(vehicles_info)):
                state1 = vehicles_info[i]['current_state']
                state2 = vehicles_info[j]['current_state']
                
                distance = math.sqrt((state1.x - state2.x)**2 + (state1.y - state2.y)**2)
                
                # åŸºäºè·ç¦»å’Œé€Ÿåº¦çš„åŠ æƒäº¤äº’
                if distance < self.interaction_radius:
                    avg_speed = (state1.v + state2.v) / 2
                    speed_weight = avg_speed / self.params.max_speed
                    distance_weight = 1.0 - (distance / self.interaction_radius)
                    
                    interaction_weight = distance_weight * (1.0 + speed_weight)
                    total_weighted_interactions += interaction_weight
                    total_possible_weight += 2.0  # æœ€å¤§å¯èƒ½æƒé‡
        
        return total_weighted_interactions / max(1, total_possible_weight)
    
    def _normalize_angle(self, angle: float) -> float:
        """è§’åº¦æ ‡å‡†åŒ–"""
        while angle > math.pi:
            angle -= 2 * math.pi
        while angle < -math.pi:
            angle += 2 * math.pi
        return angle
    
    def _create_empty_graph(self) -> VehicleInteractionGraph:
        """åˆ›å»ºç©ºå›¾"""
        return VehicleInteractionGraph(
            node_features=torch.zeros((0, self.node_feature_dim)),
            edge_indices=torch.zeros((2, 0), dtype=torch.long),
            edge_features=torch.zeros((0, self.edge_feature_dim)),
            vehicle_ids=[],
            adjacency_matrix=torch.zeros((0, 0)),
            global_features=torch.zeros(self.global_feature_dim)
        )

class PretrainedGNNEnhancedPlanner(VHybridAStarPlanner):
    """ğŸ†• é¢„è®­ç»ƒGNNå¢å¼ºçš„è§„åˆ’å™¨"""
    
    def __init__(self, environment: UnstructuredEnvironment, 
                 optimization_level: OptimizationLevel = OptimizationLevel.FULL,
                 gnn_enhancement_level: GNNEnhancementLevel = GNNEnhancementLevel.PRETRAINED_FULL):
        
        super().__init__(environment, optimization_level)
        
        self.gnn_enhancement_level = gnn_enhancement_level
        
        # ğŸ†• å¢å¼ºå›¾æ„å»ºå™¨
        self.graph_builder = EnhancedVehicleGraphBuilder(self.params)
        
        # ğŸ†• é¢„è®­ç»ƒæ¨¡å‹åŠ è½½å™¨
        self.gnn_loader = PretrainedGNNLoader()
        
        # ğŸ†• åŠ è½½é¢„è®­ç»ƒGNNæ¨¡å‹
        if gnn_enhancement_level == GNNEnhancementLevel.PRETRAINED_FULL:
            self.coordination_gnn = self.gnn_loader.load_pretrained_model()
            if self.coordination_gnn is None:
                print("âš ï¸ é¢„è®­ç»ƒæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå›é€€åˆ°åŸºç¡€GNN")
                from trans import VehicleCoordinationGNN
                self.coordination_gnn = VehicleCoordinationGNN()
                self.gnn_enhancement_level = GNNEnhancementLevel.FULL_INTEGRATION
        else:
            # ä½¿ç”¨åŸæœ‰çš„åŸºç¡€GNN
            from trans import VehicleCoordinationGNN
            self.coordination_gnn = VehicleCoordinationGNN()
        
        if self.coordination_gnn:
            self.coordination_gnn.eval()
        
        # å¢å¼ºç»Ÿè®¡ä¿¡æ¯
        self.enhanced_gnn_stats = {
            'graph_constructions': 0,
            'pretrained_inferences': 0,
            'feature_normalizations': 0,
            'dynamic_threshold_adjustments': 0,
            'enhanced_decisions': 0,
            'gnn_inference_time': 0.0,
            'total_enhancement_time': 0.0
        }
        
        print(f"      ğŸ§  é¢„è®­ç»ƒGNNå¢å¼ºè§„åˆ’å™¨åˆå§‹åŒ–")
        print(f"         å¢å¼ºçº§åˆ«: {gnn_enhancement_level.value}")
        print(f"         GNNçŠ¶æ€: {'é¢„è®­ç»ƒæ¨¡å‹' if gnn_enhancement_level == GNNEnhancementLevel.PRETRAINED_FULL else 'åŸºç¡€æ¨¡å‹'}")
    
    def plan_multi_vehicle_with_pretrained_gnn(self, vehicles_info: List[Dict]) -> Dict[int, Optional[List[VehicleState]]]:
        """ğŸ†• ä½¿ç”¨é¢„è®­ç»ƒGNNè¿›è¡Œå¤šè½¦åè°ƒè§„åˆ’"""
        
        print(f"     ğŸ§  é¢„è®­ç»ƒGNNå¤šè½¦åè°ƒ: {len(vehicles_info)}è¾†è½¦")
        print(f"        ç‰¹æ€§: é¢„è®­ç»ƒå†³ç­– + å¢å¼ºç‰¹å¾ + å®Œæ•´QPä¼˜åŒ–")
        
        enhancement_start = time.time()
        
        # 1. æ„å»ºå¢å¼ºäº¤äº’å›¾
        graph_start = time.time()
        interaction_graph = self.graph_builder.build_interaction_graph(vehicles_info)
        self.enhanced_gnn_stats['graph_constructions'] += 1
        graph_time = time.time() - graph_start
        
        print(f"        å¢å¼ºå›¾æ„å»º: {interaction_graph.node_features.shape[0]}èŠ‚ç‚¹, "
              f"{interaction_graph.edge_indices.shape[1]}è¾¹ (è€—æ—¶: {graph_time:.3f}s)")
        
        # 2. é¢„è®­ç»ƒGNNæ¨ç†
        gnn_start = time.time()
        with torch.no_grad():
            if self.gnn_enhancement_level == GNNEnhancementLevel.PRETRAINED_FULL and self.coordination_gnn:
                # è½¬æ¢ä¸ºPyGæ•°æ®æ ¼å¼
                pyg_data = interaction_graph.to_pyg_data()
                gnn_decisions = self.coordination_gnn(pyg_data)
                self.enhanced_gnn_stats['pretrained_inferences'] += 1
            else:
                # å›é€€åˆ°åŸºç¡€GNN
                gnn_decisions = self.coordination_gnn(interaction_graph)
        
        gnn_inference_time = time.time() - gnn_start
        self.enhanced_gnn_stats['gnn_inference_time'] += gnn_inference_time
        
        print(f"        GNNæ¨ç†å®Œæˆ: è€—æ—¶ {gnn_inference_time:.3f}s")
        
        # 3. å¢å¼ºå†³ç­–è§£æ
        coordination_guidance = self._parse_enhanced_gnn_decisions(gnn_decisions, vehicles_info)
        self.enhanced_gnn_stats['enhanced_decisions'] += len(coordination_guidance)
        
        # 4. æ™ºèƒ½ä¼˜å…ˆçº§æ’åº
        sorted_vehicles = self._intelligent_priority_sorting(vehicles_info, coordination_guidance)
        
        # 5. é€è½¦è§„åˆ’
        results = {}
        completed_trajectories = []
        
        for i, vehicle_info in enumerate(sorted_vehicles):
            vehicle_id = vehicle_info['id']
            guidance = coordination_guidance.get(vehicle_id, {})
            
            print(f"     ğŸš— è§„åˆ’è½¦è¾†{vehicle_id}: é¢„è®­ç»ƒæŒ‡å¯¼={guidance.get('strategy', 'normal')}")
            
            # åº”ç”¨å¢å¼ºGNNæŒ‡å¯¼
            self._apply_enhanced_gnn_guidance(guidance)
            
            # æ‰§è¡Œå¢å¼ºæœç´¢
            trajectory = self.search_with_waiting(
                vehicle_info['start'], vehicle_info['goal'], 
                vehicle_id, completed_trajectories
            )
            
            if trajectory:
                # ğŸ†• åº”ç”¨é¢„è®­ç»ƒåå¤„ç†
                if self.gnn_enhancement_level == GNNEnhancementLevel.PRETRAINED_FULL:
                    trajectory = self._apply_pretrained_postprocessing(trajectory, guidance)
                
                results[vehicle_id] = trajectory
                completed_trajectories.append(trajectory)
                print(f"        âœ… æˆåŠŸ: {len(trajectory)}ç‚¹ (é¢„è®­ç»ƒGNN+QPä¼˜åŒ–)")
            else:
                print(f"        âŒ å¤±è´¥")
                results[vehicle_id] = None
            
            # é‡ç½®å‚æ•°
            self._reset_planning_params()
        
        total_enhancement_time = time.time() - enhancement_start
        self.enhanced_gnn_stats['total_enhancement_time'] += total_enhancement_time
        
        self._print_enhanced_stats()
        return results
    def search_with_waiting(self, start: VehicleState, goal: VehicleState, 
                          vehicle_id: int, existing_trajectories: List[List[VehicleState]]) -> Optional[List[VehicleState]]:
        """ğŸ†• å¸¦ç­‰å¾…æœºåˆ¶çš„æœç´¢ï¼ˆå¦‚æœåŸºç±»æ²¡æœ‰æ­¤æ–¹æ³•ï¼‰"""
        if hasattr(super(), 'search_with_waiting'):
            return super().search_with_waiting(start, goal, vehicle_id, existing_trajectories)
        else:
            # å›é€€åˆ°åŸºç¡€æœç´¢
            print(f"        âš ï¸ å›é€€åˆ°åŸºç¡€æœç´¢æ–¹æ³•")
            return self.search(start, goal, existing_trajectories)

    def search(self, start: VehicleState, goal: VehicleState, 
               high_priority_trajectories: List[List[VehicleState]] = None) -> Optional[List[VehicleState]]:
        """ğŸ†• åŸºç¡€æœç´¢æ–¹æ³•ï¼ˆå¦‚æœåŸºç±»æ–¹æ³•ä¸å¯ç”¨ï¼‰"""
        if high_priority_trajectories is None:
            high_priority_trajectories = []
            
        try:
            # å°è¯•è°ƒç”¨çˆ¶ç±»æœç´¢
            return super().search(start, goal, high_priority_trajectories)
        except Exception as e:
            print(f"        âš ï¸ æœç´¢å¤±è´¥: {e}")
            return None

    def _reset_planning_params(self):
        """ğŸ†• é‡ç½®è§„åˆ’å‚æ•°"""
        self.params = VehicleParameters()
        
        # é‡ç½®è¿­ä»£æ¬¡æ•°
        if self.optimization_level == OptimizationLevel.BASIC:
            self.max_iterations = 15000
        elif self.optimization_level == OptimizationLevel.ENHANCED:
            self.max_iterations = 32000
        else:
            self.max_iterations = 30000
        
        print(f"          å‚æ•°é‡ç½®: max_speed={self.params.max_speed}, max_iterations={self.max_iterations}")

    def _print_enhanced_stats(self):
        """ğŸ†• æ‰“å°å¢å¼ºç»Ÿè®¡ä¿¡æ¯"""
        stats = self.enhanced_gnn_stats
        print(f"\n      ğŸ§  é¢„è®­ç»ƒGNNå¢å¼ºç»Ÿè®¡:")
        print(f"        å¢å¼ºå›¾æ„å»º: {stats['graph_constructions']}æ¬¡")
        print(f"        é¢„è®­ç»ƒæ¨ç†: {stats['pretrained_inferences']}æ¬¡")
        print(f"        ç‰¹å¾æ ‡å‡†åŒ–: {stats['feature_normalizations']}æ¬¡")
        print(f"        åŠ¨æ€é˜ˆå€¼è°ƒæ•´: {stats['dynamic_threshold_adjustments']}æ¬¡")
        print(f"        å¢å¼ºå†³ç­–: {stats['enhanced_decisions']}æ¬¡")
        print(f"        GNNæ¨ç†æ—¶é—´: {stats['gnn_inference_time']:.3f}s")
        print(f"        æ€»å¢å¼ºæ—¶é—´: {stats['total_enhancement_time']:.3f}s")
        
        if self.gnn_enhancement_level == GNNEnhancementLevel.PRETRAINED_FULL:
            print(f"        ğŸ¯ é¢„è®­ç»ƒæ¨¡å‹å·²æ¿€æ´»")
        else:
            print(f"        âš ï¸ å›é€€åˆ°åŸºç¡€GNNæ¨¡å¼")    
    def _parse_enhanced_gnn_decisions(self, decisions: Dict[str, torch.Tensor], 
                           vehicles_info: List[Dict]) -> Dict[int, Dict]:
        """ğŸ†• è§£æå¢å¼ºGNNå†³ç­–"""
        guidance = {}
        
        # åŸºç¡€å†³ç­–
        priority_adj = decisions.get('priority', torch.zeros((len(vehicles_info), 1)))
        cooperation = decisions.get('cooperation', torch.zeros((len(vehicles_info), 1)))
        urgency = decisions.get('urgency', torch.zeros((len(vehicles_info), 1)))
        safety = decisions.get('safety', torch.zeros((len(vehicles_info), 1)))
        
        # ğŸ†• å¢å¼ºå†³ç­–ï¼ˆå¦‚æœæ˜¯é¢„è®­ç»ƒæ¨¡å‹ï¼‰
        speed_adjustment = decisions.get('speed_adjustment', torch.zeros((len(vehicles_info), 1)))
        route_preference = decisions.get('route_preference', torch.zeros((len(vehicles_info), 3)))
        global_coord = decisions.get('global_coordination', torch.zeros(6))
        
        print(f"        å¢å¼ºå…¨å±€åè°ƒä¿¡å·: {global_coord.tolist()[:4]}...")
        
        for i, vehicle_info in enumerate(vehicles_info):
            if i < priority_adj.shape[0]:
                vehicle_id = vehicle_info['id']
                
                # åŸºç¡€å†³ç­–
                pri_adj = priority_adj[i, 0].item()
                coop_score = cooperation[i, 0].item()
                urgency_level = urgency[i, 0].item()
                safety_factor = safety[i, 0].item()
                
                # ğŸ†• å¢å¼ºå†³ç­–
                speed_adj = speed_adjustment[i, 0].item() if i < speed_adjustment.shape[0] else 0.0
                route_pref = route_preference[i].tolist() if i < route_preference.shape[0] else [0.33, 0.34, 0.33]
                
                # æ™ºèƒ½ç­–ç•¥ç¡®å®š
                strategy = self._determine_enhanced_strategy(
                    pri_adj, coop_score, urgency_level, safety_factor, speed_adj, route_pref)
                
                guidance[vehicle_id] = {
                    'priority_adj': pri_adj,
                    'cooperation_score': coop_score,
                    'urgency_level': urgency_level,
                    'safety_factor': safety_factor,
                    'speed_adjustment': speed_adj,  # ğŸ†•
                    'route_preference': route_pref,  # ğŸ†•
                    'adjusted_priority': vehicle_info['priority'] + pri_adj * 3.0,  # å¢å¼ºè°ƒæ•´å¹…åº¦
                    'strategy': strategy,
                    'confidence': self._compute_decision_confidence(pri_adj, coop_score, urgency_level, safety_factor)  # ğŸ†•
                }
        
        return guidance
    
    def _determine_enhanced_strategy(self, priority_adj: float, cooperation: float, 
                                   urgency: float, safety: float, 
                                   speed_adj: float, route_pref: List[float]) -> str:
        """ğŸ†• ç¡®å®šå¢å¼ºåè°ƒç­–ç•¥"""
        
        # åŸºäºå¤šç»´å†³ç­–çš„ç­–ç•¥é€‰æ‹©
        if safety > 0.8:
            return "safety_first"
        elif urgency > 0.8:
            return "urgent_passage"
        elif cooperation > 0.75:
            return "cooperative"
        elif speed_adj > 0.3:
            return "aggressive"  # ğŸ†• ç§¯æç­–ç•¥
        elif speed_adj < -0.3:
            return "cautious"    # ğŸ†• è°¨æ…ç­–ç•¥
        elif max(route_pref) > 0.6:
            preferred_direction = route_pref.index(max(route_pref))
            if preferred_direction == 0:
                return "prefer_left"   # ğŸ†• åå·¦ç­–ç•¥
            elif preferred_direction == 2:
                return "prefer_right"  # ğŸ†• åå³ç­–ç•¥
            else:
                return "prefer_straight"  # ğŸ†• ç›´è¡Œç­–ç•¥
        elif priority_adj > 0.3:
            return "assert_priority"
        elif priority_adj < -0.3:
            return "yield_way"
        else:
            return "normal"
    
    def _compute_decision_confidence(self, priority_adj: float, cooperation: float, 
                                   urgency: float, safety: float) -> float:
        """ğŸ†• è®¡ç®—å†³ç­–ç½®ä¿¡åº¦"""
        # åŸºäºå†³ç­–ä¸€è‡´æ€§çš„ç½®ä¿¡åº¦è®¡ç®—
        decision_strengths = [abs(priority_adj), cooperation, urgency, safety]
        
        # é«˜ä¸€è‡´æ€§ = é«˜ç½®ä¿¡åº¦
        max_strength = max(decision_strengths)
        avg_strength = sum(decision_strengths) / len(decision_strengths)
        
        consistency = 1.0 - (max_strength - avg_strength)
        confidence = (max_strength + consistency) / 2.0
        
        return min(1.0, confidence)
    
    def _intelligent_priority_sorting(self, vehicles_info: List[Dict], 
                                    guidance: Dict[int, Dict]) -> List[Dict]:
        """ğŸ†• æ™ºèƒ½ä¼˜å…ˆçº§æ’åº"""
        def enhanced_priority_key(vehicle_info):
            vehicle_id = vehicle_info['id']
            vehicle_guidance = guidance.get(vehicle_id, {})
            
            base_priority = vehicle_guidance.get('adjusted_priority', vehicle_info['priority'])
            confidence = vehicle_guidance.get('confidence', 0.5)
            urgency = vehicle_guidance.get('urgency_level', 0.5)
            
            # ç»¼åˆæ’åºé”®ï¼šåŸºç¡€ä¼˜å…ˆçº§ + ç½®ä¿¡åº¦æƒé‡ + ç´§æ€¥ç¨‹åº¦
            enhanced_priority = base_priority + confidence * 0.5 + urgency * 0.3
            
            return enhanced_priority
        
        return sorted(vehicles_info, key=enhanced_priority_key, reverse=True)
    
    def _apply_enhanced_gnn_guidance(self, guidance: Dict):
        """ğŸ†• åº”ç”¨å¢å¼ºGNNæŒ‡å¯¼"""
        strategy = guidance.get('strategy', 'normal')
        safety_factor = guidance.get('safety_factor', 0.5)
        cooperation_score = guidance.get('cooperation_score', 0.5)
        urgency_level = guidance.get('urgency_level', 0.5)
        speed_adjustment = guidance.get('speed_adjustment', 0.0)
        confidence = guidance.get('confidence', 0.5)
        
        # åŸºäºç½®ä¿¡åº¦è°ƒæ•´å‚æ•°å½±å“å¼ºåº¦
        influence_factor = 0.5 + confidence * 0.5
        
        # ğŸ†• å¢å¼ºç­–ç•¥åº”ç”¨
        if strategy == "safety_first":
            self.params.green_additional_safety *= (1.0 + safety_factor * 0.8 * influence_factor)
            self.params.max_speed *= (1.0 - safety_factor * 0.3 * influence_factor)
            
        elif strategy == "urgent_passage":
            self.params.max_speed *= (1.0 + urgency_level * 0.15 * influence_factor)
            self.max_iterations = int(self.max_iterations * (1.0 + urgency_level * 0.4 * influence_factor))
            
        elif strategy == "cooperative":
            self.params.wÎ´ *= (1.0 + cooperation_score * 0.4 * influence_factor)
            self.params.green_additional_safety *= (1.0 + cooperation_score * 0.3 * influence_factor)
            
        elif strategy == "aggressive":
            self.params.max_speed *= (1.0 + abs(speed_adjustment) * 0.2 * influence_factor)
            self.params.max_accel *= (1.0 + abs(speed_adjustment) * 0.15 * influence_factor)
            
        elif strategy == "cautious":
            self.params.max_speed *= (1.0 - abs(speed_adjustment) * 0.2 * influence_factor)
            self.params.green_additional_safety *= (1.0 + abs(speed_adjustment) * 0.3 * influence_factor)
            
        # è·¯å¾„åå¥½å½±å“
        route_pref = guidance.get('route_preference', [0.33, 0.34, 0.33])
        if max(route_pref) > 0.5:
            preferred_direction = route_pref.index(max(route_pref))
            preference_strength = max(route_pref)
            
            if preferred_direction == 0:  # åå·¦
                # ç•¥å¾®è°ƒæ•´è½¬å‘åå¥½ï¼ˆè¿™é‡Œæ˜¯æ¦‚å¿µæ€§çš„è°ƒæ•´ï¼‰
                pass
            elif preferred_direction == 2:  # åå³
                # ç•¥å¾®è°ƒæ•´è½¬å‘åå¥½
                pass
        
        self.enhanced_gnn_stats['dynamic_threshold_adjustments'] += 1
    
    def _apply_pretrained_postprocessing(self, trajectory: List[VehicleState], 
                                       guidance: Dict) -> List[VehicleState]:
        """ğŸ†• é¢„è®­ç»ƒæ¨¡å‹åå¤„ç†"""
        if not trajectory or len(trajectory) < 3:
            return trajectory
        
        strategy = guidance.get('strategy', 'normal')
        speed_adjustment = guidance.get('speed_adjustment', 0.0)
        safety_factor = guidance.get('safety_factor', 0.5)
        confidence = guidance.get('confidence', 0.5)
        
        # åŸºäºé¢„è®­ç»ƒå†³ç­–çš„è½¨è¿¹å¾®è°ƒ
        if confidence > 0.7:  # é«˜ç½®ä¿¡åº¦æ—¶æ‰è¿›è¡Œè°ƒæ•´
            print(f"          åº”ç”¨é¢„è®­ç»ƒåå¤„ç†: {strategy} (ç½®ä¿¡åº¦: {confidence:.3f})")
            
            adjusted_trajectory = []
            for i, state in enumerate(trajectory):
                new_state = state.copy()
                
                # é€Ÿåº¦è°ƒæ•´
                if abs(speed_adjustment) > 0.1:
                    speed_factor = 1.0 + speed_adjustment * 0.2
                    new_state.v = max(0.5, min(new_state.v * speed_factor, self.params.max_speed))
                
                # å®‰å…¨è°ƒæ•´
                if safety_factor > 0.8 and i > 0:
                    # åœ¨é«˜å®‰å…¨è¦æ±‚ä¸‹å¢åŠ ä¸å‰ä¸€ç‚¹çš„é—´éš”
                    prev_state = adjusted_trajectory[i-1]
                    distance = math.sqrt((new_state.x - prev_state.x)**2 + (new_state.y - prev_state.y)**2)
                    if distance < 1.0:  # å¦‚æœå¤ªè¿‘ï¼Œç•¥å¾®è°ƒæ•´ä½ç½®
                        angle = math.atan2(new_state.y - prev_state.y, new_state.x - prev_state.x)
                        new_state.x = prev_state.x + 1.0 * math.cos(angle)
                        new_state.y = prev_state.y + 1.0 * math.sin(angle)
                
                adjusted_trajectory.append(new_state)
            
            # é‡æ–°åŒæ­¥æ—¶é—´
            return TimeSync.resync_trajectory_time(adjusted_trajectory)
        
        return trajectory
    
    def _print_enhanced_stats(self):
        """ğŸ†• æ‰“å°å¢å¼ºç»Ÿè®¡ä¿¡æ¯"""
        stats = self.enhanced_gnn_stats
        print(f"\n      ğŸ§  é¢„è®­ç»ƒGNNå¢å¼ºç»Ÿè®¡:")
        print(f"        å¢å¼ºå›¾æ„å»º: {stats['graph_constructions']}æ¬¡")
        print(f"        é¢„è®­ç»ƒæ¨ç†: {stats['pretrained_inferences']}æ¬¡")
        print(f"        ç‰¹å¾æ ‡å‡†åŒ–: {stats['feature_normalizations']}æ¬¡")
        print(f"        åŠ¨æ€é˜ˆå€¼è°ƒæ•´: {stats['dynamic_threshold_adjustments']}æ¬¡")
        print(f"        å¢å¼ºå†³ç­–: {stats['enhanced_decisions']}æ¬¡")
        print(f"        GNNæ¨ç†æ—¶é—´: {stats['gnn_inference_time']:.3f}s")
        print(f"        æ€»å¢å¼ºæ—¶é—´: {stats['total_enhancement_time']:.3f}s")
        
        if self.gnn_enhancement_level == GNNEnhancementLevel.PRETRAINED_FULL:
            print(f"        ğŸ¯ é¢„è®­ç»ƒæ¨¡å‹å·²æ¿€æ´»")
        else:
            print(f"        âš ï¸ å›é€€åˆ°åŸºç¡€GNNæ¨¡å¼")

class PretrainedGNNIntegratedCoordinator:
    """ğŸ†• é¢„è®­ç»ƒGNNé›†æˆåè°ƒå™¨"""
    
    def __init__(self, map_file_path=None, 
                 optimization_level: OptimizationLevel = OptimizationLevel.FULL,
                 gnn_enhancement_level: GNNEnhancementLevel = GNNEnhancementLevel.PRETRAINED_FULL):
        
        self.environment = UnstructuredEnvironment(size=100)
        self.optimization_level = optimization_level
        self.gnn_enhancement_level = gnn_enhancement_level
        self.map_data = None
        
        if map_file_path:
            self.load_map(map_file_path)
        
        # ğŸ†• åˆ›å»ºé¢„è®­ç»ƒGNNå¢å¼ºè§„åˆ’å™¨
        self.pretrained_gnn_planner = PretrainedGNNEnhancedPlanner(
            self.environment, optimization_level, gnn_enhancement_level
        )
        
        print(f"âœ… é¢„è®­ç»ƒGNNé›†æˆåè°ƒå™¨åˆå§‹åŒ–")
        print(f"   åŸºç¡€ä¼˜åŒ–: {optimization_level.value}")
        print(f"   GNNå¢å¼º: {gnn_enhancement_level.value}")
        if gnn_enhancement_level == GNNEnhancementLevel.PRETRAINED_FULL:
            print(f"   ğŸ¯ ç‰¹æ€§: é¢„è®­ç»ƒGNN + å¢å¼ºç‰¹å¾ + å®Œæ•´QPä¼˜åŒ–")
        else:
            print(f"   ç‰¹æ€§: åŸºç¡€GNN + å®Œæ•´QPä¼˜åŒ–")
    
    def load_map(self, map_file_path):
        """åŠ è½½åœ°å›¾"""
        self.map_data = self.environment.load_from_json(map_file_path)
        return self.map_data is not None
    
    def create_scenarios_from_json(self):
        """ä»JSONåˆ›å»ºåœºæ™¯ï¼ˆä¿æŒåŸå®ç°ï¼‰"""
        if not self.map_data:
            return []
        
        start_points = self.map_data.get("start_points", [])
        end_points = self.map_data.get("end_points", [])
        point_pairs = self.map_data.get("point_pairs", [])
        
        if not point_pairs:
            print("âŒ æœªæ‰¾åˆ°è½¦è¾†é…å¯¹")
            return []
        
        scenarios = []
        colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan']
        
        for i, pair in enumerate(point_pairs):
            start_id = pair["start_id"]
            end_id = pair["end_id"]
            
            start_point = next((p for p in start_points if p["id"] == start_id), None)
            end_point = next((p for p in end_points if p["id"] == end_id), None)
            
            if start_point and end_point:
                dx = end_point["x"] - start_point["x"]
                dy = end_point["y"] - start_point["y"]
                optimal_theta = math.atan2(dy, dx)
                
                start_state = VehicleState(
                    x=float(start_point["x"]),
                    y=float(start_point["y"]),
                    theta=optimal_theta,
                    v=3.0,
                    t=0.0
                )
                
                goal_state = VehicleState(
                    x=float(end_point["x"]),
                    y=float(end_point["y"]),
                    theta=optimal_theta,
                    v=2.0,
                    t=0.0
                )
                
                scenario = {
                    'id': i + 1,
                    'priority': 1,
                    'color': colors[i % len(colors)],
                    'start': start_state,
                    'goal': goal_state,
                    'description': f'Vehicle {i+1} (S{start_id}->E{end_id})'
                }
                
                scenarios.append(scenario)
        
        print(f"âœ… åˆ›å»º{len(scenarios)}ä¸ªåœºæ™¯")
        return scenarios
    
    def plan_with_pretrained_gnn_integration(self):
        """ğŸ†• æ‰§è¡Œé¢„è®­ç»ƒGNNé›†æˆè§„åˆ’"""
        
        scenarios = self.create_scenarios_from_json()
        if not scenarios:
            return None, None
        
        print(f"\nğŸ¯ é¢„è®­ç»ƒGNN+QPé›†æˆè§„åˆ’: {len(scenarios)}è¾†è½¦")
        if self.gnn_enhancement_level == GNNEnhancementLevel.PRETRAINED_FULL:
            print(f"   ğŸ§  é¢„è®­ç»ƒGNN: æ™ºèƒ½å†³ç­– + å¢å¼ºç‰¹å¾æå–")
        print(f"   âš™ï¸ QPä¼˜åŒ–æµç¨‹: è·¯å¾„å¹³æ»‘ + é€Ÿåº¦ä¼˜åŒ– + å‡¸ç©ºé—´çº¦æŸ")
        print(f"   ğŸ”§ ç²¾ç¡®è¿åŠ¨å­¦: å®Œæ•´è½¬å¼¯åŠå¾„è®¡ç®— + è§’åº¦æ›´æ–°")
        
        # è½¬æ¢ä¸ºè§„åˆ’ä¿¡æ¯æ ¼å¼
        vehicles_info = []
        for scenario in scenarios:
            vehicles_info.append({
                'id': scenario['id'],
                'start': scenario['start'],
                'goal': scenario['goal'],
                'priority': scenario['priority'],
                'current_state': scenario['start'],
                'goal_state': scenario['goal']
            })
        
        # ğŸ†• æ‰§è¡Œé¢„è®­ç»ƒGNNå¢å¼ºè§„åˆ’
        start_time = time.time()
        planning_results = self.pretrained_gnn_planner.plan_multi_vehicle_with_pretrained_gnn(vehicles_info)
        total_time = time.time() - start_time
        
        # è½¬æ¢ç»“æœæ ¼å¼
        results = {}
        for scenario in scenarios:
            vehicle_id = scenario['id']
            trajectory = planning_results.get(vehicle_id)
            
            results[vehicle_id] = {
                'trajectory': trajectory if trajectory else [],
                'color': scenario['color'],
                'description': scenario['description'],
                'planning_time': total_time / len(scenarios)
            }
        
        success_count = sum(1 for r in results.values() if r['trajectory'])
        
        print(f"\nğŸ“Š é¢„è®­ç»ƒGNN+QPé›†æˆè§„åˆ’ç»“æœ:")
        print(f"   æˆåŠŸç‡: {success_count}/{len(scenarios)} ({100*success_count/len(scenarios):.1f}%)")
        print(f"   æ€»æ—¶é—´: {total_time:.2f}s")
        print(f"   å¹³å‡æ—¶é—´: {total_time/len(scenarios):.2f}s/è½¦")
        print(f"   ä¼˜åŒ–çº§åˆ«: {self.optimization_level.value}")
        if self.gnn_enhancement_level == GNNEnhancementLevel.PRETRAINED_FULL:
            print(f"   GNNçŠ¶æ€: é¢„è®­ç»ƒæ¨¡å‹å·²æ¿€æ´»")
        print(f"   ç‰¹æ€§å®Œæ•´æ€§: 100%é›†æˆï¼ˆé¢„è®­ç»ƒGNN+QP+è¿åŠ¨å­¦ï¼‰")
        
        return results, scenarios

def main():
    """ğŸ†• ä¸»å‡½æ•° - é¢„è®­ç»ƒGNNé›†æˆç‰ˆ"""
    print("ğŸ§  é¢„è®­ç»ƒGNNå¢å¼ºçš„V-Hybrid A*å¤šè½¦åè°ƒç³»ç»Ÿ")
    print("=" * 80)
    print("ğŸ¯ å®Œæ•´ç‰¹æ€§ï¼ˆä¿®å¤trans.pyç¼ºé™·ï¼‰:")
    print("   âœ… é¢„è®­ç»ƒGNNæ¨¡å‹: å›¾å·ç§¯+æ³¨æ„åŠ›+æ± åŒ–+æ®‹å·®è¿æ¥")
    print("   âœ… å¢å¼ºç‰¹å¾æå–: ç‰¹å¾æ ‡å‡†åŒ–+åŠ¨æ€é˜ˆå€¼+ç©ºé—´åˆ†æ")
    print("   âœ… æ™ºèƒ½å†³ç­–ç³»ç»Ÿ: å¤šä»»åŠ¡è¾“å‡º+ç½®ä¿¡åº¦è¯„ä¼°+ç­–ç•¥é€‰æ‹©")
    print("   âœ… å®Œæ•´QPä¼˜åŒ–: è·¯å¾„å¹³æ»‘+é€Ÿåº¦ä¼˜åŒ–+å‡¸ç©ºé—´çº¦æŸ")
    print("   âœ… ç²¾ç¡®è¿åŠ¨å­¦: è½¬å¼¯åŠå¾„+è§’åº¦æ›´æ–°+ä½ç½®è®¡ç®—")
    print("   âœ… åˆ†å±‚å®‰å…¨ç­–ç•¥: åŠ¨æ€å®‰å…¨è·ç¦»åˆ‡æ¢")
    print("   âœ… 3Dæ—¶ç©ºåœ°å›¾: çœŸå®æ—¶ç©ºç»´åº¦è§„åˆ’")
    print("=" * 80)
    
    # æ£€æŸ¥é¢„è®­ç»ƒæ¨¡å‹
    gnn_loader = PretrainedGNNLoader()
    if gnn_loader.available_models:
        print(f"\nğŸ“¥ å‘ç°é¢„è®­ç»ƒæ¨¡å‹: {gnn_loader.available_models}")
        gnn_level = GNNEnhancementLevel.PRETRAINED_FULL
        print(f"ğŸ¯ å¯ç”¨é¢„è®­ç»ƒGNNå¢å¼º")
    else:
        print(f"\nâš ï¸ æœªå‘ç°é¢„è®­ç»ƒæ¨¡å‹ï¼Œå°†ä½¿ç”¨åŸºç¡€GNN")
        print(f"   æç¤º: è¿è¡Œ 'python gnn_pretraining.py' ç”Ÿæˆé¢„è®­ç»ƒæ¨¡å‹")
        gnn_level = GNNEnhancementLevel.FULL_INTEGRATION
    
    # é€‰æ‹©åœ°å›¾
    selected_file = interactive_json_selection()
    if not selected_file:
        print("âŒ æœªé€‰æ‹©åœ°å›¾æ–‡ä»¶")
        return
    
    print(f"\nğŸ—ºï¸ ä½¿ç”¨åœ°å›¾: {selected_file}")
    
    # åˆ›å»ºé¢„è®­ç»ƒGNNé›†æˆç³»ç»Ÿ
    try:
        coordinator = PretrainedGNNIntegratedCoordinator(
            map_file_path=selected_file,
            optimization_level=OptimizationLevel.FULL,
            gnn_enhancement_level=gnn_level
        )
        
        if not coordinator.map_data:
            print("âŒ åœ°å›¾æ•°æ®åŠ è½½å¤±è´¥")
            return
        
        # æ‰§è¡Œé¢„è®­ç»ƒGNNé›†æˆè§„åˆ’
        results, scenarios = coordinator.plan_with_pretrained_gnn_integration()
        
        if results and scenarios and any(r['trajectory'] for r in results.values()):
            print(f"\nğŸ¬ ç”Ÿæˆé¢„è®­ç»ƒGNNå¢å¼ºå¯è§†åŒ–...")
            
            # ä½¿ç”¨åŸå§‹åè°ƒå™¨è¿›è¡Œå¯è§†åŒ–
            original_coordinator = MultiVehicleCoordinator(selected_file, OptimizationLevel.FULL)
            original_coordinator.create_animation(results, scenarios)
            
            print(f"\nâœ… é¢„è®­ç»ƒGNNé›†æˆæ¼”ç¤ºå®Œæˆ!")
            print(f"\nğŸ† ä¿®å¤å¯¹æ¯”:")
            print(f"   åŸç‰ˆtrans.py: ç¼ºå°‘é¢„è®­ç»ƒ+åŸºç¡€GNN+éšæœºæƒé‡")
            print(f"   å¢å¼ºtrans.py: å®Œæ•´é¢„è®­ç»ƒ+å›¾å·ç§¯+æ³¨æ„åŠ›æœºåˆ¶+QPä¼˜åŒ–")
            print(f"   è´¨é‡æå‡: æ™ºèƒ½å†³ç­–æ¨¡å‹ + ä¿æŒè½¨è¿¹è´¨é‡ + é¢„è®­ç»ƒç¨³å®šæ€§")
            print(f"   æˆåŠŸç‡: {sum(1 for r in results.values() if r['trajectory'])}/{len(scenarios)}")
            
        else:
            print("âŒ è§„åˆ’å¤±è´¥")
        
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()