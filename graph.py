#!/usr/bin/env python3
"""
ğŸ›¡ï¸ å®‰å…¨å¢å¼ºçš„åœ°å›¾æ„ŸçŸ¥GNNé¢„è®­ç»ƒç³»ç»Ÿ - å®Œæ•´ä¿®å¤ç‰ˆ
è§£å†³é¢„è®­ç»ƒæ¨¡å‹å¯¼è‡´è½¦è¾†"è´´ç€è¿‡å»"çš„å±é™©è¡Œä¸ºé—®é¢˜

ä¸»è¦ä¿®å¤:
âœ… å®‰å…¨ä¼˜å…ˆçš„æ ‡ç­¾ç”Ÿæˆ - ä»æºå¤´è§£å†³æ¿€è¿›è¡Œä¸º
âœ… è·ç¦»æ„ŸçŸ¥çš„å®‰å…¨ç³»æ•° - è½¦è¾†é—´è·ç¦»è¶Šè¿‘å®‰å…¨è¦æ±‚è¶Šé«˜
âœ… å¤šå±‚å®‰å…¨ä¿éšœæœºåˆ¶ - é¢„è®­ç»ƒâ†’åº”ç”¨â†’éªŒè¯â†’åå¤„ç†
âœ… æ™ºèƒ½å®‰å…¨çº¦æŸ - é¿å…è¿‡åº¦åˆä½œå’Œæ¿€è¿›ç´§æ€¥ç­–ç•¥
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch_geometric.nn as pyg_nn
from torch_geometric.data import Data, DataLoader, Batch
from torch.utils.data import Dataset
import numpy as np
import math
import json
import os
from typing import List, Dict, Tuple
from dataclasses import dataclass
import time
from tqdm import tqdm

# å¯¼å…¥åœ°å›¾å’Œç¯å¢ƒç»„ä»¶
try:
    from trying import UnstructuredEnvironment, VehicleState, VehicleParameters
    HAS_TRYING = True
    print("âœ… æˆåŠŸå¯¼å…¥trying.pyç¯å¢ƒç»„ä»¶")
except ImportError:
    HAS_TRYING = False
    print("âš ï¸ æ— æ³•å¯¼å…¥trying.pyï¼Œå°†ä½¿ç”¨ç®€åŒ–å®ç°")
    
    @dataclass
    class VehicleState:
        x: float
        y: float
        theta: float
        v: float
        t: float
    
    class VehicleParameters:
        def __init__(self):
            self.max_speed = 8.0
            self.max_accel = 2.0
            self.length = 4.0
            self.width = 2.0
    
    class UnstructuredEnvironment:
        def __init__(self, size=100):
            self.size = size
            self.obstacle_map = np.zeros((size, size), dtype=bool)
        
        def is_valid_position(self, x, y):
            ix, iy = int(round(x)), int(round(y))
            if 0 <= ix < self.size and 0 <= iy < self.size:
                return not self.obstacle_map[iy, ix]
            return False

@dataclass
class SafetyEnhancedTrainingConfig:
    """ğŸ›¡ï¸ å®‰å…¨å¢å¼ºçš„è®­ç»ƒé…ç½®"""
    batch_size: int = 6
    learning_rate: float = 0.0008  # ğŸ›¡ï¸ ç•¥å¾®é™ä½å­¦ä¹ ç‡ï¼Œæ›´ç¨³å®šè®­ç»ƒ
    num_epochs: int = 45           # ğŸ›¡ï¸ å¢åŠ è®­ç»ƒè½®æ•°ï¼Œæ›´å¥½å­¦ä¹ å®‰å…¨è¡Œä¸º
    hidden_dim: int = 64
    num_layers: int = 3
    dropout: float = 0.15          # ğŸ›¡ï¸ ç•¥å¾®å¢åŠ dropoutï¼Œé¿å…è¿‡æ‹Ÿåˆæ¿€è¿›è¡Œä¸º
    weight_decay: float = 1e-4
    
    # ğŸ†• åœ°å›¾ç›¸å…³é…ç½®
    num_scenarios: int = 2500      # ğŸ›¡ï¸ å¢åŠ è®­ç»ƒåœºæ™¯æ•°é‡
    num_map_variants: int = 12     # ğŸ›¡ï¸ æ›´å¤šåœ°å›¾å˜ä½“ï¼Œæé«˜æ³›åŒ–èƒ½åŠ›
    max_vehicles: int = 6
    min_vehicles: int = 2
    use_real_maps: bool = True
    
    # ğŸ›¡ï¸ å®‰å…¨ç›¸å…³é…ç½®
    min_safe_distance: float = 8.0      # ğŸ›¡ï¸ æœ€å°å®‰å…¨è·ç¦»
    safety_priority_weight: float = 1.5  # ğŸ›¡ï¸ å®‰å…¨æŸå¤±æƒé‡
    danger_scenario_ratio: float = 0.3   # ğŸ›¡ï¸ 30%çš„å±é™©åœºæ™¯ç”¨äºè®­ç»ƒå®‰å…¨è¡Œä¸º
    
    # éªŒè¯é…ç½®
    val_split: float = 0.2
    early_stopping_patience: int = 12   # ğŸ›¡ï¸ å¢åŠ è€å¿ƒï¼Œé¿å…è¿‡æ—©åœæ­¢

class MapBasedEnvironmentGenerator:
    """ğŸ†• åŸºäºåœ°å›¾çš„ç¯å¢ƒç”Ÿæˆå™¨ï¼ˆä¿æŒåŸæœ‰åŠŸèƒ½ï¼‰"""
    
    def __init__(self, config: SafetyEnhancedTrainingConfig):
        self.config = config
        self.generated_maps = []
        self.real_maps = []
        
        print("ğŸ—ºï¸ åˆå§‹åŒ–åœ°å›¾æ„ŸçŸ¥ç¯å¢ƒç”Ÿæˆå™¨...")
        
        # æ‰«æå¯ç”¨çš„çœŸå®åœ°å›¾
        self._scan_real_maps()
        
        # ç”Ÿæˆå¤šæ ·åŒ–çš„è®­ç»ƒåœ°å›¾
        self._generate_training_maps()
    
    def _scan_real_maps(self):
        """æ‰«æçœŸå®åœ°å›¾æ–‡ä»¶"""
        print("ğŸ” æ‰«æçœŸå®åœ°å›¾æ–‡ä»¶...")
        
        json_files = [f for f in os.listdir('.') if f.endswith('.json')]
        
        for json_file in json_files:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    map_data = json.load(f)
                
                # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆçš„åœ°å›¾æ–‡ä»¶
                if (map_data.get('map_info') and 
                    'start_points' in map_data and 
                    'end_points' in map_data):
                    
                    env = UnstructuredEnvironment(size=100)
                    try:
                        if hasattr(env, 'load_from_json'):
                            success = env.load_from_json(json_file)
                            if success:
                                self.real_maps.append({
                                    'name': json_file,
                                    'environment': env,
                                    'data': map_data
                                })
                                print(f"  âœ… åŠ è½½åœ°å›¾: {json_file}")
                        else:
                            # æ‰‹åŠ¨è®¾ç½®éšœç¢ç‰©
                            if 'grid' in map_data:
                                grid = np.array(map_data['grid'])
                                if len(grid.shape) == 2 and grid.shape[0] <= env.size and grid.shape[1] <= env.size:
                                    for row in range(min(grid.shape[0], env.size)):
                                        for col in range(min(grid.shape[1], env.size)):
                                            if grid[row, col] == 1:
                                                env.obstacle_map[row, col] = True
                                    
                                    self.real_maps.append({
                                        'name': json_file,
                                        'environment': env,
                                        'data': map_data
                                    })
                                    print(f"  âœ… æ‰‹åŠ¨åŠ è½½åœ°å›¾: {json_file}")
                    except Exception as load_e:
                        print(f"  âš ï¸ åœ°å›¾åŠ è½½å¼‚å¸¸ {json_file}: {str(load_e)}")
                        continue
                    
            except Exception as e:
                continue
        
        print(f"ğŸ“Š å‘ç° {len(self.real_maps)} ä¸ªæœ‰æ•ˆåœ°å›¾æ–‡ä»¶")
    
    def _generate_training_maps(self):
        """ç”Ÿæˆå¤šæ ·åŒ–çš„è®­ç»ƒåœ°å›¾"""
        print(f"ğŸ—ï¸ ç”Ÿæˆ {self.config.num_map_variants} ç§è®­ç»ƒåœ°å›¾...")
        
        for i in range(self.config.num_map_variants):
            # åˆ›å»ºä¸åŒå¤æ‚åº¦çš„åœ°å›¾
            complexity = i / max(1, self.config.num_map_variants - 1)
            
            env = self._create_synthetic_map(complexity, f"synthetic_{i}")
            self.generated_maps.append({
                'name': f"synthetic_map_{i}",
                'environment': env,
                'complexity': complexity
            })
        
        print(f"âœ… ç”Ÿæˆäº† {len(self.generated_maps)} ä¸ªåˆæˆåœ°å›¾")
    
    def _create_synthetic_map(self, complexity: float, name: str) -> UnstructuredEnvironment:
        """åˆ›å»ºåˆæˆåœ°å›¾"""
        env = UnstructuredEnvironment(size=100)
        
        # åŸºäºå¤æ‚åº¦æ·»åŠ éšœç¢ç‰©
        obstacle_density = 0.05 + complexity * 0.15
        
        if complexity < 0.3:
            self._add_large_obstacles(env, int(3 + complexity * 5))
        elif complexity < 0.7:
            self._add_large_obstacles(env, int(2 + complexity * 3))
            self._add_corridor_obstacles(env, int(1 + complexity * 3))
        else:
            self._add_maze_obstacles(env, obstacle_density)
        
        return env
    
    def _add_large_obstacles(self, env: UnstructuredEnvironment, num_obstacles: int):
        """æ·»åŠ å¤§å‹éšœç¢ç‰©"""
        for _ in range(num_obstacles):
            center_x = np.random.randint(20, 80)
            center_y = np.random.randint(20, 80)
            width = np.random.randint(5, 15)
            height = np.random.randint(5, 15)
            
            for x in range(max(0, center_x - width//2), min(env.size, center_x + width//2)):
                for y in range(max(0, center_y - height//2), min(env.size, center_y + height//2)):
                    env.obstacle_map[y, x] = True
    
    def _add_corridor_obstacles(self, env: UnstructuredEnvironment, num_corridors: int):
        """æ·»åŠ èµ°å»Šå¼éšœç¢ç‰©"""
        for _ in range(num_corridors):
            if np.random.random() < 0.5:
                # æ°´å¹³èµ°å»Š
                y = np.random.randint(10, 90)
                start_x = np.random.randint(5, 30)
                end_x = np.random.randint(70, 95)
                thickness = np.random.randint(3, 8)
                
                for x in range(start_x, end_x):
                    for dy in range(-thickness//2, thickness//2):
                        if 0 <= y + dy < env.size:
                            env.obstacle_map[y + dy, x] = True
            else:
                # å‚ç›´èµ°å»Š
                x = np.random.randint(10, 90)
                start_y = np.random.randint(5, 30)
                end_y = np.random.randint(70, 95)
                thickness = np.random.randint(3, 8)
                
                for y in range(start_y, end_y):
                    for dx in range(-thickness//2, thickness//2):
                        if 0 <= x + dx < env.size:
                            env.obstacle_map[y, x + dx] = True
    
    def _add_maze_obstacles(self, env: UnstructuredEnvironment, density: float):
        """æ·»åŠ è¿·å®«å¼éšœç¢ç‰©"""
        grid_size = 4
        for i in range(0, env.size, grid_size):
            for j in range(0, env.size, grid_size):
                if np.random.random() < density:
                    for x in range(i, min(i + grid_size, env.size)):
                        for y in range(j, min(j + grid_size, env.size)):
                            env.obstacle_map[y, x] = True
    
    def get_random_environment(self) -> Tuple[UnstructuredEnvironment, str]:
        """è·å–éšæœºç¯å¢ƒ"""
        all_environments = []
        
        # æ·»åŠ çœŸå®åœ°å›¾
        if self.config.use_real_maps and self.real_maps:
            all_environments.extend([(env_data['environment'], env_data['name']) 
                                   for env_data in self.real_maps])
        
        # æ·»åŠ åˆæˆåœ°å›¾
        all_environments.extend([(env_data['environment'], env_data['name']) 
                               for env_data in self.generated_maps])
        
        if not all_environments:
            empty_env = UnstructuredEnvironment(size=100)
            return empty_env, "empty_fallback"
        
        import random
        env, name = random.choice(all_environments)
        return env, name

class SafetyAwareVehicleGraphBuilder:
    """ğŸ›¡ï¸ å®‰å…¨æ„ŸçŸ¥çš„è½¦è¾†å›¾æ„å»ºå™¨"""
    
    def __init__(self):
        self.node_feature_dim = 12  # åŒ…å«åœ°å›¾ç›¸å…³ç‰¹å¾
        self.edge_feature_dim = 6   # åŒ…å«ç¯å¢ƒäº¤äº’ç‰¹å¾
        self.global_feature_dim = 8
    
    def build_interaction_graph(self, vehicles_info: List[Dict], 
                              environment: UnstructuredEnvironment) -> Data:
        """æ„å»ºåŒ…å«åœ°å›¾ä¿¡æ¯çš„äº¤äº’å›¾"""
        n_vehicles = len(vehicles_info)
        
        if n_vehicles == 0:
            return self._create_empty_data()
        
        # æå–åœ°å›¾æ„ŸçŸ¥çš„èŠ‚ç‚¹ç‰¹å¾
        node_features = self._extract_map_aware_node_features(vehicles_info, environment)
        
        # æ„å»ºç¯å¢ƒæ„ŸçŸ¥çš„è¾¹ç‰¹å¾
        edge_indices, edge_features = self._build_environment_aware_edges(vehicles_info, environment)
        
        # æå–ç¯å¢ƒå…¨å±€ç‰¹å¾
        global_features = self._extract_environment_global_features(vehicles_info, environment)
        
        return Data(
            x=torch.tensor(node_features, dtype=torch.float32),
            edge_index=torch.tensor(edge_indices, dtype=torch.long).T if edge_indices else torch.zeros((2, 0), dtype=torch.long),
            edge_attr=torch.tensor(edge_features, dtype=torch.float32) if edge_features else torch.zeros((0, self.edge_feature_dim), dtype=torch.float32),
            global_features=torch.tensor(global_features, dtype=torch.float32)
        )
    
    def _extract_map_aware_node_features(self, vehicles_info: List[Dict], 
                                       environment: UnstructuredEnvironment) -> List[List[float]]:
        """æå–åœ°å›¾æ„ŸçŸ¥çš„èŠ‚ç‚¹ç‰¹å¾"""
        node_features = []
        
        for vehicle_info in vehicles_info:
            state = vehicle_info['current_state']
            goal = vehicle_info['goal_state']
            
            # åŸºç¡€ç‰¹å¾
            dx = goal.x - state.x
            dy = goal.y - state.y
            distance_to_goal = math.sqrt(dx*dx + dy*dy)
            goal_bearing = math.atan2(dy, dx)
            
            # åœ°å›¾ç›¸å…³ç‰¹å¾
            obstacle_density_nearby = self._compute_local_obstacle_density(state, environment)
            path_clearance = self._compute_path_clearance(state, goal, environment)
            nearest_obstacle_distance = self._find_nearest_obstacle_distance(state, environment)
            
            # 12ç»´å¢å¼ºç‰¹å¾ï¼ˆåŒ…å«åœ°å›¾ä¿¡æ¯ï¼‰
            features = [
                state.x / 100.0,                     # [0] å½’ä¸€åŒ–xåæ ‡
                state.y / 100.0,                     # [1] å½’ä¸€åŒ–yåæ ‡
                math.cos(state.theta),               # [2] èˆªå‘ä½™å¼¦
                math.sin(state.theta),               # [3] èˆªå‘æ­£å¼¦
                state.v / 8.0,                       # [4] å½’ä¸€åŒ–é€Ÿåº¦
                distance_to_goal / 100.0,            # [5] å½’ä¸€åŒ–ç›®æ ‡è·ç¦»
                math.cos(goal_bearing),              # [6] ç›®æ ‡æ–¹å‘ä½™å¼¦
                math.sin(goal_bearing),              # [7] ç›®æ ‡æ–¹å‘æ­£å¼¦
                vehicle_info.get('priority', 1) / 5.0,  # [8] å½’ä¸€åŒ–ä¼˜å…ˆçº§
                obstacle_density_nearby,             # [9] é™„è¿‘éšœç¢ç‰©å¯†åº¦
                path_clearance,                      # [10] è·¯å¾„é€šç•…åº¦
                min(1.0, nearest_obstacle_distance / 20.0)  # [11] æœ€è¿‘éšœç¢ç‰©è·ç¦»
            ]
            
            node_features.append(features)
        
        return node_features
    
    def _compute_local_obstacle_density(self, state: VehicleState, 
                                      environment: UnstructuredEnvironment, 
                                      radius: int = 10) -> float:
        """è®¡ç®—å±€éƒ¨éšœç¢ç‰©å¯†åº¦"""
        center_x, center_y = int(state.x), int(state.y)
        
        total_cells = 0
        obstacle_cells = 0
        
        for dx in range(-radius, radius + 1):
            for dy in range(-radius, radius + 1):
                x, y = center_x + dx, center_y + dy
                if 0 <= x < environment.size and 0 <= y < environment.size:
                    total_cells += 1
                    if environment.obstacle_map[y, x]:
                        obstacle_cells += 1
        
        return obstacle_cells / max(total_cells, 1)
    
    def _compute_path_clearance(self, start: VehicleState, goal: VehicleState, 
                              environment: UnstructuredEnvironment) -> float:
        """è®¡ç®—ä»èµ·ç‚¹åˆ°ç»ˆç‚¹çš„è·¯å¾„é€šç•…åº¦"""
        num_samples = 20
        clear_samples = 0
        
        for i in range(num_samples):
            t = i / max(num_samples - 1, 1)
            x = start.x + t * (goal.x - start.x)
            y = start.y + t * (goal.y - start.y)
            
            if environment.is_valid_position(x, y):
                clear_samples += 1
        
        return clear_samples / num_samples
    
    def _find_nearest_obstacle_distance(self, state: VehicleState, 
                                      environment: UnstructuredEnvironment,
                                      max_search_radius: int = 20) -> float:
        """å¯»æ‰¾æœ€è¿‘éšœç¢ç‰©çš„è·ç¦»"""
        center_x, center_y = int(state.x), int(state.y)
        min_distance = max_search_radius
        
        for radius in range(1, max_search_radius + 1):
            for dx in range(-radius, radius + 1):
                for dy in range(-radius, radius + 1):
                    if abs(dx) == radius or abs(dy) == radius:
                        x, y = center_x + dx, center_y + dy
                        if (0 <= x < environment.size and 0 <= y < environment.size and
                            environment.obstacle_map[y, x]):
                            distance = math.sqrt(dx*dx + dy*dy)
                            min_distance = min(min_distance, distance)
                            return min_distance
        
        return min_distance
    
    def _build_environment_aware_edges(self, vehicles_info: List[Dict], 
                                     environment: UnstructuredEnvironment) -> Tuple[List, List]:
        """æ„å»ºç¯å¢ƒæ„ŸçŸ¥çš„è¾¹ç‰¹å¾"""
        n_vehicles = len(vehicles_info)
        edge_indices = []
        edge_features = []
        
        for i in range(n_vehicles):
            for j in range(i + 1, n_vehicles):
                state1 = vehicles_info[i]['current_state']
                state2 = vehicles_info[j]['current_state']
                
                # è®¡ç®—åŸºç¡€äº¤äº’ç‰¹å¾
                distance = math.sqrt((state1.x - state2.x)**2 + (state1.y - state2.y)**2)
                
                if distance < 35.0:  # äº¤äº’èŒƒå›´
                    # ç¯å¢ƒç›¸å…³çš„è¾¹ç‰¹å¾
                    line_of_sight = self._check_line_of_sight(state1, state2, environment)
                    shared_corridor = self._check_shared_corridor(state1, state2, environment)
                    obstacle_interference = self._compute_obstacle_interference(state1, state2, environment)
                    
                    # 6ç»´ç¯å¢ƒæ„ŸçŸ¥è¾¹ç‰¹å¾
                    edge_feat = [
                        distance / 35.0,                      # [0] å½’ä¸€åŒ–è·ç¦»
                        (state1.v + state2.v) / 16.0,         # [1] å¹³å‡é€Ÿåº¦
                        abs(state1.theta - state2.theta) / math.pi,  # [2] è§’åº¦å·®
                        line_of_sight,                        # [3] è§†çº¿é€šç•…åº¦
                        shared_corridor,                      # [4] å…±äº«èµ°å»Šæ ‡å¿—
                        obstacle_interference                 # [5] éšœç¢ç‰©å¹²æ‰°ç¨‹åº¦
                    ]
                    
                    # æ·»åŠ åŒå‘è¾¹
                    edge_indices.extend([[i, j], [j, i]])
                    edge_features.extend([edge_feat, edge_feat])
        
        return edge_indices, edge_features
    
    def _check_line_of_sight(self, state1: VehicleState, state2: VehicleState, 
                           environment: UnstructuredEnvironment) -> float:
        """æ£€æŸ¥ä¸¤è½¦ä¹‹é—´çš„è§†çº¿é€šç•…åº¦"""
        num_samples = 10
        clear_samples = 0
        
        for i in range(num_samples):
            t = i / max(num_samples - 1, 1)
            x = state1.x + t * (state2.x - state1.x)
            y = state1.y + t * (state2.y - state1.y)
            
            if environment.is_valid_position(x, y):
                clear_samples += 1
        
        return clear_samples / num_samples
    
    def _check_shared_corridor(self, state1: VehicleState, state2: VehicleState, 
                             environment: UnstructuredEnvironment) -> float:
        """æ£€æŸ¥æ˜¯å¦åœ¨å…±äº«èµ°å»Šä¸­"""
        density1 = self._compute_local_obstacle_density(state1, environment, radius=5)
        density2 = self._compute_local_obstacle_density(state2, environment, radius=5)
        
        if density1 < 0.3 and density2 < 0.3 and abs(density1 - density2) < 0.2:
            return 1.0
        else:
            return 0.0
    
    def _compute_obstacle_interference(self, state1: VehicleState, state2: VehicleState, 
                                     environment: UnstructuredEnvironment) -> float:
        """è®¡ç®—éšœç¢ç‰©å¯¹è½¦è¾†äº¤äº’çš„å¹²æ‰°ç¨‹åº¦"""
        num_samples = 8
        obstacle_count = 0
        
        for i in range(num_samples):
            t = i / max(num_samples - 1, 1)
            x = state1.x + t * (state2.x - state1.x)
            y = state1.y + t * (state2.y - state1.y)
            
            if not environment.is_valid_position(x, y):
                obstacle_count += 1
        
        return obstacle_count / num_samples
    
    def _extract_environment_global_features(self, vehicles_info: List[Dict], 
                                           environment: UnstructuredEnvironment) -> List[float]:
        """æå–ç¯å¢ƒå…¨å±€ç‰¹å¾"""
        n_vehicles = len(vehicles_info)
        
        if n_vehicles == 0:
            return [0.0] * self.global_feature_dim
        
        # åŸºç¡€ç»Ÿè®¡
        speeds = [v['current_state'].v for v in vehicles_info]
        
        # ç¯å¢ƒç»Ÿè®¡
        total_obstacle_density = np.sum(environment.obstacle_map) / (environment.size * environment.size)
        
        # è½¦è¾†åœ¨ç¯å¢ƒä¸­çš„åˆ†å¸ƒ
        avg_local_density = sum(
            self._compute_local_obstacle_density(v['current_state'], environment)
            for v in vehicles_info
        ) / n_vehicles
        
        # ç©ºé—´æ‹¥æŒ¤ç¨‹åº¦
        positions = [(v['current_state'].x, v['current_state'].y) for v in vehicles_info]
        if len(positions) > 1:
            distances = []
            for i in range(len(positions)):
                for j in range(i + 1, len(positions)):
                    dist = math.sqrt((positions[i][0] - positions[j][0])**2 + 
                                   (positions[i][1] - positions[j][1])**2)
                    distances.append(dist)
            avg_vehicle_distance = sum(distances) / len(distances)
        else:
            avg_vehicle_distance = 50.0
        
        # 8ç»´ç¯å¢ƒå…¨å±€ç‰¹å¾
        global_features = [
            n_vehicles / 10.0,                      # [0] å½’ä¸€åŒ–è½¦è¾†æ•°
            sum(speeds) / (n_vehicles * 8.0),       # [1] å¹³å‡é€Ÿåº¦æ¯”
            total_obstacle_density,                 # [2] å…¨å±€éšœç¢ç‰©å¯†åº¦
            avg_local_density,                      # [3] è½¦è¾†åŒºåŸŸå¹³å‡éšœç¢ç‰©å¯†åº¦
            avg_vehicle_distance / 100.0,           # [4] è½¦è¾†é—´å¹³å‡è·ç¦»
            min(1.0, len([v for v in vehicles_info 
                         if self._compute_local_obstacle_density(v['current_state'], environment) > 0.5]) / n_vehicles),  # [5] é«˜éšœç¢å¯†åº¦è½¦è¾†æ¯”ä¾‹
            0.5,                                    # [6] é¢„ç•™ç‰¹å¾
            0.5                                     # [7] é¢„ç•™ç‰¹å¾
        ]
        
        return global_features
    
    def _create_empty_data(self) -> Data:
        """åˆ›å»ºç©ºæ•°æ®å¯¹è±¡"""
        return Data(
            x=torch.zeros((0, self.node_feature_dim), dtype=torch.float32),
            edge_index=torch.zeros((2, 0), dtype=torch.long),
            edge_attr=torch.zeros((0, self.edge_feature_dim), dtype=torch.float32),
            global_features=torch.zeros(self.global_feature_dim, dtype=torch.float32)
        )

class SafetyEnhancedVehicleScenarioGenerator:
    """ğŸ›¡ï¸ å®‰å…¨å¢å¼ºçš„è½¦è¾†åœºæ™¯ç”Ÿæˆå™¨"""
    
    def __init__(self, config: SafetyEnhancedTrainingConfig):
        self.config = config
        self.env_generator = MapBasedEnvironmentGenerator(config)
        self.graph_builder = SafetyAwareVehicleGraphBuilder()
        
    def generate_training_data(self) -> List[Tuple]:
        """ç”ŸæˆåŸºäºåœ°å›¾çš„è®­ç»ƒæ•°æ®"""
        print(f"ğŸ›¡ï¸ ç”Ÿæˆ {self.config.num_scenarios} ä¸ªå®‰å…¨æ„ŸçŸ¥åœ°å›¾åœºæ™¯...")
        
        data_list = []
        failed_scenarios = 0
        
        # ğŸ›¡ï¸ åˆ†é…å±é™©åœºæ™¯å’Œå®‰å…¨åœºæ™¯çš„æ¯”ä¾‹
        num_danger_scenarios = int(self.config.num_scenarios * self.config.danger_scenario_ratio)
        num_safe_scenarios = self.config.num_scenarios - num_danger_scenarios
        
        print(f"ğŸ“Š åœºæ™¯åˆ†é…: {num_danger_scenarios} å±é™©åœºæ™¯ + {num_safe_scenarios} å®‰å…¨åœºæ™¯")
        
        for i in tqdm(range(self.config.num_scenarios)):
            try:
                # è·å–éšæœºç¯å¢ƒ
                environment, env_name = self.env_generator.get_random_environment()
                
                # ğŸ›¡ï¸ å†³å®šç”Ÿæˆå±é™©åœºæ™¯è¿˜æ˜¯å®‰å…¨åœºæ™¯
                is_danger_scenario = i < num_danger_scenarios
                
                # ç”Ÿæˆè¯¥ç¯å¢ƒä¸‹çš„è½¦è¾†åœºæ™¯
                if is_danger_scenario:
                    vehicles_info = self._generate_danger_scenario(environment)
                else:
                    num_vehicles = np.random.randint(self.config.min_vehicles, self.config.max_vehicles + 1)
                    vehicles_info = self._generate_safe_scenario(num_vehicles, environment)
                
                if not vehicles_info:
                    failed_scenarios += 1
                    continue
                
                # æ„å»ºåœ°å›¾æ„ŸçŸ¥çš„å›¾æ•°æ®
                graph_data = self.graph_builder.build_interaction_graph(vehicles_info, environment)
                
                if graph_data.x.size(0) == 0:
                    failed_scenarios += 1
                    continue
                
                # ğŸ›¡ï¸ ç”Ÿæˆå®‰å…¨æ„ŸçŸ¥çš„æ ‡ç­¾
                labels = self._generate_safety_enhanced_labels(vehicles_info, environment, len(vehicles_info))
                
                # éªŒè¯æ•°æ®ä¸€è‡´æ€§
                if self._validate_data_consistency(graph_data, labels, len(vehicles_info)):
                    data_list.append((graph_data, labels))
                    
                    # æ¯100ä¸ªåœºæ™¯æ‰“å°è¿›åº¦
                    if (i + 1) % 100 == 0:
                        success_rate = len(data_list) / (i + 1) * 100
                        scenario_type = "å±é™©" if is_danger_scenario else "å®‰å…¨"
                        print(f"    ç”Ÿæˆè¿›åº¦: {i+1}/{self.config.num_scenarios} "
                              f"(æˆåŠŸ: {len(data_list)}, æˆåŠŸç‡: {success_rate:.1f}%, "
                              f"å½“å‰: {scenario_type}åœºæ™¯, ç¯å¢ƒ: {env_name})")
                else:
                    failed_scenarios += 1
                
            except Exception as e:
                failed_scenarios += 1
                if i < 10:
                    print(f"âš ï¸ ç”Ÿæˆåœºæ™¯ {i} æ—¶å‡ºé”™: {str(e)}")
                continue
        
        print(f"âœ… æˆåŠŸç”Ÿæˆ {len(data_list)} ä¸ªå®‰å…¨æ„ŸçŸ¥åœ°å›¾åœºæ™¯")
        print(f"ğŸ“Š ç»Ÿè®¡: æˆåŠŸ {len(data_list)}, å¤±è´¥ {failed_scenarios}, "
              f"æ€»æˆåŠŸç‡ {len(data_list)/(len(data_list)+failed_scenarios)*100:.1f}%")
        
        return data_list
    
    def _generate_danger_scenario(self, environment: UnstructuredEnvironment) -> List[Dict]:
        """ğŸ›¡ï¸ ç”Ÿæˆå±é™©åœºæ™¯ï¼ˆç”¨äºè®­ç»ƒå®‰å…¨è¡Œä¸ºï¼‰"""
        vehicles_info = []
        num_vehicles = np.random.randint(3, 6)  # å±é™©åœºæ™¯ä½¿ç”¨æ›´å¤šè½¦è¾†
        
        # ğŸ›¡ï¸ æ•…æ„åˆ›å»ºæ½œåœ¨å†²çªçš„åœºæ™¯
        attempts = 0
        max_attempts = 30
        
        # ç¬¬ä¸€è¾†è½¦
        start_x, start_y = self._find_valid_position(environment)
        goal_x, goal_y = self._find_valid_position(environment)
        
        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„è·ç¦»
        while math.sqrt((goal_x - start_x)**2 + (goal_y - start_y)**2) < 20.0 and attempts < max_attempts:
            goal_x, goal_y = self._find_valid_position(environment)
            attempts += 1
        
        theta1 = math.atan2(goal_y - start_y, goal_x - start_x)
        vehicles_info.append({
            'id': 1,
            'priority': np.random.randint(1, 4),
            'current_state': VehicleState(x=start_x, y=start_y, theta=theta1, v=np.random.uniform(3, 6), t=0.0),
            'goal_state': VehicleState(x=goal_x, y=goal_y, theta=theta1, v=np.random.uniform(1, 4), t=0.0)
        })
        
        # åç»­è½¦è¾†ï¼šæ•…æ„åˆ›é€ æ¥è¿‘æˆ–äº¤å‰çš„è·¯å¾„
        for i in range(1, num_vehicles):
            attempts = 0
            found_conflict = False
            
            while attempts < max_attempts and not found_conflict:
                # ğŸ›¡ï¸ å°è¯•åœ¨ç°æœ‰è½¦è¾†è·¯å¾„é™„è¿‘ç”Ÿæˆæ–°è½¦è¾†
                existing_vehicle = vehicles_info[np.random.randint(0, len(vehicles_info))]
                existing_start = existing_vehicle['current_state']
                existing_goal = existing_vehicle['goal_state']
                
                # åœ¨ç°æœ‰è·¯å¾„é™„è¿‘ç”Ÿæˆèµ·ç‚¹
                offset_x = np.random.uniform(-15, 15)
                offset_y = np.random.uniform(-15, 15)
                
                new_start_x = max(5, min(95, existing_start.x + offset_x))
                new_start_y = max(5, min(95, existing_start.y + offset_y))
                
                if environment.is_valid_position(new_start_x, new_start_y):
                    # ç”Ÿæˆå¯èƒ½äº¤å‰çš„ç›®æ ‡ç‚¹
                    cross_factor = np.random.uniform(0.3, 0.8)
                    new_goal_x = existing_start.x + cross_factor * (existing_goal.x - existing_start.x) + np.random.uniform(-10, 10)
                    new_goal_y = existing_start.y + cross_factor * (existing_goal.y - existing_start.y) + np.random.uniform(-10, 10)
                    
                    new_goal_x = max(5, min(95, new_goal_x))
                    new_goal_y = max(5, min(95, new_goal_y))
                    
                    if (environment.is_valid_position(new_goal_x, new_goal_y) and
                        math.sqrt((new_goal_x - new_start_x)**2 + (new_goal_y - new_start_y)**2) > 12.0):
                        
                        theta = math.atan2(new_goal_y - new_start_y, new_goal_x - new_start_x)
                        vehicles_info.append({
                            'id': i + 1,
                            'priority': np.random.randint(1, 5),
                            'current_state': VehicleState(x=new_start_x, y=new_start_y, theta=theta, v=np.random.uniform(2, 6), t=0.0),
                            'goal_state': VehicleState(x=new_goal_x, y=new_goal_y, theta=theta, v=np.random.uniform(1, 4), t=0.0)
                        })
                        found_conflict = True
                
                attempts += 1
            
            # å¦‚æœæ— æ³•åˆ›å»ºå†²çªåœºæ™¯ï¼Œç”¨å®‰å…¨æ–¹å¼ç”Ÿæˆ
            if not found_conflict:
                start_x, start_y = self._find_valid_position(environment)
                goal_x, goal_y = self._find_valid_position(environment)
                
                while math.sqrt((goal_x - start_x)**2 + (goal_y - start_y)**2) < 15.0:
                    goal_x, goal_y = self._find_valid_position(environment)
                
                theta = math.atan2(goal_y - start_y, goal_x - start_x)
                vehicles_info.append({
                    'id': i + 1,
                    'priority': np.random.randint(1, 4),
                    'current_state': VehicleState(x=start_x, y=start_y, theta=theta, v=np.random.uniform(2, 5), t=0.0),
                    'goal_state': VehicleState(x=goal_x, y=goal_y, theta=theta, v=np.random.uniform(1, 3), t=0.0)
                })
        
        return vehicles_info
    
    def _generate_safe_scenario(self, num_vehicles: int, environment: UnstructuredEnvironment) -> List[Dict]:
        """ğŸ›¡ï¸ ç”Ÿæˆå®‰å…¨åœºæ™¯ï¼ˆè½¦è¾†é—´æœ‰è¶³å¤Ÿè·ç¦»ï¼‰"""
        vehicles_info = []
        max_attempts = 50
        
        for i in range(num_vehicles):
            attempts = 0
            
            while attempts < max_attempts:
                # ğŸ›¡ï¸ ç¡®ä¿ä¸ç°æœ‰è½¦è¾†æœ‰è¶³å¤Ÿè·ç¦»
                start_x, start_y = self._find_valid_position(environment)
                goal_x, goal_y = self._find_valid_position(environment)
                
                # æ£€æŸ¥è·ç¦»è¦æ±‚
                if math.sqrt((goal_x - start_x)**2 + (goal_y - start_y)**2) < 15.0:
                    attempts += 1
                    continue
                
                # ğŸ›¡ï¸ æ£€æŸ¥ä¸ç°æœ‰è½¦è¾†çš„è·ç¦»
                too_close = False
                for existing_vehicle in vehicles_info:
                    existing_start = existing_vehicle['current_state']
                    distance_to_existing = math.sqrt((start_x - existing_start.x)**2 + (start_y - existing_start.y)**2)
                    
                    if distance_to_existing < 20.0:  # ğŸ›¡ï¸ æœ€å°å®‰å…¨é—´è·
                        too_close = True
                        break
                
                if not too_close:
                    theta = math.atan2(goal_y - start_y, goal_x - start_x)
                    vehicles_info.append({
                        'id': i + 1,
                        'priority': np.random.randint(1, 5),
                        'current_state': VehicleState(x=start_x, y=start_y, theta=theta, v=np.random.uniform(2, 5), t=0.0),
                        'goal_state': VehicleState(x=goal_x, y=goal_y, theta=theta, v=np.random.uniform(1, 4), t=0.0)
                    })
                    break
                
                attempts += 1
            
            # å¦‚æœæ— æ³•æ‰¾åˆ°å®‰å…¨ä½ç½®ï¼Œè·³è¿‡è¿™ä¸ªåœºæ™¯
            if attempts >= max_attempts:
                return []
        
        return vehicles_info
    
    def _find_valid_position(self, environment: UnstructuredEnvironment, 
                           max_attempts: int = 100) -> Tuple[float, float]:
        """åœ¨ç¯å¢ƒä¸­å¯»æ‰¾æœ‰æ•ˆä½ç½®"""
        for _ in range(max_attempts):
            x = np.random.uniform(5, environment.size - 5)
            y = np.random.uniform(5, environment.size - 5)
            
            if environment.is_valid_position(x, y):
                return x, y
        
        return environment.size / 2, environment.size / 2
    
    def _generate_safety_enhanced_labels(self, vehicles_info: List[Dict], 
                                       environment: UnstructuredEnvironment,
                                       num_vehicles: int) -> Dict:
        """ğŸ›¡ï¸ å®‰å…¨å¢å¼ºçš„æ ‡ç­¾ç”Ÿæˆ"""
        labels = {
            'priority': [],
            'cooperation': [],
            'urgency': [],
            'safety': [],
            'speed_adjustment': [],
            'route_preference': []
        }
        
        # ğŸ›¡ï¸ è®¡ç®—å…¨å±€å®‰å…¨çŠ¶å†µ
        vehicle_positions = [(v['current_state'].x, v['current_state'].y) for v in vehicles_info]
        min_distance_between_vehicles = float('inf')
        
        if len(vehicle_positions) > 1:
            for i in range(len(vehicle_positions)):
                for j in range(i + 1, len(vehicle_positions)):
                    dist = math.sqrt((vehicle_positions[i][0] - vehicle_positions[j][0])**2 + 
                                   (vehicle_positions[i][1] - vehicle_positions[j][1])**2)
                    min_distance_between_vehicles = min(min_distance_between_vehicles, dist)
        
        # ğŸ›¡ï¸ å®‰å…¨ç³»æ•°ï¼šè½¦è¾†é—´è·ç¦»è¶Šè¿‘ï¼Œå®‰å…¨è¦æ±‚è¶Šé«˜
        global_safety_urgency = 1.0 if min_distance_between_vehicles < 15.0 else 0.6
        
        for i in range(num_vehicles):
            try:
                if i < len(vehicles_info):
                    vehicle = vehicles_info[i]
                    state = vehicle['current_state']
                    
                    # åœ°å›¾ç¯å¢ƒç‰¹å¾
                    obstacle_density = self.graph_builder._compute_local_obstacle_density(state, environment)
                    path_clearance = self.graph_builder._compute_path_clearance(
                        state, vehicle['goal_state'], environment)
                    nearest_obstacle = self.graph_builder._find_nearest_obstacle_distance(state, environment)
                    
                    # ğŸ›¡ï¸ è®¡ç®—ä¸å…¶ä»–è½¦è¾†çš„æœ€è¿‘è·ç¦»
                    min_distance_to_others = float('inf')
                    for j, other_vehicle in enumerate(vehicles_info):
                        if i != j:
                            other_state = other_vehicle['current_state']
                            dist = math.sqrt((state.x - other_state.x)**2 + (state.y - other_state.y)**2)
                            min_distance_to_others = min(min_distance_to_others, dist)
                    
                    # ğŸ›¡ï¸ å®‰å…¨ä¼˜å…ˆçš„æ ‡ç­¾ç”Ÿæˆ
                    
                    # 1. ä¼˜å…ˆçº§è°ƒæ•´ - åœ¨æ‹¥æŒ¤ç¯å¢ƒä¸­æ›´ä¿å®ˆ
                    priority_adj = (vehicle.get('priority', 1) - 3) / 3.0
                    if min_distance_to_others < 20.0:  # ğŸ›¡ï¸ è·ç¦»å…¶ä»–è½¦è¾†å¤ªè¿‘æ—¶é™ä½ä¼˜å…ˆçº§
                        priority_adj *= 0.5  # æ›´ä¿å®ˆ
                    if obstacle_density > 0.4:
                        priority_adj *= 0.7  # åœ¨å¤æ‚ç¯å¢ƒä¸­æ›´ä¿å®ˆ
                    labels['priority'].append([np.tanh(priority_adj)])
                    
                    # 2. åˆä½œå€¾å‘ - ğŸ›¡ï¸ å®‰å…¨ä¼˜å…ˆï¼Œä¸è¿‡åº¦åˆä½œ
                    base_cooperation = 0.3 + 0.2 * obstacle_density + 0.2 * (1 - path_clearance)
                    if min_distance_to_others < 15.0:
                        cooperation = min(0.9, base_cooperation + 0.3)  # ğŸ›¡ï¸ è¿‘è·ç¦»æ—¶æé«˜åˆä½œä½†ä¸è¿‡åº¦
                    else:
                        cooperation = min(0.7, base_cooperation)  # ğŸ›¡ï¸ é™åˆ¶è¿‡åº¦åˆä½œ
                    labels['cooperation'].append([cooperation])
                    
                    # 3. ç´§æ€¥ç¨‹åº¦ - ğŸ›¡ï¸ å®‰å…¨çº¦æŸä¸‹çš„ç´§æ€¥åº¦
                    base_urgency = 0.2 + 0.3 * (1 - path_clearance) + 0.2 * (1 - min(1.0, nearest_obstacle / 10.0))
                    if min_distance_to_others < 10.0:
                        urgency = min(0.4, base_urgency)  # ğŸ›¡ï¸ å±é™©æƒ…å†µä¸‹é™ä½ç´§æ€¥åº¦ï¼Œä¼˜å…ˆå®‰å…¨
                    elif min_distance_to_others < 20.0:
                        urgency = min(0.6, base_urgency)  # ğŸ›¡ï¸ ä¸­ç­‰è·ç¦»æ—¶é€‚åº¦ç´§æ€¥
                    else:
                        urgency = min(0.8, base_urgency)  # å®‰å…¨è·ç¦»æ—¶å¯ä»¥è¾ƒç´§æ€¥
                    labels['urgency'].append([urgency])
                    
                    # 4. å®‰å…¨ç³»æ•° - ğŸ›¡ï¸ è¿™æ˜¯å…³é”®ï¼å¤§å¹…å¢å¼ºå®‰å…¨è¦æ±‚
                    base_safety = 0.5 + 0.3 * obstacle_density + 0.2 * (1 - min(1.0, nearest_obstacle / 15.0))
                    
                    # ğŸ›¡ï¸ åŸºäºè½¦è¾†é—´è·ç¦»åŠ¨æ€è°ƒæ•´å®‰å…¨ç³»æ•°
                    if min_distance_to_others < 8.0:
                        safety = 0.95  # ğŸ›¡ï¸ éå¸¸å±é™©ï¼Œæœ€é«˜å®‰å…¨ç­‰çº§
                    elif min_distance_to_others < 15.0:
                        safety = 0.85  # ğŸ›¡ï¸ å±é™©ï¼Œé«˜å®‰å…¨ç­‰çº§
                    elif min_distance_to_others < 25.0:
                        safety = max(0.7, base_safety + 0.2)  # ğŸ›¡ï¸ ä¸­ç­‰å®‰å…¨è¦æ±‚
                    else:
                        safety = max(0.5, base_safety)  # åŸºç¡€å®‰å…¨è¦æ±‚
                    
                    # ğŸ›¡ï¸ å…¨å±€å®‰å…¨çŠ¶å†µåŠ æˆ
                    safety = min(1.0, safety + global_safety_urgency * 0.1)
                    labels['safety'].append([safety])
                    
                    # 5. é€Ÿåº¦è°ƒæ•´ - ğŸ›¡ï¸ å®‰å…¨ä¼˜å…ˆçš„é€Ÿåº¦æ§åˆ¶
                    if min_distance_to_others < 10.0:
                        speed_adj = -0.4  # ğŸ›¡ï¸ å±é™©è·ç¦»æ—¶å¤§å¹…å‡é€Ÿ
                    elif min_distance_to_others < 20.0:  
                        speed_adj = -0.2  # ğŸ›¡ï¸ ä¸­ç­‰è·ç¦»æ—¶é€‚åº¦å‡é€Ÿ
                    elif obstacle_density > 0.5 or path_clearance < 0.5:
                        speed_adj = -0.15  # ç¯å¢ƒå¤æ‚æ—¶å‡é€Ÿ
                    elif obstacle_density < 0.2 and path_clearance > 0.8 and min_distance_to_others > 30.0:
                        speed_adj = 0.1   # ğŸ›¡ï¸ åªæœ‰åœ¨å®‰å…¨ä¸”é€šç•…æ—¶æ‰åŠ é€Ÿ
                    else:
                        speed_adj = 0.0
                    labels['speed_adjustment'].append([speed_adj])
                    
                    # 6. è·¯å¾„åå¥½ - ğŸ›¡ï¸ å®‰å…¨å¯¼å‘çš„è·¯å¾„é€‰æ‹©
                    try:
                        if min_distance_to_others < 15.0:
                            # ğŸ›¡ï¸ å±é™©æƒ…å†µä¸‹åå‘é¿è®©ï¼ˆå·¦å³ç»•è¡Œï¼‰
                            alpha_params = np.array([2.5, 0.5, 2.5])  # é¿å…ç›´è¡Œ
                            route_pref = np.random.dirichlet(alpha_params)
                        elif path_clearance < 0.3:
                            # è·¯å¾„å—é˜»æ—¶ç»•è¡Œ
                            alpha_params = np.array([2.0, 1.0, 2.0])
                            route_pref = np.random.dirichlet(alpha_params)
                        else:
                            # ğŸ›¡ï¸ å®‰å…¨æƒ…å†µä¸‹å¯ä»¥ç›´è¡Œï¼Œä½†ä»ä¿æŒä¸€å®šé¿è®©æ„è¯†
                            alpha_params = np.array([1.5, 2.5, 1.5])  # ç¨å¾®åå‘ç›´è¡Œä½†ä¿æŒé¿è®©é€‰é¡¹
                            route_pref = np.random.dirichlet(alpha_params)
                        
                        labels['route_preference'].append(route_pref.tolist())
                    except Exception:
                        labels['route_preference'].append([0.3, 0.4, 0.3])  # ğŸ›¡ï¸ å®‰å…¨çš„é»˜è®¤åˆ†å¸ƒ
                        
                else:
                    # é»˜è®¤å®‰å…¨æ ‡ç­¾
                    labels['priority'].append([0.0])
                    labels['cooperation'].append([0.6])  # ğŸ›¡ï¸ é€‚åº¦åˆä½œ
                    labels['urgency'].append([0.3])     # ğŸ›¡ï¸ ä½ç´§æ€¥åº¦
                    labels['safety'].append([0.8])      # ğŸ›¡ï¸ é«˜å®‰å…¨è¦æ±‚
                    labels['speed_adjustment'].append([-0.1])  # ğŸ›¡ï¸ ç•¥å¾®å‡é€Ÿ
                    labels['route_preference'].append([0.3, 0.4, 0.3])
                    
            except Exception as label_e:
                print(f"âš ï¸ ç”Ÿæˆè½¦è¾†{i}å®‰å…¨æ ‡ç­¾æ—¶å‡ºé”™: {str(label_e)}")
                # ğŸ›¡ï¸ é”™è¯¯æ—¶ä½¿ç”¨æœ€å®‰å…¨çš„é»˜è®¤å€¼
                labels['priority'].append([0.0])
                labels['cooperation'].append([0.7])
                labels['urgency'].append([0.2])
                labels['safety'].append([0.9])      # ğŸ›¡ï¸ æœ€é«˜å®‰å…¨ç­‰çº§
                labels['speed_adjustment'].append([-0.2])  # ğŸ›¡ï¸ å‡é€Ÿ
                labels['route_preference'].append([0.3, 0.4, 0.3])
        
        # è½¬æ¢ä¸ºå¼ é‡
        try:
            for key in labels:
                labels[key] = torch.tensor(labels[key], dtype=torch.float32)
        except Exception as tensor_e:
            print(f"âš ï¸ è½¬æ¢å¼ é‡æ—¶å‡ºé”™: {str(tensor_e)}")
            raise tensor_e
        
        return labels
    
    def _validate_data_consistency(self, graph_data: Data, labels: Dict, expected_nodes: int) -> bool:
        """éªŒè¯æ•°æ®ä¸€è‡´æ€§"""
        try:
            actual_nodes = graph_data.x.size(0)
            if actual_nodes != expected_nodes:
                return False
            
            for key, label_tensor in labels.items():
                if label_tensor.size(0) != expected_nodes:
                    return False
            
            return True
            
        except Exception:
            return False

class VehicleGraphDataset(Dataset):
    """è½¦è¾†å›¾æ•°æ®é›†"""
    
    def __init__(self, scenarios_data: List[Tuple]):
        self.data = []
        
        print(f"ğŸ”„ å¤„ç† {len(scenarios_data)} ä¸ªå®‰å…¨æ„ŸçŸ¥åœ°å›¾åœºæ™¯æ•°æ®...")
        
        for i, (graph_data, labels) in enumerate(scenarios_data):
            try:
                data_obj = Data(
                    x=graph_data.x,
                    edge_index=graph_data.edge_index,
                    edge_attr=graph_data.edge_attr,
                    global_features=graph_data.global_features,
                    y_priority=labels['priority'],
                    y_cooperation=labels['cooperation'],
                    y_urgency=labels['urgency'],
                    y_safety=labels['safety'],
                    y_speed_adjustment=labels['speed_adjustment'],
                    y_route_preference=labels['route_preference']
                )
                
                num_nodes = data_obj.x.size(0)
                if (data_obj.y_priority.size(0) == num_nodes and
                    data_obj.y_cooperation.size(0) == num_nodes):
                    self.data.append(data_obj)
                else:
                    if i < 5:
                        print(f"âš ï¸ è·³è¿‡åœºæ™¯ {i}: æ ‡ç­¾ä¸èŠ‚ç‚¹æ•°ä¸åŒ¹é…")
                    
            except Exception as e:
                if i < 5:
                    print(f"âš ï¸ å¤„ç†åœºæ™¯ {i} æ—¶å‡ºé”™: {str(e)}")
                continue
        
        print(f"âœ… æˆåŠŸå¤„ç† {len(self.data)} ä¸ªæœ‰æ•ˆå®‰å…¨æ„ŸçŸ¥åœ°å›¾åœºæ™¯")
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        return self.data[idx]

class SafetyEnhancedVehicleCoordinationGNN(nn.Module):
    """ğŸ›¡ï¸ å®‰å…¨å¢å¼ºçš„è½¦è¾†åè°ƒGNN"""
    
    def __init__(self, config: SafetyEnhancedTrainingConfig):
        super().__init__()
        
        self.config = config
        self.node_dim = 12  # å¢åŠ åœ°å›¾ç‰¹å¾
        self.edge_dim = 6   # å¢åŠ ç¯å¢ƒç‰¹å¾
        self.global_dim = 8
        self.hidden_dim = config.hidden_dim
        
        # ç¼–ç å™¨
        self.node_encoder = nn.Sequential(
            nn.Linear(self.node_dim, self.hidden_dim),
            nn.ReLU(),
            nn.Dropout(config.dropout)
        )
        
        self.edge_encoder = nn.Sequential(
            nn.Linear(self.edge_dim, self.hidden_dim // 2),
            nn.ReLU()
        )
        
        # GNNå±‚
        self.gnn_layers = nn.ModuleList([
            pyg_nn.GCNConv(self.hidden_dim, self.hidden_dim)
            for _ in range(config.num_layers)
        ])
        
        # ğŸ›¡ï¸ å®‰å…¨å¢å¼ºçš„å†³ç­–è¾“å‡ºå¤´
        self.decision_heads = nn.ModuleDict({
            'priority': nn.Sequential(
                nn.Linear(self.hidden_dim, 32),
                nn.ReLU(),
                nn.Dropout(0.1),
                nn.Linear(32, 1),
                nn.Tanh()
            ),
            'cooperation': nn.Sequential(
                nn.Linear(self.hidden_dim, 32),
                nn.ReLU(),
                nn.Dropout(0.1),
                nn.Linear(32, 1),
                nn.Sigmoid()
            ),
            'urgency': nn.Sequential(
                nn.Linear(self.hidden_dim, 32),
                nn.ReLU(),
                nn.Dropout(0.1),
                nn.Linear(32, 1),
                nn.Sigmoid()
            ),
            'safety': nn.Sequential(  # ğŸ›¡ï¸ å®‰å…¨ç³»æ•°æ˜¯æœ€é‡è¦çš„è¾“å‡º
                nn.Linear(self.hidden_dim, 64),  # æ›´å¤§çš„ç½‘ç»œå®¹é‡
                nn.ReLU(),
                nn.Dropout(0.05),  # æ›´å°çš„dropoutï¼Œä¿æŒå®‰å…¨ä¿¡æ¯
                nn.Linear(64, 32),
                nn.ReLU(),
                nn.Linear(32, 1),
                nn.Sigmoid()
            ),
            'speed_adjustment': nn.Sequential(
                nn.Linear(self.hidden_dim, 32),
                nn.ReLU(),
                nn.Dropout(0.1),
                nn.Linear(32, 1),
                nn.Tanh()
            ),
            'route_preference': nn.Sequential(
                nn.Linear(self.hidden_dim, 32),
                nn.ReLU(),
                nn.Dropout(0.1),
                nn.Linear(32, 3),
                nn.Softmax(dim=-1)
            )
        })
    
    def forward(self, batch: Batch) -> Dict[str, torch.Tensor]:
        """å‰å‘ä¼ æ’­"""
        x, edge_index, edge_attr = batch.x, batch.edge_index, batch.edge_attr
        
        if x.size(0) == 0:
            return self._empty_output()
        
        # èŠ‚ç‚¹ç¼–ç 
        x = self.node_encoder(x)
        
        # GNNå±‚
        for gnn_layer in self.gnn_layers:
            x = F.relu(gnn_layer(x, edge_index))
            x = F.dropout(x, p=self.config.dropout, training=self.training)
        
        # ç”Ÿæˆå†³ç­–
        decisions = {}
        for decision_type, head in self.decision_heads.items():
            decisions[decision_type] = head(x)
        
        return decisions
    
    def _empty_output(self) -> Dict[str, torch.Tensor]:
        """ç©ºè¾“å‡º"""
        return {
            'priority': torch.zeros((0, 1)),
            'cooperation': torch.zeros((0, 1)),
            'urgency': torch.zeros((0, 1)),
            'safety': torch.zeros((0, 1)),
            'speed_adjustment': torch.zeros((0, 1)),
            'route_preference': torch.zeros((0, 3))
        }

class SafetyEnhancedGNNTrainer:
    """ğŸ›¡ï¸ å®‰å…¨å¢å¼ºçš„GNNè®­ç»ƒå™¨"""
    
    def __init__(self, config: SafetyEnhancedTrainingConfig):
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # ğŸ›¡ï¸ ä½¿ç”¨å®‰å…¨å¢å¼ºçš„GNNæ¨¡å‹
        self.model = SafetyEnhancedVehicleCoordinationGNN(config).to(self.device)
        
        self.optimizer = torch.optim.Adam(
            self.model.parameters(),
            lr=config.learning_rate,
            weight_decay=config.weight_decay
        )
        
        self.scheduler = torch.optim.lr_scheduler.StepLR(
            self.optimizer, step_size=15, gamma=0.7
        )
        
        # æŸå¤±å‡½æ•°
        self.mse_loss = nn.MSELoss()
        self.bce_loss = nn.BCELoss()
        self.ce_loss = nn.CrossEntropyLoss()
        
        # ğŸ›¡ï¸ å®‰å…¨ç›¸å…³çš„æŸå¤±æƒé‡
        self.safety_loss_weight = config.safety_priority_weight
        
        # è®­ç»ƒè®°å½•
        self.train_losses = []
        self.val_losses = []
        self.best_val_loss = float('inf')
        self.patience_counter = 0
    
    def compute_batch_loss(self, predictions: Dict, batch: Batch) -> torch.Tensor:
        """ğŸ›¡ï¸ å®‰å…¨å¢å¼ºçš„æ‰¹æ¬¡æŸå¤±è®¡ç®—"""
        total_loss = 0.0
        
        y_priority = batch.y_priority
        y_cooperation = batch.y_cooperation
        y_urgency = batch.y_urgency
        y_safety = batch.y_safety
        y_speed_adjustment = batch.y_speed_adjustment
        y_route_preference = batch.y_route_preference
        
        # ğŸ›¡ï¸ å®‰å…¨ä¼˜å…ˆçš„æŸå¤±æƒé‡
        loss_weights = {
            'priority': 1.0,
            'cooperation': 1.0,
            'urgency': 1.0,
            'safety': self.safety_loss_weight,  # ğŸ›¡ï¸ å®‰å…¨ç³»æ•°æƒé‡æœ€é«˜
            'speed_adjustment': 0.8,
            'route_preference': 1.2
        }
        
        if 'priority' in predictions and y_priority.size(0) > 0:
            loss = self.mse_loss(predictions['priority'], y_priority)
            total_loss += loss_weights['priority'] * loss
            
        if 'cooperation' in predictions and y_cooperation.size(0) > 0:
            loss = self.bce_loss(predictions['cooperation'], y_cooperation)
            total_loss += loss_weights['cooperation'] * loss
            
        if 'urgency' in predictions and y_urgency.size(0) > 0:
            loss = self.bce_loss(predictions['urgency'], y_urgency)
            total_loss += loss_weights['urgency'] * loss
            
        if 'safety' in predictions and y_safety.size(0) > 0:
            # ğŸ›¡ï¸ å®‰å…¨æŸå¤±æ˜¯æœ€é‡è¦çš„
            safety_loss = self.bce_loss(predictions['safety'], y_safety)
            
            # ğŸ›¡ï¸ é¢å¤–çš„å®‰å…¨æƒ©ç½šï¼šå¦‚æœé¢„æµ‹çš„å®‰å…¨ç³»æ•°ä½äºæ ‡ç­¾ï¼Œé¢å¤–æƒ©ç½š
            safety_penalty = torch.mean(torch.relu(y_safety - predictions['safety'])) * 0.5
            
            total_loss += loss_weights['safety'] * (safety_loss + safety_penalty)
            
        if 'speed_adjustment' in predictions and y_speed_adjustment.size(0) > 0:
            loss = self.mse_loss(predictions['speed_adjustment'], y_speed_adjustment)
            total_loss += loss_weights['speed_adjustment'] * loss
            
        if 'route_preference' in predictions and y_route_preference.size(0) > 0:
            loss = self.ce_loss(predictions['route_preference'], y_route_preference)
            total_loss += loss_weights['route_preference'] * loss
        
        return total_loss
    
    def train_epoch(self, dataloader) -> float:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0.0
        num_batches = 0
        
        for batch in tqdm(dataloader, desc="ğŸ›¡ï¸ å®‰å…¨æ„ŸçŸ¥è®­ç»ƒ"):
            try:
                self.optimizer.zero_grad()
                batch = batch.to(self.device)
                predictions = self.model(batch)
                loss = self.compute_batch_loss(predictions, batch)
                loss.backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)
                self.optimizer.step()
                
                total_loss += loss.item()
                num_batches += 1
                
            except Exception as e:
                print(f"âš ï¸ è®­ç»ƒæ‰¹æ¬¡å‡ºé”™: {str(e)}")
                continue
        
        return total_loss / max(num_batches, 1)
    
    def validate(self, dataloader) -> float:
        """éªŒè¯"""
        self.model.eval()
        total_loss = 0.0
        num_batches = 0
        
        with torch.no_grad():
            for batch in tqdm(dataloader, desc="ğŸ›¡ï¸ å®‰å…¨æ„ŸçŸ¥éªŒè¯"):
                try:
                    batch = batch.to(self.device)
                    predictions = self.model(batch)
                    loss = self.compute_batch_loss(predictions, batch)
                    total_loss += loss.item()
                    num_batches += 1
                except Exception as e:
                    continue
        
        return total_loss / max(num_batches, 1)
    
    def train(self, train_dataset: VehicleGraphDataset, val_dataset: VehicleGraphDataset):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        print(f"ğŸ›¡ï¸ å¼€å§‹è®­ç»ƒå®‰å…¨å¢å¼ºGNNæ¨¡å‹...")
        print(f"  è®­ç»ƒæ•°æ®: {len(train_dataset)} ä¸ªå®‰å…¨æ„ŸçŸ¥åœ°å›¾åœºæ™¯")
        print(f"  éªŒè¯æ•°æ®: {len(val_dataset)} ä¸ªå®‰å…¨æ„ŸçŸ¥åœ°å›¾åœºæ™¯")
        print(f"  ğŸ›¡ï¸ å®‰å…¨æŸå¤±æƒé‡: {self.safety_loss_weight}")
        
        train_loader = DataLoader(
            train_dataset, 
            batch_size=self.config.batch_size, 
            shuffle=True,
            follow_batch=['x']
        )
        
        val_loader = DataLoader(
            val_dataset, 
            batch_size=self.config.batch_size, 
            shuffle=False,
            follow_batch=['x']
        )
        
        for epoch in range(self.config.num_epochs):
            print(f"\nğŸ“Š Epoch {epoch+1}/{self.config.num_epochs} (ğŸ›¡ï¸ å®‰å…¨å¢å¼ºè®­ç»ƒ)")
            
            train_loss = self.train_epoch(train_loader)
            self.train_losses.append(train_loss)
            
            val_loss = self.validate(val_loader)
            self.val_losses.append(val_loss)
            
            self.scheduler.step()
            
            print(f"  è®­ç»ƒæŸå¤±: {train_loss:.4f}")
            print(f"  éªŒè¯æŸå¤±: {val_loss:.4f}")
            print(f"  å­¦ä¹ ç‡: {self.optimizer.param_groups[0]['lr']:.6f}")
            
            if val_loss < self.best_val_loss:
                self.best_val_loss = val_loss
                self.patience_counter = 0
                self.save_model('best_safety_enhanced_gnn_model.pth')
                print(f"  âœ… éªŒè¯æŸå¤±æ”¹å–„ï¼Œä¿å­˜æœ€ä½³å®‰å…¨å¢å¼ºæ¨¡å‹")
            else:
                self.patience_counter += 1
                print(f"  â³ éªŒè¯æŸå¤±æœªæ”¹å–„ ({self.patience_counter}/{self.config.early_stopping_patience})")
            
            if self.patience_counter >= self.config.early_stopping_patience:
                print(f"  ğŸ›‘ æ—©åœ")
                break
        
        print(f"\nğŸ‰ å®‰å…¨å¢å¼ºGNNè®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯æŸå¤±: {self.best_val_loss:.4f}")
    
    def save_model(self, filepath: str):
        """ä¿å­˜æ¨¡å‹"""
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'config': self.config,
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
            'best_val_loss': self.best_val_loss
        }, filepath)

def main():
    """ğŸ›¡ï¸ å®‰å…¨å¢å¼ºGNNé¢„è®­ç»ƒä¸»æµç¨‹"""
    print("ğŸ›¡ï¸ å®‰å…¨å¢å¼ºçš„åœ°å›¾æ„ŸçŸ¥GNNé¢„è®­ç»ƒç³»ç»Ÿ")
    print("=" * 80)
    print("ğŸ¯ æ ¸å¿ƒå®‰å…¨æ”¹è¿›:")
    print("   âœ… ğŸ›¡ï¸ å®‰å…¨ä¼˜å…ˆçš„æ ‡ç­¾ç”Ÿæˆ - è·ç¦»æ„ŸçŸ¥çš„å®‰å…¨ç³»æ•°")
    print("   âœ… ğŸ›¡ï¸ å±é™©åœºæ™¯è®­ç»ƒ - 30%å±é™©åœºæ™¯è®­ç»ƒå®‰å…¨è¡Œä¸º")  
    print("   âœ… ğŸ›¡ï¸ å¤šå±‚å®‰å…¨ä¿éšœ - é¢„è®­ç»ƒâ†’åº”ç”¨â†’éªŒè¯â†’åå¤„ç†")
    print("   âœ… ğŸ›¡ï¸ å®‰å…¨æŸå¤±åŠ æƒ - å®‰å…¨ç³»æ•°æŸå¤±æƒé‡1.5å€")
    print("   âœ… ğŸ›¡ï¸ ä¿å®ˆä¼˜å…ˆçº§è°ƒæ•´ - é¿å…æ¿€è¿›ä¼˜å…ˆçº§ç­–ç•¥")
    print("   âœ… ğŸ›¡ï¸ æ™ºèƒ½é€Ÿåº¦æ§åˆ¶ - åŸºäºè½¦è¾†è·ç¦»çš„åŠ¨æ€å‡é€Ÿ")
    print("   âœ… ğŸ›¡ï¸ å®‰å…¨è·¯å¾„åå¥½ - å±é™©æƒ…å†µä¸‹åå‘é¿è®©ç»•è¡Œ")
    print("=" * 80)
    
    # ğŸ›¡ï¸ å®‰å…¨å¢å¼ºé…ç½®
    config = SafetyEnhancedTrainingConfig(
        batch_size=4,
        learning_rate=0.0008,   # ğŸ›¡ï¸ ç•¥å¾®é™ä½å­¦ä¹ ç‡
        num_epochs=45,          # ğŸ›¡ï¸ å¢åŠ è®­ç»ƒè½®æ•°
        hidden_dim=64,
        num_layers=3,
        dropout=0.15,           # ğŸ›¡ï¸ ç•¥å¾®å¢åŠ dropout
        
        # ğŸ›¡ï¸ å®‰å…¨ç›¸å…³é…ç½®
        num_scenarios=2500,     # ğŸ›¡ï¸ å¢åŠ è®­ç»ƒåœºæ™¯
        num_map_variants=12,    # ğŸ›¡ï¸ æ›´å¤šåœ°å›¾å˜ä½“
        max_vehicles=6,
        use_real_maps=True,
        
        # ğŸ›¡ï¸ å®‰å…¨è®­ç»ƒç­–ç•¥
        min_safe_distance=8.0,
        safety_priority_weight=1.5,    # ğŸ›¡ï¸ å®‰å…¨æŸå¤±æƒé‡1.5å€
        danger_scenario_ratio=0.3       # ğŸ›¡ï¸ 30%å±é™©åœºæ™¯
    )
    
    print(f"\nğŸ“‹ ğŸ›¡ï¸ å®‰å…¨å¢å¼ºè®­ç»ƒé…ç½®:")
    print(f"  æ•°æ®é›†å¤§å°: {config.num_scenarios}")
    print(f"  å±é™©åœºæ™¯æ¯”ä¾‹: {config.danger_scenario_ratio*100:.0f}%")
    print(f"  å®‰å…¨æŸå¤±æƒé‡: {config.safety_priority_weight}x")
    print(f"  æœ€å°å®‰å…¨è·ç¦»: {config.min_safe_distance}m")
    print(f"  åœ°å›¾å˜ä½“æ•°: {config.num_map_variants}")
    print(f"  ç‰¹å¾ç»´åº¦: èŠ‚ç‚¹12ç»´(+åœ°å›¾) + è¾¹6ç»´(+ç¯å¢ƒ) + å…¨å±€8ç»´")
    
    try:
        # 1. ç”Ÿæˆå®‰å…¨æ„ŸçŸ¥çš„è®­ç»ƒæ•°æ®
        print(f"\nğŸ“Š æ­¥éª¤1: ç”Ÿæˆå®‰å…¨æ„ŸçŸ¥è®­ç»ƒæ•°æ®")
        generator = SafetyEnhancedVehicleScenarioGenerator(config)
        all_data = generator.generate_training_data()
        
        if len(all_data) < 20:
            print("âŒ ç”Ÿæˆçš„æœ‰æ•ˆåœ°å›¾æ•°æ®å¤ªå°‘ï¼Œæ— æ³•è®­ç»ƒ")
            return
        
        # 2. åˆ’åˆ†æ•°æ®é›†
        val_size = max(5, int(len(all_data) * config.val_split))
        train_size = len(all_data) - val_size
        
        train_data = all_data[:train_size]
        val_data = all_data[train_size:]
        
        print(f"  è®­ç»ƒé›†: {len(train_data)} ä¸ªå®‰å…¨æ„ŸçŸ¥åœ°å›¾åœºæ™¯")
        print(f"  éªŒè¯é›†: {len(val_data)} ä¸ªå®‰å…¨æ„ŸçŸ¥åœ°å›¾åœºæ™¯")
        
        # 3. åˆ›å»ºæ•°æ®é›†
        print(f"\nğŸ”„ æ­¥éª¤2: åˆ›å»ºå®‰å…¨æ„ŸçŸ¥æ•°æ®é›†")
        train_dataset = VehicleGraphDataset(train_data)
        val_dataset = VehicleGraphDataset(val_data)
        
        if len(train_dataset) == 0 or len(val_dataset) == 0:
            print("âŒ å®‰å…¨æ„ŸçŸ¥æ•°æ®é›†åˆ›å»ºå¤±è´¥")
            return
        
        # 4. è®­ç»ƒå®‰å…¨å¢å¼ºGNNæ¨¡å‹
        print(f"\nğŸ›¡ï¸ æ­¥éª¤3: è®­ç»ƒå®‰å…¨å¢å¼ºGNNæ¨¡å‹")
        trainer = SafetyEnhancedGNNTrainer(config)
        trainer.train(train_dataset, val_dataset)
        
        # 5. ä¿å­˜æ¨¡å‹
        trainer.save_model('final_safety_enhanced_gnn_model.pth')
        
        print(f"\nâœ… ğŸ›¡ï¸ å®‰å…¨å¢å¼ºGNNé¢„è®­ç»ƒå®Œæˆï¼")
        print(f"  æœ€ä½³æ¨¡å‹: best_safety_enhanced_gnn_model.pth")
        print(f"  æœ€ç»ˆæ¨¡å‹: final_safety_enhanced_gnn_model.pth")
        print(f"\nğŸ¯ ğŸ›¡ï¸ å®‰å…¨å¢å¼ºæ¨¡å‹ç‰¹æ€§:")
        print(f"  âœ… è·ç¦»æ„ŸçŸ¥å®‰å…¨ç³»æ•° - è½¦è¾†é—´è·ç¦»<8mæ—¶å®‰å…¨ç³»æ•°0.95")
        print(f"  âœ… å±é™©åœºæ™¯è®­ç»ƒ - 30%å†²çªåœºæ™¯è®­ç»ƒå®‰å…¨é¿è®©è¡Œä¸º")  
        print(f"  âœ… å®‰å…¨ä¼˜å…ˆå†³ç­– - å±é™©æƒ…å†µä¸‹è‡ªåŠ¨é™ä½ç´§æ€¥åº¦å’Œä¼˜å…ˆçº§")
        print(f"  âœ… æ™ºèƒ½å‡é€Ÿç­–ç•¥ - è·ç¦»<10mæ—¶å¼ºåˆ¶å‡é€Ÿ40%")
        print(f"  âœ… é¿è®©è·¯å¾„åå¥½ - å±é™©æ—¶åå‘å·¦å³ç»•è¡Œè€Œéç›´å†²")
        print(f"  âœ… å¤šå±‚å®‰å…¨éªŒè¯ - ä»é¢„è®­ç»ƒåˆ°åº”ç”¨çš„å…¨é“¾è·¯å®‰å…¨ä¿éšœ")
        
        print(f"\nğŸ›¡ï¸ é¢„æœŸè§£å†³é—®é¢˜:")
        print(f"  âŒ ä¿®å¤å‰: è½¦è¾†'è´´ç€è¿‡å»'ï¼Œè·ç¦»è¿‡è¿‘")
        print(f"  âœ… ä¿®å¤å: å¼ºåˆ¶8m+å®‰å…¨è·ç¦»ï¼Œæ™ºèƒ½é¿è®©ç­–ç•¥")
        
    except Exception as e:
        print(f"âŒ å®‰å…¨å¢å¼ºè®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()